{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start up commands/load relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling CSV [336ed68f-0bac-5ca0-87d4-7b16caf5d00b]\n",
      "└ @ Base loading.jl:1187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 2:\t┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "      From worker 2:\t│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "      From worker 2:\t└ @ Base loading.jl:941\n",
      "      From worker 3:\t┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "      From worker 3:\t│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "      From worker 3:\t└ @ Base loading.jl:941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:941\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/em.jl:299\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:67\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:67\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/common.jl:67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/genVars.jl:17.\n",
      "└ @ nothing /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/genVars.jl:17\n",
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/genVars.jl:17.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/genVars.jl:17\n",
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/Dropbox/Summerfield_Lab/ValueInference/models/model101/genVars.jl:17.\n",
      "└ @ ~/Dropbox/Summerfield_Lab/ValueInference/models/model101/genVars.jl:17\n"
     ]
    }
   ],
   "source": [
    "# load required libraries\n",
    "using Distributed\n",
    "\n",
    "# # set everything up\n",
    "parallel = true # Run on multiple CPUs. If youhttp://localhost:8888/notebooks/Dropbox/Daw_Lab/PreySelection/v103/models/model_subjective1beta2lr_delayreward/model_subjective1beta2lr_delayreward.jl.ipynb# are having trouble, set parallel = false: easier to debug\n",
    "\n",
    "# this activates the multiprocessing threads\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "    addprocs(2)\n",
    "end\n",
    "\n",
    "# load required libraries\n",
    "@everywhere using DataFrames\n",
    "@everywhere using ForwardDiff\n",
    "@everywhere using PyCall\n",
    "@everywhere using Distributions\n",
    "@everywhere using PyPlot\n",
    "@everywhere using CSV\n",
    "@everywhere using SpecialFunctions\n",
    "@everywhere using SharedArrays\n",
    "@everywhere using LinearAlgebra\n",
    "\n",
    "@everywhere PyCall.@pyimport scipy.optimize as so\n",
    "\n",
    "# this is the code for the actual fitting routines\n",
    "@everywhere include(\"em.jl\")\n",
    "@everywhere include(\"common.jl\")\n",
    "@everywhere include(\"likfuns.jl\")\n",
    "\n",
    "# this is generates starting matricies for betas, sigmas etc to feed into model\n",
    "@everywhere include(\"genVars.jl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data read and process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: readtable is deprecated, use CSV.read from the CSV package instead\n",
      "│   caller = top-level scope at In[2]:1\n",
      "└ @ Core In[2]:1\n",
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[2]:19\n",
      "└ @ Core In[2]:19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>participantID</th><th>condition</th><th>blocks</th><th>blockType</th><th>trials</th><th>probabilitiesMarketOne_1</th><th>probabilitiesMarketOne_2</th><th>probabilitiesMarketTwo_1</th><th>probabilitiesMarketTwo_2</th><th>rewards_1</th><th>rewards_2</th><th>gem_presented</th><th>market_presented</th><th>chooseLeft</th><th>stateChosen</th><th>outcomeState</th><th>outcome</th><th>RT</th><th>black_rl_p</th><th>black_sofa_p</th><th>chosen_rl_p</th><th>chosen_sofa_p</th><th>pick_black</th><th>rt_log_trans</th><th>white_rl_p</th><th>white_sofa_p</th><th>missed_response</th><th>structureAwareness</th><th>evidence_consistency</th><th>consistent_choice</th><th>same_gem</th><th>doorRepeat</th><th>sideRepeat</th><th>sub</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>6 rows × 34 columns</p><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2</td><td>2</td><td>0</td><td>1.235</td><td>0.2</td><td>0.8</td><td>0.8</td><td>0.2</td><td>0.0</td><td>-0.211073</td><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><th>2</th><td>1</td><td>1</td><td>1</td><td>1</td><td>3</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1.75767</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1.0</td><td>-0.56399</td><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><th>3</th><td>1</td><td>1</td><td>1</td><td>1</td><td>4</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>0</td><td>1.23885</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1.0</td><td>-0.214187</td><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td></tr><tr><th>4</th><td>1</td><td>1</td><td>1</td><td>1</td><td>5</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>-1</td><td>0</td><td>2</td><td>1</td><td>0</td><td>1</td><td>2</td><td>0</td><td>3.50974</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1.0</td><td>-1.25554</td><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td></tr><tr><th>5</th><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1.87775</td><td>0.2</td><td>0.8</td><td>0.8</td><td>0.2</td><td>0.0</td><td>-0.630076</td><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><th>6</th><td>1</td><td>1</td><td>1</td><td>1</td><td>7</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1</td><td>0</td><td>2</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1.35541</td><td>0.2</td><td>0.8</td><td>0.8</td><td>0.2</td><td>0.0</td><td>-0.304105</td><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccccccccccccccccccccccccccc}\n",
       "\t& participantID & condition & blocks & blockType & trials & probabilitiesMarketOne\\_1 & probabilitiesMarketOne\\_2 & probabilitiesMarketTwo\\_1 & probabilitiesMarketTwo\\_2 & rewards\\_1 & rewards\\_2 & gem\\_presented & market\\_presented & chooseLeft & stateChosen & outcomeState & outcome & RT & black\\_rl\\_p & black\\_sofa\\_p & chosen\\_rl\\_p & chosen\\_sofa\\_p & pick\\_black & rt\\_log\\_trans & white\\_rl\\_p & white\\_sofa\\_p & missed\\_response & structureAwareness & evidence\\_consistency & consistent\\_choice & same\\_gem & doorRepeat & sideRepeat & sub\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & 2 & 0.2 & 0.8 & 0.2 & 0.8 & 1 & 0 & 1 & 1 & 1 & 2 & 2 & 0 & 1.235 & 0.2 & 0.8 & 0.8 & 0.2 & 0.0 & -0.211073 & 0.8 & 0.2 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 \\\\\n",
       "\t2 & 1 & 1 & 1 & 1 & 3 & 0.2 & 0.8 & 0.2 & 0.8 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 1.75767 & 0.2 & 0.8 & 0.2 & 0.8 & 1.0 & -0.56399 & 0.8 & 0.2 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 1 \\\\\n",
       "\t3 & 1 & 1 & 1 & 1 & 4 & 0.2 & 0.8 & 0.2 & 0.8 & 1 & 0 & 1 & 1 & 1 & 1 & 2 & 0 & 1.23885 & 0.2 & 0.8 & 0.2 & 0.8 & 1.0 & -0.214187 & 0.8 & 0.2 & 0 & 0 & 1 & 1 & 1 & 1 & 0 & 1 \\\\\n",
       "\t4 & 1 & 1 & 1 & 1 & 5 & 0.2 & 0.8 & 0.2 & 0.8 & -1 & 0 & 2 & 1 & 0 & 1 & 2 & 0 & 3.50974 & 0.2 & 0.8 & 0.2 & 0.8 & 1.0 & -1.25554 & 0.8 & 0.2 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 \\\\\n",
       "\t5 & 1 & 1 & 1 & 1 & 6 & 0.2 & 0.8 & 0.2 & 0.8 & 1 & 0 & 1 & 1 & 1 & 2 & 1 & 1 & 1.87775 & 0.2 & 0.8 & 0.8 & 0.2 & 0.0 & -0.630076 & 0.8 & 0.2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
       "\t6 & 1 & 1 & 1 & 1 & 7 & 0.2 & 0.8 & 0.2 & 0.8 & 1 & 0 & 2 & 1 & 1 & 2 & 1 & 1 & 1.35541 & 0.2 & 0.8 & 0.8 & 0.2 & 0.0 & -0.304105 & 0.8 & 0.2 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×34 DataFrame. Omitted printing of 29 columns\n",
       "│ Row │ participantID │ condition │ blocks │ blockType │ trials │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m        │ \u001b[90mInt64⍰\u001b[39m    │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m    │ \u001b[90mInt64⍰\u001b[39m │\n",
       "├─────┼───────────────┼───────────┼────────┼───────────┼────────┤\n",
       "│ 1   │ 1             │ 1         │ 1      │ 1         │ 2      │\n",
       "│ 2   │ 1             │ 1         │ 1      │ 1         │ 3      │\n",
       "│ 3   │ 1             │ 1         │ 1      │ 1         │ 4      │\n",
       "│ 4   │ 1             │ 1         │ 1      │ 1         │ 5      │\n",
       "│ 5   │ 1             │ 1         │ 1      │ 1         │ 6      │\n",
       "│ 6   │ 1             │ 1         │ 1      │ 1         │ 7      │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv file of the data\n",
    "#df = readtable(\"/Users/Leonie/Dropbox/ValueInference/data/complete_dat.csv\")\n",
    "df = readtable(\"/Users/Neil/Dropbox/Summerfield_Lab/ValueInference/data/complete_dat.csv\")\n",
    "\n",
    "#Leonie\\Dropbox\\ValueInference\n",
    "\n",
    "#get rid of missed responses\n",
    "df = df[df[:outcome].!=9,:]\n",
    "\n",
    "#outcome state 1 = reward/loss state\n",
    "#outcome state 2 = neutral state\n",
    "\n",
    "#add \"sub column\" \n",
    "# this is just a replica of the existing column sub_no but I think em looks for \"sub\" specifically\n",
    "df[:sub] = df[:participantID];\n",
    "\n",
    "#change coding of markets prestened so that 1 = market 1 in dependent condition, 2 and 3 refer to the two markets in the independent condition\n",
    "df[df[:condition].==2,:market_presented] = df[df[:condition].==2,:market_presented] .+ 1\n",
    "\n",
    "# rescale rewards? think about this\n",
    "\n",
    "# display header\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Model (Basic)\n",
    "\n",
    "\n",
    "Takes into account gem type -  updates probabilites for black/white door based on state reached following choice and then uses these to compute the value of each door on the current trial. seperate traces for each gem\n",
    "\n",
    "have just one probability estimate which captures proability of reaching the gain loss state for black door and the safe state for white (i.e. take into account inherent dependence between the doors)\n",
    "\n",
    "Model comprises:\n",
    "\n",
    "slope governing sensitivity to two quantities\n",
    "one learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function rl_model(params, data)\n",
    "    \n",
    "    #model parameteres\n",
    "\tbeta_mb = params[1] #weight for MB\n",
    "\tbeta_mf = params[2] #weight for MB\n",
    "    lr_pos = 0.5 .+ 0.5 * erf(params[3] / sqrt(2)) #learning rate\n",
    "    lr_neg = 0.5 .+ 0.5 * erf(params[4] / sqrt(2)) #learning rate\n",
    "    lr_MF = 0.5 .+ 0.5 * erf(params[5] / sqrt(2)) #learning rate\n",
    "    lr_w = 0.5 + 0.5 * erf(params[6] / sqrt(2)) #contribution of each gem\n",
    "            \n",
    "    w = 0.5\n",
    "    \n",
    "    c1 = data[:stateChosen] # choice: 1 = black door, 2 = white door\n",
    "    r = data[:outcome] # outcome: coded as +1 = gain, -1 = loss, 0 = neutral \n",
    "    s = data[:outcomeState] # stage 2 state: coded as 1 = gain/loss state reached, 2 = neutral state reached\n",
    "    t = data[:trials] # trial number\n",
    "    sub = data[:sub] # subject number\n",
    "    condition = data[:blockType] # condition: 1 = dependent, 2=independent\n",
    "    gem = data[:gem_presented] #gem presented\n",
    "    market = data[:market_presented] #market presented\n",
    "    reward_loss_trial = data[:rewards_1] #market presented\n",
    "    \n",
    "    SR_m = zeros(typeof(beta_mb), 4, 1) .+ 0.5 #initalise to 0.5. stores estimates of transition probabilities for black/white door going to reward/loss state \n",
    "\n",
    "\tQm = zeros(typeof(beta_mb), 2) #decision variable\n",
    "    Q1 = zeros(typeof(beta_mb), 2) #TD1\n",
    "    \n",
    "    covar = zeros(typeof(beta_mb), 1) .+ 0.0 #one or one per block?\n",
    "\n",
    "    # initialize likelihood\n",
    "    lik = 0 \n",
    "\n",
    "    # tracking previous choice to determine perseveration\n",
    "    prevc = 0 \n",
    "\n",
    "\tfor i = 1:length(c1)\n",
    "                \n",
    "        #if gem[i]<3\n",
    "        #    QMB1 = [SR_m[gem[i]].*reward_loss_trial[i], (1-SR_m[gem[i]]).*reward_loss_trial[i]] #two column vector predicted value black white door       \n",
    "        #    QMB2 = [SR_m[abs(gem[i]-3)].*reward_loss_trial[i], (1-SR_m[abs(gem[i]-3)]).*reward_loss_trial[i]] #two column vector predicted value black white door       \n",
    "        #else\n",
    "        #    QMB1 = [SR_m[gem[i]].*reward_loss_trial[i], (1-SR_m[gem[i]]).*reward_loss_trial[i]] #two column vector predicted value black white door       \n",
    "        #    QMB2 = [SR_m[abs(gem[i]-2-3)+2].*reward_loss_trial[i], (1-SR_m[abs(gem[i]-2-3)+2]).*reward_loss_trial[i]] #two column vector predicted value black white door \n",
    "        #end\n",
    "                        \n",
    "        #covar_rescaled = 0.5*(covar - 1) + 0.5\n",
    "        \n",
    "        covar_rescaled = 0 \n",
    "        \n",
    "        Qmb_curr_gem = [SR_m[gem[i]].*reward_loss_trial[i], (1-SR_m[gem[i]]).*reward_loss_trial[i]]\n",
    "        \n",
    "        if gem[i]<3\n",
    "            Qmb_other_gem = [SR_m[abs(gem[i]-3)].*reward_loss_trial[i], (1-SR_m[abs(gem[i]-3)]).*reward_loss_trial[i]]\n",
    "        else\n",
    "            Qmb_other_gem = [SR_m[abs(gem[i]-2-3)+2].*reward_loss_trial[i], (1-SR_m[abs(gem[i]-2-3)+2]).*reward_loss_trial[i]]            \n",
    "        end\n",
    "        \n",
    "        \n",
    "        #if gem[i]<3\n",
    "            #Qmb = (1-covar_rescaled).*QMB1[gem[i]] + covar_rescaled.*QMB2[abs(gem[i]-3)]\n",
    "        #    Qmb = QMB1[gem[i]]\n",
    "        #else\n",
    "            #Qmb = (1-covar_rescaled).*QMB1[gem[i]] + covar_rescaled.*QMB2[abs(gem[i]-2-3)+2]   \n",
    "        #    Qmb = QMB1[gem[i]]\n",
    "        #end\n",
    "                                \n",
    "        #Q-values that determine the decision\n",
    "        Qd = beta_mb.*Qmb #.+ beta_mf.*Q1 \n",
    "\n",
    "        # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "        # add that likelihood to the running likelihood\n",
    "        lik += Qd[c1[i]] - log(sum(exp.(Qd)))\n",
    "        \n",
    "        if (reward_loss_trial[i]==1 & r[i]==1)\n",
    "            lr = lr_pos\n",
    "        elseif (reward_loss_trial[i]==-1 & r[i]==0)\n",
    "            lr = lr_pos\n",
    "        else\n",
    "            lr = lr_neg\n",
    "        end \n",
    "        \n",
    "        # updates go in here - these are updates of probability estimates (not contingent on outcome)\n",
    "        if (s[i]==1 & c1[i]==1)\n",
    "            SR_m[gem[i]] = (1-lr)*SR_m[gem[i]] .+ lr*1          \n",
    "        elseif (s[i]==2 & c1[i]==2)\n",
    "            SR_m[gem[i]] = (1-lr)*SR_m[gem[i]] .+ lr*1\n",
    "        else\n",
    "            SR_m[gem[i]] = (1-lr)*SR_m[gem[i]] .+ lr*0\n",
    "        end\n",
    "        \n",
    "        #MF update\n",
    "        Q1[c1[i]] = (1-lr_MF) * Q1[c1[i]] .+ lr_MF*r[i] #TD1\n",
    "        \n",
    "        #if gem[i] < 3\n",
    "            #variance of the SRs\n",
    "        #    var = minimum(SR_m[1:2])/maximum(SR_m[1:2])\n",
    "        #else\n",
    "        #     var = minimum(SR_m[3:4])/maximum(SR_m[3:4])       \n",
    "        #end\n",
    "        \n",
    "        \n",
    "        #update the covariance estimate between the two gems\n",
    "        #covar[1] = (1-lr_w)*covar[1] + lr_w*var\n",
    "\n",
    "\tend\n",
    "\n",
    "    # compile trial by trial values here\n",
    "    trial_data = DataFrame(trial = t,\n",
    "            sub = sub,\n",
    "            choice = c1,\n",
    "            state = s,\n",
    "            reward = r)\n",
    "        \n",
    "    # here if running em you can only return the likelihood\n",
    "    return -lik\n",
    "    \n",
    "    # but if you run in order to extract trial by trial Q values etc. (once you know the parameters) then want to return this\n",
    "    #return (-lik, trial_data)\n",
    "       \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model for one subject\n",
    "(aids debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331.3243523076546"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize parameter structures\n",
    "(df, subs, X, betas, sigma) = genVars(df, 6);\n",
    "\n",
    "# run model for sub 1\n",
    "rl_model(betas, df[df[:sub].==subs[1],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run em to get best fit parameters for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>participantID</th><th>condition</th><th>blocks</th><th>blockType</th><th>trials</th><th>probabilitiesMarketOne_1</th><th>probabilitiesMarketOne_2</th><th>probabilitiesMarketTwo_1</th><th>probabilitiesMarketTwo_2</th><th>rewards_1</th><th>rewards_2</th><th>gem_presented</th><th>market_presented</th><th>chooseLeft</th><th>stateChosen</th><th>outcomeState</th><th>outcome</th><th>RT</th><th>black_rl_p</th><th>black_sofa_p</th><th>chosen_rl_p</th><th>chosen_sofa_p</th><th>pick_black</th><th>rt_log_trans</th><th>white_rl_p</th><th>white_sofa_p</th><th>missed_response</th><th>structureAwareness</th><th>evidence_consistency</th><th>consistent_choice</th><th>same_gem</th><th>doorRepeat</th><th>sideRepeat</th><th>sub</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>2 rows × 34 columns</p><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>3</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1.75767</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1.0</td><td>-0.56399</td><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><th>2</th><td>1</td><td>1</td><td>1</td><td>1</td><td>4</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>0</td><td>1.23885</td><td>0.2</td><td>0.8</td><td>0.2</td><td>0.8</td><td>1.0</td><td>-0.214187</td><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccccccccccccccccccccccccccc}\n",
       "\t& participantID & condition & blocks & blockType & trials & probabilitiesMarketOne\\_1 & probabilitiesMarketOne\\_2 & probabilitiesMarketTwo\\_1 & probabilitiesMarketTwo\\_2 & rewards\\_1 & rewards\\_2 & gem\\_presented & market\\_presented & chooseLeft & stateChosen & outcomeState & outcome & RT & black\\_rl\\_p & black\\_sofa\\_p & chosen\\_rl\\_p & chosen\\_sofa\\_p & pick\\_black & rt\\_log\\_trans & white\\_rl\\_p & white\\_sofa\\_p & missed\\_response & structureAwareness & evidence\\_consistency & consistent\\_choice & same\\_gem & doorRepeat & sideRepeat & sub\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & 3 & 0.2 & 0.8 & 0.2 & 0.8 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 1.75767 & 0.2 & 0.8 & 0.2 & 0.8 & 1.0 & -0.56399 & 0.8 & 0.2 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 1 \\\\\n",
       "\t2 & 1 & 1 & 1 & 1 & 4 & 0.2 & 0.8 & 0.2 & 0.8 & 1 & 0 & 1 & 1 & 1 & 1 & 2 & 0 & 1.23885 & 0.2 & 0.8 & 0.2 & 0.8 & 1.0 & -0.214187 & 0.8 & 0.2 & 0 & 0 & 1 & 1 & 1 & 1 & 0 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "2×34 DataFrame. Omitted printing of 29 columns\n",
       "│ Row │ participantID │ condition │ blocks │ blockType │ trials │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m        │ \u001b[90mInt64⍰\u001b[39m    │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m    │ \u001b[90mInt64⍰\u001b[39m │\n",
       "├─────┼───────────────┼───────────┼────────┼───────────┼────────┤\n",
       "│ 1   │ 1             │ 1         │ 1      │ 1         │ 3      │\n",
       "│ 2   │ 1             │ 1         │ 1      │ 1         │ 4      │"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[2:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized parameter structures (again)\n",
    "# note that some of the variables (e.g. betas, sigma) are entered and returned by em function \n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# run for full learner\n",
    "# x contains the parameters for each subject (note not the same as variable X)\n",
    "# l and h are per-subject likelihood and hessians\n",
    "@time (betas, sigma, x, l, h) = em(df, subs, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true, quiet=false);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Model Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBIC, IAIC and LOOcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model selection/comparison/scoring\n",
    "\n",
    "# laplace approximation to the aggregate log marginal likelihood of the whole dataset\n",
    "# marginalized over the individual params\n",
    "\n",
    "aggll = lml(x, l, h)\n",
    "\n",
    "# to compare this between models you need to correct for the group-level free parameters\n",
    "# either aic or bic\n",
    "\n",
    "aggll_ibic = ibic(x, l, h, betas, sigma, nrow(df))\n",
    "aggll_iaic = iaic(x, l, h, betas, sigma)\n",
    "\n",
    "# or you can compute unbiased per subject marginal likelihoods via subject-level cross validation\n",
    "# you can do paired t tests on these between models\n",
    "# these are also appropriate for SPM_BMS etc\n",
    "\n",
    "# takes ages so comment in when want to run, otherwise just use IAIC above\n",
    "#liks = loocv(df, subs, x, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true)\n",
    "#aggll_loo = sum(liks)\n",
    "\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll: $aggll_iaic\\nloo nll:  $aggll_loo\")\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll:\")\n",
    "print(aggll_iaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write loocv scores to csv file\n",
    "\n",
    "(if you have run this part above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put loocv scores into dataframe\n",
    "loocv_scores = DataFrame(sub = subs,\n",
    "liks = vec(liks));\n",
    "\n",
    "#write to csv\n",
    "CSV.write(\"loocv_scores.csv\", DataFrame(loocv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and write p values, std error and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard errors on the subject-level means, based on an asymptotic Gaussian approx \n",
    "# (these may be inflated esp for small n)\n",
    "(standarderrors, pvalues, covmtx) = emerrors(df, subs, x, X, h, betas, sigma, rl_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = DataFrame(stderror = vec(standarderrors),\n",
    "pvalues = vec(pvalues),\n",
    "covmtx_1 = vec(covmtx[:,1]),\n",
    "covmtx_2 = vec(covmtx[:,2]),\n",
    "covmtx_3 = vec(covmtx[:,3]));\n",
    "\n",
    "# save model stats to csv file\n",
    "CSV.write(\"model_stats.csv\", DataFrame(model_stats));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standarderrors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covmtx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write per subject model parameters to csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save a copy of just the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put parameters into variable d\n",
    "d=x';\n",
    "\n",
    "# now put parameters into dataframe\n",
    "params = DataFrame(sub = subs,\n",
    "beta_mb = vec(d[:, 1]), \n",
    "beta_mf = vec(d[:, 2]), \n",
    "eta_unconverted_pos = vec(d[:, 3]),\n",
    "eta_converted_pos = vec(0.5 .+ 0.5*erf.(d[:, 3] / sqrt(2))),\n",
    "eta_unconverted_neg = vec(d[:, 4]),\n",
    "eta_converted_neg = vec(0.5 .+ 0.5*erf.(d[:, 4] / sqrt(2))),\n",
    "p_unconverted = vec(d[:, 5]),\n",
    "p_converted = vec(0.5 .+ 0.5*erf.(d[:, 5] / sqrt(2))))\n",
    "\n",
    "# save parameters to csv file\n",
    "CSV.write(\"subject_params.csv\", DataFrame(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save a copy with summary stats as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params[:,2:end]\n",
    "summary_stats = [summary_stats params]\n",
    "CSV.write(\"summary_stats.csv\", DataFrame(summary_stats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Generate trial by trial values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get best fit parameters from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if you already have best fit parameters saved, can read in here (rather than running model to find)\n",
    "params_full = readtable(\"subject_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run model for each sub using best fit parameters\n",
    "\n",
    "Note: must rerun model with it set to return trial data (uncomment this)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initialize parameter structures once again\n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# initalise this - will store all trial to trial parameters\n",
    "trial_data_compile = []\n",
    "\n",
    "# run model for each subject using best fit parameters\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = convert(Array, params[x, [:betamb, :beta_mf0, :beta_mf1, :eta_unconverted, :sticky]])\n",
    "    data_sub = df[df[:sub].==subs[x], :]\n",
    "    \n",
    "    # run model using these parameters - note must have commented in the model to return all of these variables (and not only -lik)\n",
    "    (minus_li, trial_data) = rl_model(betas_sub, data_sub)\n",
    "    \n",
    "    if x.==1\n",
    "        \n",
    "        trial_data_compile = trial_data\n",
    "        \n",
    "    else\n",
    "        \n",
    "        append!(trial_data_compile, trial_data)\n",
    "        \n",
    "    end\n",
    " \n",
    "end\n",
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(trial_data_compile))\n",
    "\n",
    "# print header of data compile\n",
    "head(trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save data to csv in model folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CSV.write(\"trial_data_compile.csv\", DataFrame(trial_data_compile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
