{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n",
    "#### Runs model, finds best fit params and then seperately extracts Q values etc. for each subject trial by trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up commands/load relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set everything up\n",
    "#parallel = true # Run on multiple CPUs. If you are having trouble, set parallel = false: easier to debug\n",
    "\n",
    "# this activates the multiprocessing threads\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "\taddprocs()\n",
    "end\n",
    "\n",
    "# load required libraries\n",
    "\n",
    "using DataFrames\n",
    "using ForwardDiff\n",
    "using PyCall\n",
    "using Distributions\n",
    "\n",
    "@everywhere PyCall.@pyimport scipy.optimize as so\n",
    "\n",
    "# this is the code for the actual fitting routines\n",
    "@everywhere include(\"em.jl\")\n",
    "@everywhere include(\"common.jl\")\n",
    "@everywhere include(\"likfuns.jl\")\n",
    "\n",
    "# this is generates starting matricies for betas, sigmas etc to feed into model\n",
    "@everywhere include(\"genVars.jl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in csv file of the data\n",
    "df = readtable(\"/Users/neil/Dropbox/Daw_Lab/TwoStepAversive/data/julia_raw_data_ex_19_25_26.csv\")\n",
    "\n",
    "# change states from 2,3 to 1,2; this allows you to use states as index to update relevant values based on states encountered\n",
    "df[:s] = df[:s]-1\n",
    "\n",
    "# display header\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model: \"full_learner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model used both MB and MF components\n",
    "# no seperate trace of Qvals for Pav trials\n",
    "# one learning rate for all trial types\n",
    "# note: First run model to generate best fit params for each subject (only -lik returned); then, \n",
    "# edit (get to return more than -lik) and run using best fit params to obtain trial by trial values (e.g. Q values, PEs etc.)\n",
    "            \n",
    "@everywhere function full_learner(params, data)\n",
    "\tbeta_mb = params[1]\n",
    "\tbeta_mf0 = params[2]\n",
    "    beta_mf1 = params[3]\n",
    "    lr = 0.5 + 0.5 * erf(params[4] / sqrt(2)) #some weird means of constraining learning rate. note that learning rate that pops out needs to be converted\n",
    "  \n",
    "    # perseveration/stickiness parameter\n",
    "    ps = params[5] \n",
    "        \n",
    "    c1 = data[:c1] # choice 1, 1 and 2 for left vs. right\n",
    "    r = data[:r] # coded as -1 and 1; note that here -1 is shock \n",
    "    s = data[:s] # stage 2 state, coded as 1 and 2 \n",
    "    t = data[:trial] # trial\n",
    "    sub = data[:sub] # subject number\n",
    "    \n",
    "    Q0 = zeros(typeof(beta_mb),2) # c1, left vs. right\n",
    "    Q0s2 = zeros(typeof(beta_mb),2) # values of stage 2 states\n",
    "    Q1 = zeros(typeof(beta_mb),2) #\n",
    "\tQm = zeros(typeof(beta_mb),2)\n",
    "\n",
    "    # initalise these (used to store trial by trial values)\n",
    "    trial_store = []\n",
    "    sub_store = []\n",
    "    \n",
    "    Q0_raw_left = []; Q0_raw_right = [];\n",
    "    Q1_raw_left = []; Q1_raw_right = [];\n",
    "    Q0s2_raw_left = []; Q0s2_raw_right = [];\n",
    "    \n",
    "    Q0_scaled_left = []; Q0_scaled_right = []; \n",
    "    Q1_scaled_left = []; Q1_scaled_right = [];\n",
    "    Q0s2_scaled_left = []; Q0s2_scaled_right = [];\n",
    "      \n",
    "    PE0_store = []; PE1_store = []; PES_store = [];\n",
    "        \n",
    "    # initialize likelihood\n",
    "    lik = 0 \n",
    "\n",
    "    # tracking previous choice to determine perseveration\n",
    "    prevc = 0 \n",
    "\n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        # store these on each trial        \n",
    "        append!(trial_store, t[i])\n",
    "        append!(sub_store, sub[i])\n",
    "        \n",
    "        # note that Q values are before update occurs on that trial (so can model choice based on existing Qvals)\n",
    "        append!(Q0_raw_left, Q0[1]); append!(Q0_raw_right, Q0[2])\n",
    "        append!(Q1_raw_left, Q1[1]); append!(Q1_raw_right, Q1[2])\n",
    "        append!(Q0s2_raw_left, Q0s2[1]); append!(Q0s2_raw_right, Q0s2[2])\n",
    "        \n",
    "        append!(Q0_scaled_left, lr^2.*Q0[1]); append!(Q0_scaled_right, lr^2.*Q0[2])\n",
    "        append!(Q1_scaled_left, lr.*Q1[1]); append!(Q1_scaled_right, lr.*Q1[2])\n",
    "        append!(Q0s2_scaled_left, lr.*Q0s2[1]); append!(Q0s2_scaled_right, lr.*Q0s2[2])\n",
    "        \n",
    "        if (c1[i]>0) # won't be the case for the pavlovian trials\n",
    "            \n",
    "            # calculate model-based component of Q values\n",
    "            # the Q for the ending states are usually given by roughly the maximum of the ending states\n",
    "            # Qm = [softmaximum(Q0[2,1],Q0[2,2]),softmaximum(Q0[3,1],Q0[3,2])]\n",
    "            \n",
    "\t\t\tQm = [Q0s2[1], Q0s2[2]] # or technically Qm = [.7*Q0[2] + .3*Q0[3],.3*Q0[2] + .7*Q0[3]]           \n",
    "            \n",
    "            # ultimately, the Q-values that determine the decision are a weighted combination of MB and MF values\n",
    "            # why only take Q0[1] and not both vals?\n",
    "            Qd = beta_mb.* Qm + beta_mf0.*(Q0) + beta_mf1.*(Q1)\n",
    "            \n",
    "            # plus perseveration bonus to last choice \n",
    "            # potentially consider different perseveration\n",
    "\t\t\tif prevc>0\n",
    "\t\t\t\tQd[prevc] += ps #increments Qd[prevc] by ps \n",
    "\t\t\tend\n",
    "            \n",
    "            # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "            # add that likelihood to the running likelihood\n",
    "\t\t\tlik += Qd[c1[i]] - log(sum(exp.(Qd)))\n",
    "            \n",
    "           # PE0_store = [PE0_store lr^2*(Q0[c1[i]]) - lr*Q0s2[s[i]]] \n",
    "           # PE1_store = [PE1_store lr^2*(Q1[c1[i]]) - lr*Q0s2[s[i]]]\n",
    "            #PE1_store = [PE1_store r[i] - lr*(Q1[c1[i]])] what about this?\n",
    "            \n",
    "            Q0[c1[i]] = (1-lr) * Q0[c1[i]] + Q0s2[s[i]] # TD0 \n",
    "            Q1[c1[i]] = (1-lr) * Q1[c1[i]] + r[i] # TD1\n",
    "            \n",
    "            prevc = c1[i]\n",
    "            \n",
    "            #PES_store = [PES_store lr*[0.7*Q0s2[c1[i]] + 0.3*Q0s2[abs(c1[i]-3)]] - lr*Q0s2[s[i]]]\n",
    "\n",
    "        else\n",
    "            \n",
    "           # cannot store for these - \n",
    "           # PE0_store = [PE0_store NaN]\n",
    "           # PE1_store = [PE1_store NaN]\n",
    "            \n",
    "           # PES_store = [PES_store lr*[0.5*Q0s2[1] + 0.5*Q0s2[2]] - lr*Q0s2[s[i]]]\n",
    "\n",
    "        end\n",
    "        \n",
    "\t\tQ0s2[s[i]] = (1-lr) * Q0s2[s[i]] + r[i]\n",
    "        \n",
    "\tend\n",
    "\n",
    "    trial_data = DataFrame([t, \n",
    "            sub_store,\n",
    "            c1,\n",
    "            s,  \n",
    "            r,\n",
    "            Q0_raw_left,\n",
    "            Q0_raw_right,\n",
    "            Q1_raw_left,\n",
    "            Q1_raw_right,\n",
    "            Q0s2_raw_left,\n",
    "            Q0s2_raw_right,\n",
    "            Q0_scaled_left,\n",
    "            Q0_scaled_right,\n",
    "            Q1_scaled_left,\n",
    "            Q1_scaled_right,\n",
    "            Q0s2_scaled_left,\n",
    "            Q0s2_scaled_right])\n",
    "    \n",
    "    # detail names of variables - frustrating this is neccesary\n",
    "    names!(trial_data,[:trial, \n",
    "            :sub,\n",
    "            :choice,\n",
    "            :state,\n",
    "            :reward,\n",
    "            :Q0_raw_left,\n",
    "            :Q0_raw_right,\n",
    "            :Q1_raw_left,\n",
    "            :Q1_raw_right,\n",
    "            :Q0s2_raw_left,\n",
    "            :Q0s2_raw_right,\n",
    "            :Q0_scaled_left,\n",
    "            :Q0_scaled_right,\n",
    "            :Q1_scaled_left,\n",
    "            :Q1_scaled_right,\n",
    "            :Q0s2_scaled_left,\n",
    "            :Q0s2_scaled_right])\n",
    "    \n",
    "    # here if running em you can only return the likelihood\n",
    "    return -lik\n",
    "    \n",
    "    # but if you run in order to extract trials, subs etc then want to return this\n",
    "    #return (-lik, trial_data)\n",
    "       \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model for one subject\n",
    "\n",
    "##### aids debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize parameter structures\n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# run model for sub 1\n",
    "full_learner(betas,df[df[:sub].==subs[1],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run em to get best fit parameters for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialized parameter structures (again)\n",
    "# note that some of the variables (e.g. betas, sigma) are entered and returned by em function \n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# run for full learner\n",
    "# x contains the parameters for each subject (note not the same as variable X)\n",
    "# l and h are per-subject likelihood and hessians\n",
    "@time (betas, sigma, x, l, h) = em(df, subs, X, betas, sigma, full_learner; emtol=1e-3, parallel=true, full=true, quiet=false);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Model Statistics \n",
    "#### (IAIC, LOOCV, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## model selection/comparison/scoring\n",
    "\n",
    "# laplace approximation to the aggregate log marginal likelihood of the whole dataset\n",
    "# marginalized over the individual params\n",
    "\n",
    "aggll = lml(x,l,h)\n",
    "\n",
    "# to compare this between models you need to correct for the group-level free parameters\n",
    "# either aic or bic\n",
    "\n",
    "aggll_ibic = ibic(x,l,h,betas,sigma,nrow(df))\n",
    "aggll_iaic = iaic(x,l,h,betas,sigma)\n",
    "\n",
    "# or you can compute unbiased per subject marginal likelihoods via subject-level cross validation\n",
    "# you can do paired t tests on these between models\n",
    "# these are also appropriate for SPM_BMS etc\n",
    "\n",
    "# takes ages so comment in when want to run, otherwise just use IAIC above\n",
    "\n",
    "liks = loocv(df, subs, x, X, betas, sigma, full_learner; emtol=1e-3, parallel=true, full=true)\n",
    "aggll_loo = sum(liks)\n",
    "\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll: $aggll_iaic\\nloo nll:  $aggll_loo\")\n",
    "println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write loocv scores to csv file\n",
    "\n",
    "#### (if you have run this part above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put loocv scores into dataframe\n",
    "loocv_scores = DataFrame(sub = subs,\n",
    "liks = vec(liks));\n",
    "\n",
    "# save loocv scores to csv file\n",
    "writetable(\"loocv_scores.csv\", DataFrame(loocv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write per subject model parameters to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put parameters into variable d\n",
    "d=x';\n",
    "\n",
    "# now put parameters into dataframe\n",
    "params_full = DataFrame(sub = subs,\n",
    "betamb = vec(d[:,1]), \n",
    "beta_mf0 = vec(d[:,2]),\n",
    "beta_mf1 = vec(d[:,3]),\n",
    "eta_unconverted = vec(d[:,4]),\n",
    "eta_converted = vec(0.5 + 0.5 * erf(d[:,4] / sqrt(2))),\n",
    "sticky = vec(d[:,5]));\n",
    "\n",
    "# save parameters to csv file\n",
    "writetable(\"subject_params_full_learner.csv\", DataFrame(params_full))\n",
    "\n",
    "#or: CSV.write(\"subject_params_full_learner.csv\",params_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run  model with these parameters for each subject to get trial by trial Q values\n",
    "##### Note: must rerun model with it set to return trial data (uncomment this)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you already have best fit parameters saved, can read in here (rather than running model to find)\n",
    "params_full = readtable(\"subject_params_full_learner.csv\")\n",
    "head(params_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run model for each sub using best fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize parameter structures once again\n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# initalise this - will store all trial to trial parameters\n",
    "trial_data_compile = []\n",
    "\n",
    "# run model for each subject using best fit parameters\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = Array(params_full[x, [:betamb, :beta_mf0, :beta_mf1, :eta_unconverted, :sticky]])\n",
    "    data_sub = df[df[:sub].==subs[x], :]\n",
    "    \n",
    "    # run model using these parameters - note must have commented in the model to return all of these variables (and not only -lik)\n",
    "    (minus_li, trial_data) = full_learner(betas_sub, data_sub)\n",
    "    \n",
    "    if x==1\n",
    "        \n",
    "        trial_data_compile = trial_data\n",
    "        \n",
    "    else\n",
    "        \n",
    "        append!(trial_data_compile, trial_data)\n",
    "        \n",
    "    end\n",
    " \n",
    " n\n",
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(trial_data_compile))\n",
    "\n",
    "# print header of data compile\n",
    "head(trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate out Q values for options encountered/not encountered and Q values for options choosen/not choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for encountered option Q values, index states 1 and 2\n",
    "index_s1 = find(trial_data_compile[:state].==1)\n",
    "index_s2 = find(trial_data_compile[:state].==2)\n",
    "\n",
    "index_encounter = [index_s1; index_s2]\n",
    "\n",
    "# now use indexes to pull out Qvalues for options encountered for Q0, Q1 and Qs (raw and scaled values)\n",
    "# note that state 1 corresponds to left and 2 to right. \n",
    "# therefore if state encountered is 1, then pick left Q value for Q value of the option encountered, \n",
    "# and right Q value for the option not encountered\n",
    "Q0_raw_encounter = [trial_data_compile[index_s1,:Q0_raw_left]; trial_data_compile[index_s2,:Q0_raw_right]]\n",
    "Q0_raw_NOTencounter = [trial_data_compile[index_s1,:Q0_raw_right]; trial_data_compile[index_s2,:Q0_raw_left]]\n",
    "trial_data_compile[:Q0_raw_encounter] = vcat(Q0_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q0_raw_NOTencounter] = vcat(Q0_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q1_raw_encounter = [trial_data_compile[index_s1,:Q1_raw_left]; trial_data_compile[index_s2,:Q1_raw_right]]\n",
    "Q1_raw_NOTencounter = [trial_data_compile[index_s1,:Q0_raw_left]; trial_data_compile[index_s2,:Q0_raw_right]]\n",
    "trial_data_compile[:Q1_raw_encounter] = vcat(Q1_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q1_raw_NOTencounter] = vcat(Q1_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q0s2_raw_encounter = [trial_data_compile[index_s1,:Q0s2_raw_left]; trial_data_compile[index_s2,:Q0s2_raw_right]]\n",
    "Q0s2_raw_NOTencounter = [trial_data_compile[index_s1,:Q0s2_raw_right]; trial_data_compile[index_s2,:Q0s2_raw_left]]\n",
    "trial_data_compile[:Q0s2_raw_encounter] = vcat(Q0s2_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q0s2_raw_NOTencounter] = vcat(Q0s2_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q0_scaled_encounter = [trial_data_compile[index_s1,:Q0_scaled_left]; trial_data_compile[index_s2,:Q0_scaled_right]] \n",
    "Q0_scaled_NOTencounter = [trial_data_compile[index_s1,:Q0_scaled_right]; trial_data_compile[index_s2,:Q0_scaled_left]] \n",
    "trial_data_compile[:Q0_scaled_encounter] = vcat(Q0_scaled_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q0_scaled_NOTencounter] = vcat(Q0_scaled_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q1_scaled_encounter = [trial_data_compile[index_s1,:Q1_scaled_left]; trial_data_compile[index_s2,:Q1_scaled_right]]\n",
    "Q1_scaled_NOTencounter = [trial_data_compile[index_s1,:Q1_scaled_right]; trial_data_compile[index_s2,:Q1_scaled_left]]\n",
    "trial_data_compile[:Q1_scaled_encounter] = vcat(Q1_scaled_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q1_scaled_NOTencounter] = vcat(Q1_scaled_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q0s2_scaled_encounter = [trial_data_compile[index_s1,:Q0s2_scaled_left]; trial_data_compile[index_s2,:Q0s2_scaled_right]]\n",
    "Q0s2_scaled_NOTencounter = [trial_data_compile[index_s1,:Q0s2_scaled_right]; trial_data_compile[index_s2,:Q0s2_scaled_left]]\n",
    "trial_data_compile[:Q0s2_scaled_encounter] = vcat(Q0s2_scaled_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q0s2_scaled_NOTencounter] = vcat(Q0s2_scaled_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "# for choosen option Q values, index choices 1 and 2 and 99 (so that length of columns is correct)\n",
    "index_c1 = find(trial_data_compile[:choice].==1)\n",
    "index_c2 = find(trial_data_compile[:choice].==2)\n",
    "index_c99 = find(trial_data_compile[:choice].==-99)\n",
    "\n",
    "index_choice = [index_c1; index_c2; index_c99]\n",
    "\n",
    "Q0_raw_choosen = [trial_data_compile[index_c1,:Q0_raw_left]; trial_data_compile[index_c2,:Q0_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q0_raw_NOTchoosen = [trial_data_compile[index_c1,:Q0_raw_right]; trial_data_compile[index_c2,:Q0_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q0_raw_choosen] = vcat(Q0_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q0_raw_NOTchoosen] = vcat(Q0_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "Q1_raw_choosen = [trial_data_compile[index_c1,:Q1_raw_left]; trial_data_compile[index_c2,:Q1_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q1_raw_NOTchoosen = [trial_data_compile[index_c1,:Q1_raw_right]; trial_data_compile[index_c2,:Q1_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q1_raw_choosen] = vcat(Q1_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q1_raw_NOTchoosen] = vcat(Q1_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "Q0s2_raw_choosen = [trial_data_compile[index_c1,:Q0s2_raw_left]; trial_data_compile[index_c2,:Q0s2_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q0s2_raw_NOTchoosen = [trial_data_compile[index_c1,:Q0s2_raw_right]; trial_data_compile[index_c2,:Q0s2_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q0s2_raw_choosen] = vcat(Q0s2_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q0s2_raw_NOTchoosen] = vcat(Q0s2_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "#replace -99 choices with NaNs for Q values choosen/not choosen\n",
    "trial_data_compile[find(trial_data_compile[:choice].==-99), [:Q0_raw_choosen, :Q0_raw_NOTchoosen, :Q1_raw_choosen, :Q1_raw_NOTchoosen, :Q0s2_raw_choosen, :Q0s2_raw_NOTchoosen]] = NaN\n",
    "\n",
    "head(trial_data_compile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate probabilities of choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate probability of chosen and unchosen from Q values \n",
    "\n",
    "ProbChosen_ALL = []\n",
    "ProbUnchosen_ALL =  []\n",
    "ProbChosen_minus_Unchosen_ALL = []\n",
    "\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "    \n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = Array(params_full[x, [:betamb, :beta_mf0, :beta_mf1, :eta_unconverted, :sticky]])\n",
    "    \n",
    "    beta_MB = betas_sub[1] #beta MB\n",
    "    betas_MF0 = betas_sub[2] #beta MF0\n",
    "    betas_MF1 = betas_sub[3] #beta MF1\n",
    "    betas_lr = betas_sub[4] #beta lr\n",
    "    betas_stick = betas_sub[5] #sticky\n",
    "        \n",
    "    subset_data = trial_data_compile[trial_data_compile[:sub].==subs[x], :]\n",
    "    \n",
    "    n_trials = size(subset_data); n_trials = n_trials[1]\n",
    "\n",
    "    ProbChosen = zeros(n_trials)\n",
    "    ProbUnchosen = zeros(n_trials)\n",
    "    ProbChosen_minus_Unchosen = zeros(n_trials)\n",
    "    \n",
    "    choices = subset_data[:choice]\n",
    "    Q0select = subset_data[:Q0_raw_choosen]\n",
    "    Q0NOTselect = subset_data[:Q0_raw_NOTchoosen] \n",
    "    Q1select = subset_data[:Q1_raw_choosen]\n",
    "    Q1NOTselect = subset_data[:Q1_raw_NOTchoosen] \n",
    "    QSselect = subset_data[:Q0s2_raw_choosen]\n",
    "    QSNOTselect = subset_data[:Q0s2_raw_NOTchoosen] \n",
    "    \n",
    "    prev_choice = NaN;\n",
    "    \n",
    "    for t = 1:n_trials\n",
    "    \n",
    "        curr_choice = choices[t]\n",
    "        \n",
    "        #if not a pav trial \n",
    "        if curr_choice>0\n",
    "            \n",
    "            #if first choice (note first trial will be pav, missed responses already taken out) \n",
    "            #then do not include sticky parameter into softmax\n",
    "            if n_trials == 2\n",
    "                ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t])) \n",
    "                ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                prev_choice = curr_choice\n",
    "                \n",
    "            #if not the first choice then do not include sticky parameter into softmax    \n",
    "            elseif n_trials > 2\n",
    "                \n",
    "                # where sticky param is added depends whether the current choice equals the current choice\n",
    "                # if it is then add into the chosen probability\n",
    "                if curr_choice==prev_choice\n",
    "                    ProbChosen[t] = exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) \n",
    "                        + betas_stick)/(exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + betas_stick) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t])) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t];\n",
    "                    prev_choice = curr_choice;\n",
    "                # if it is then add into the not chosen probability\n",
    "                elseif curr_choice!=prev_choice\n",
    "                    ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + exp((betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t]) + betas_stick)) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                    prev_choice = curr_choice;\n",
    "                end\n",
    "                \n",
    "            end\n",
    "                \n",
    "        else\n",
    "            ProbChosen[t]  = NaN;\n",
    "            ProbUnchosen[t] = NaN;\n",
    "            ProbChosen_minus_Unchosen[t] = NaN;\n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    ProbChosen_ALL = [ProbChosen_ALL; ProbChosen]\n",
    "    ProbUnchosen_ALL = [ProbUnchosen_ALL; ProbUnchosen]\n",
    "    ProbChosen_minus_Unchosen_ALL = [ProbChosen_minus_Unchosen_ALL; ProbChosen_minus_Unchosen]\n",
    "    \n",
    "end\n",
    "\n",
    "#Now bung into data frame and merge with rest\n",
    "Q_probs = DataFrame([ProbChosen_ALL, \n",
    "        ProbUnchosen_ALL, \n",
    "        ProbChosen_minus_Unchosen_ALL]) \n",
    "\n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_probs, [:ProbChosen, \n",
    "        :ProbUnchosen, \n",
    "        :ProbChosen_minus_Unchosen])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous full compile)\n",
    "trial_data_compile = hcat(trial_data_compile, Q_probs); #could also do just: [full_Q_compile Q_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head(trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to csv in model folder\n",
    "##### NOTE: after this note you must save as an xlsx file to run in matlab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writetable(\"full_learner_Qvalues.csv\", DataFrame(trial_data_compile))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
