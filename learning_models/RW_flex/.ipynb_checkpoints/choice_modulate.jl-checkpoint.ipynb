{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start up commands/load relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel = true # Run on multiple CPUs. If you are having trouble, set parallel = false: easier to debug\n",
    "full = false    # Maintain full covariance matrix (vs a diagional one) at the group level\n",
    "emtol = 1e-3    # stopping condition (relative change) for EM\n",
    "\n",
    "using Distributed\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "\taddprocs()\n",
    "end\n",
    "\n",
    "# this loads the packages needed -- the @everywhere makes sure they \n",
    "# available on all CPUs \n",
    "\n",
    "@everywhere using DataFrames\n",
    "@everywhere using SharedArrays\n",
    "@everywhere using ForwardDiff\n",
    "@everywhere using Optim\n",
    "@everywhere using LinearAlgebra       # for tr, diagonal\n",
    "@everywhere using StatsFuns           # logsumexp\n",
    "@everywhere using SpecialFunctions    # for erf\n",
    "@everywhere using Statistics          # for mean\n",
    "@everywhere using Distributions\n",
    "@everywhere using GLM\n",
    "@everywhere using CSV #for reading/writing csv files\n",
    "\n",
    "# change this to where you keep the Daw's latest em code\n",
    "@everywhere directory = \"/Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/em\"\n",
    "\n",
    "#load in functions including em\n",
    "@everywhere include(\"$directory/em.jl\");\n",
    "@everywhere include(\"$directory/common.jl\");\n",
    "@everywhere include(\"$directory/likfuns.jl\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data read and process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: readtable is deprecated, use CSV.read from the CSV package instead\n",
      "│   caller = top-level scope at In[2]:1\n",
      "└ @ Core In[2]:1\n",
      "┌ Warning: `a::AbstractArray + b::Number` is deprecated, use `a .+ b` instead.\n",
      "│   caller = top-level scope at In[2]:10\n",
      "└ @ Core In[2]:10\n",
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[2]:22\n",
      "└ @ Core In[2]:22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>participantID</th><th>block_n</th><th>trials</th><th>blockType</th><th>forcedTrial</th><th>gem_presented</th><th>market_presented</th><th>door_side</th><th>chooseLeft</th><th>outcomeState</th><th>outcome</th><th>ons_fixation</th><th>ons_door_display</th><th>ons_responsecue</th><th>ons_gem_fixation</th><th>ons_outcome_display</th><th>ons_condition_text</th><th>ons_trigger</th><th>missed_trial</th><th>rew_loss</th><th>rt</th><th>prob_market_presented</th><th>correct_choice</th><th>market_reversal</th><th>pick_black</th><th>black_presented_force</th><th>prob_independent_1</th><th>prob_independent_2</th><th>prob_dependent</th><th>blackFirst</th><th>gem_colour</th><th>sub</th><th>state_chosen</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64</th><th>Int64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Integer</th></tr></thead><tbody><p>6 rows × 33 columns</p><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1.0</td><td>2</td><td>0.0</td><td>12435.6</td><td>12440.7</td><td>12443.7</td><td>12445.3</td><td>12448.1</td><td>12432.6</td><td>NaN</td><td>0</td><td>1</td><td>0.658662</td><td>0.8</td><td>NaN</td><td>0</td><td>1.0</td><td>1.0</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>2</td><td>1</td><td>1</td></tr><tr><th>2</th><td>1</td><td>1</td><td>2</td><td>1</td><td>0</td><td>2</td><td>1</td><td>2</td><td>1.0</td><td>1</td><td>-1.0</td><td>12450.1</td><td>12452.6</td><td>12456.1</td><td>12457.6</td><td>12461.8</td><td>NaN</td><td>NaN</td><td>0</td><td>-1</td><td>0.599319</td><td>0.8</td><td>0.0</td><td>0</td><td>1.0</td><td>NaN</td><td>0.2</td><td>0.8</td><td>0.8</td><td>-1</td><td>2</td><td>1</td><td>1</td></tr><tr><th>3</th><td>1</td><td>1</td><td>3</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1.0</td><td>2</td><td>0.0</td><td>12463.8</td><td>12466.4</td><td>12468.2</td><td>12469.8</td><td>12474.8</td><td>NaN</td><td>NaN</td><td>0</td><td>1</td><td>0.781297</td><td>0.8</td><td>NaN</td><td>0</td><td>1.0</td><td>1.0</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>2</td><td>1</td><td>1</td></tr><tr><th>4</th><td>1</td><td>1</td><td>4</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1.0</td><td>2</td><td>0.0</td><td>12476.8</td><td>12481.7</td><td>12484.1</td><td>12485.6</td><td>12488.7</td><td>NaN</td><td>NaN</td><td>0</td><td>-1</td><td>0.889409</td><td>0.8</td><td>1.0</td><td>0</td><td>2.0</td><td>NaN</td><td>0.2</td><td>0.8</td><td>0.8</td><td>-1</td><td>4</td><td>1</td><td>2</td></tr><tr><th>5</th><td>1</td><td>1</td><td>5</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1.0</td><td>1</td><td>-1.0</td><td>12490.7</td><td>12494.0</td><td>12496.4</td><td>12497.9</td><td>12501.1</td><td>NaN</td><td>NaN</td><td>0</td><td>-1</td><td>0.389441</td><td>0.8</td><td>NaN</td><td>0</td><td>1.0</td><td>1.0</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>4</td><td>1</td><td>1</td></tr><tr><th>6</th><td>1</td><td>1</td><td>6</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>0.0</td><td>1</td><td>-1.0</td><td>12503.1</td><td>12509.0</td><td>12512.2</td><td>12513.8</td><td>12517.5</td><td>NaN</td><td>NaN</td><td>0</td><td>-1</td><td>0.302638</td><td>0.8</td><td>NaN</td><td>0</td><td>2.0</td><td>0.0</td><td>0.2</td><td>0.8</td><td>0.8</td><td>-1</td><td>4</td><td>1</td><td>2</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccccccccccccccccccccccccc}\n",
       "\t& participantID & block\\_n & trials & blockType & forcedTrial & gem\\_presented & market\\_presented & door\\_side & chooseLeft & outcomeState & outcome & ons\\_fixation & ons\\_door\\_display & ons\\_responsecue & ons\\_gem\\_fixation & ons\\_outcome\\_display & ons\\_condition\\_text & ons\\_trigger & missed\\_trial & rew\\_loss & rt & prob\\_market\\_presented & correct\\_choice & market\\_reversal & pick\\_black & black\\_presented\\_force & prob\\_independent\\_1 & prob\\_independent\\_2 & prob\\_dependent & blackFirst & gem\\_colour & sub & state\\_chosen\\\\\n",
       "\t\\hline\n",
       "\t& Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64 & Int64⍰ & Float64⍰ & Int64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Int64⍰ & Int64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Int64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Integer\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & 1 & 2 & 1 & 1 & 1.0 & 2 & 0.0 & 12435.6 & 12440.7 & 12443.7 & 12445.3 & 12448.1 & 12432.6 & NaN & 0 & 1 & 0.658662 & 0.8 & NaN & 0 & 1.0 & 1.0 & 0.2 & 0.8 & 0.8 & 1 & 2 & 1 & 1 \\\\\n",
       "\t2 & 1 & 1 & 2 & 1 & 0 & 2 & 1 & 2 & 1.0 & 1 & -1.0 & 12450.1 & 12452.6 & 12456.1 & 12457.6 & 12461.8 & NaN & NaN & 0 & -1 & 0.599319 & 0.8 & 0.0 & 0 & 1.0 & NaN & 0.2 & 0.8 & 0.8 & -1 & 2 & 1 & 1 \\\\\n",
       "\t3 & 1 & 1 & 3 & 1 & 1 & 2 & 1 & 1 & 1.0 & 2 & 0.0 & 12463.8 & 12466.4 & 12468.2 & 12469.8 & 12474.8 & NaN & NaN & 0 & 1 & 0.781297 & 0.8 & NaN & 0 & 1.0 & 1.0 & 0.2 & 0.8 & 0.8 & 1 & 2 & 1 & 1 \\\\\n",
       "\t4 & 1 & 1 & 4 & 1 & 0 & 1 & 1 & 1 & 1.0 & 2 & 0.0 & 12476.8 & 12481.7 & 12484.1 & 12485.6 & 12488.7 & NaN & NaN & 0 & -1 & 0.889409 & 0.8 & 1.0 & 0 & 2.0 & NaN & 0.2 & 0.8 & 0.8 & -1 & 4 & 1 & 2 \\\\\n",
       "\t5 & 1 & 1 & 5 & 1 & 1 & 1 & 1 & 1 & 1.0 & 1 & -1.0 & 12490.7 & 12494.0 & 12496.4 & 12497.9 & 12501.1 & NaN & NaN & 0 & -1 & 0.389441 & 0.8 & NaN & 0 & 1.0 & 1.0 & 0.2 & 0.8 & 0.8 & 1 & 4 & 1 & 1 \\\\\n",
       "\t6 & 1 & 1 & 6 & 1 & 1 & 1 & 1 & 2 & 0.0 & 1 & -1.0 & 12503.1 & 12509.0 & 12512.2 & 12513.8 & 12517.5 & NaN & NaN & 0 & -1 & 0.302638 & 0.8 & NaN & 0 & 2.0 & 0.0 & 0.2 & 0.8 & 0.8 & -1 & 4 & 1 & 2 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×33 DataFrame. Omitted printing of 28 columns\n",
       "│ Row │ participantID │ block_n │ trials │ blockType │ forcedTrial │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m        │ \u001b[90mInt64⍰\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m    │ \u001b[90mInt64⍰\u001b[39m      │\n",
       "├─────┼───────────────┼─────────┼────────┼───────────┼─────────────┤\n",
       "│ 1   │ 1             │ 1       │ 1      │ 1         │ 1           │\n",
       "│ 2   │ 1             │ 1       │ 2      │ 1         │ 0           │\n",
       "│ 3   │ 1             │ 1       │ 3      │ 1         │ 1           │\n",
       "│ 4   │ 1             │ 1       │ 4      │ 1         │ 0           │\n",
       "│ 5   │ 1             │ 1       │ 5      │ 1         │ 1           │\n",
       "│ 6   │ 1             │ 1       │ 6      │ 1         │ 1           │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data\n",
    "df = readtable(\"/Users/Neil/GitHubRepo/Projects/ValueInference/study4_mri/data/gem_dat.csv\")\n",
    "\n",
    "#get rid of missed responses\n",
    "df = df[df[:missed_trial].!=1,:]\n",
    "\n",
    "#add \"sub column\" \n",
    "# this is just a replica of the existing column sub_no but I think em looks for \"sub\" specifically\n",
    "df[:sub] = df[:participantID];\n",
    "\n",
    "#change coding so that 1 = market 1 in dependent condition,\n",
    "#2 and 3 refer to the two markets in the independent condition\n",
    "df[:market_presented] = df[:market_presented] + 1\n",
    "df[df[:blockType].==1,:market_presented] = 1\n",
    "\n",
    "#code picking white as 2, picking black as 1\n",
    "df[:state_chosen] = df[:pick_black]\n",
    "df[df[:state_chosen].==0, :state_chosen] = 2\n",
    "\n",
    "#convert this so can use in model\n",
    "df[:state_chosen] = convert(Vector{Integer}, df[:state_chosen])\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exlude subs 21 and 28..\n",
    "\n",
    "df = df[df[:participantID].!=21,:];\n",
    "df = df[df[:participantID].!=28,:];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use recoded condition variable in the model\n",
    "df[:condition_recode] = df[:blockType]\n",
    "df[df[:condition_recode].==2,:condition_recode] = -1\n",
    "\n",
    "#now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function rl_model(params, data)\n",
    "    \n",
    "    #model parameteres\n",
    "\tbeta_mb = params[1] \n",
    "    w_slope = params[2]\n",
    "    lr =  0.5 .+ 0.5.*erf(params[3]/sqrt(2))\n",
    "    \n",
    "    c1 = data[:state_chosen] # choice: 1 = black door, 2 = white door\n",
    "    r = data[:outcome] # outcome: coded as +1 = gain, -1 = loss, 0 = neutral \n",
    "    s = data[:outcomeState] # stage 2 state: coded as 1 = gain/loss state reached, 2 = neutral state reached\n",
    "    t = data[:trials] # trial number\n",
    "    sub = data[:sub] # subject number\n",
    "    condition = data[:condition_recode] # condition: 1 = dependent, -1=independent\n",
    "    gem = data[:gem_presented] #gem presented\n",
    "    market = data[:market_presented] #market presented\n",
    "    reward_loss_trial = data[:rew_loss]\n",
    "    force_t = data[:forcedTrial]\n",
    "    block_n = data[:block_n]\n",
    "    blackFirst = data[:blackFirst]\n",
    "    \n",
    "    SR_m = zeros(typeof(beta_mb), 2) .+ 0.5 #initalise to 0.5. stores estimates of transition probabilities for black/white door going to reward/loss state \n",
    "    SR_gem = zeros(typeof(beta_mb), 4) .+ 0.5 #initalise to 0.5. stores estimates of transition probabilities for black/white door going to reward/loss state \n",
    "   \n",
    "\tQmb = zeros(typeof(beta_mb), 2) #decision variable\n",
    "    Qmb_gem = zeros(typeof(beta_mb), 2) #decision variable\n",
    "    \n",
    "    #encode in the frame of getting to the rl state\n",
    "    prob_rl_chosen_m = [];\n",
    "    prob_rl_unchosen_m = [];\n",
    "    prob_rl_doorpresented_m = [];\n",
    "\n",
    "    ev_rl_chosen_m = [];\n",
    "    ev_rl_unchosen_m = [];\n",
    "    ev_rl_doorpresented_m = [];\n",
    "    \n",
    "    prob_rl_chosen_gem = [];\n",
    "    prob_rl_unchosen_gem = [];\n",
    "    prob_rl_doorpresented_gem = [];\n",
    "\n",
    "    ev_rl_chosen_gem = [];\n",
    "    ev_rl_unchosen_gem = [];\n",
    "    ev_rl_doorpresented_gem = [];\n",
    "    \n",
    "    SPE_m_compile_signed = [];\n",
    "    SPE_m_compile_abs = [];\n",
    "    SPE_gem_compile_signed = [];\n",
    "    SPE_gem_compile_abs = [];\n",
    "    \n",
    "    EV_combined_compile = [];\n",
    "    prob_combined_rl_chosen_compile = [];\n",
    "    \n",
    "    good_bad_compile = [];\n",
    "    \n",
    "    # initialize likelihood\n",
    "    lik = 0 \n",
    "    \n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        w_raw = -1*w_slope*(condition[i])\n",
    "\n",
    "        if gem[i]<3\n",
    "            index = 1            \n",
    "        else\n",
    "            index = 2\n",
    "        end\n",
    "        \n",
    "        w = 0.5 .+ 0.5.*erf(w_raw/sqrt(2))\n",
    "                \n",
    "        Qmb = [SR_m[index].*reward_loss_trial[i], (1-SR_m[index]).*reward_loss_trial[i]]\n",
    "        Qmb_gem = [SR_gem[gem[i]].*reward_loss_trial[i], (1-SR_gem[gem[i]]).*reward_loss_trial[i]]\n",
    "       \n",
    "        tmp_a = (1-w).*Qmb + w.*Qmb_gem\n",
    "        tmp_b = (1-w).*[SR_m[index], (1-SR_m[index])] + w.*[SR_gem[gem[i]], (1-SR_gem[gem[i]])]\n",
    "        \n",
    "        if (c1[i]==1)\n",
    "            append!(prob_rl_chosen_m, SR_m[index]); append!(prob_rl_unchosen_m, 1-SR_m[index]);\n",
    "            append!(prob_rl_chosen_gem, SR_gem[gem[i]]); append!(prob_rl_unchosen_gem, 1-SR_gem[gem[i]]);\n",
    "            append!(ev_rl_chosen_m, Qmb[1]); append!(ev_rl_unchosen_m, Qmb[2]);    \n",
    "            append!(ev_rl_chosen_gem, Qmb_gem[1]); append!(ev_rl_unchosen_gem, Qmb_gem[2]); \n",
    "            append!(EV_combined_compile, tmp_a[1]); \n",
    "            append!(prob_combined_rl_chosen_compile, tmp_b[1]); \n",
    "            \n",
    "        elseif (c1[i]==2)\n",
    "            append!(prob_rl_chosen_m, 1-SR_m[index]); append!(prob_rl_unchosen_m, SR_m[index]);\n",
    "            append!(prob_rl_chosen_gem, 1-SR_gem[gem[i]]); append!(prob_rl_unchosen_gem, SR_gem[gem[i]]);    \n",
    "            append!(ev_rl_chosen_m, Qmb[2]); append!(ev_rl_unchosen_m, Qmb[1]);  \n",
    "            append!(ev_rl_chosen_gem, Qmb_gem[2]); append!(ev_rl_unchosen_gem, Qmb_gem[1]);\n",
    "            append!(EV_combined_compile, tmp_a[2]); \n",
    "            append!(prob_combined_rl_chosen_compile, tmp_b[2]); \n",
    "            \n",
    "        end\n",
    "        \n",
    "        if (blackFirst[i]==1)\n",
    "            append!(prob_rl_doorpresented_m, SR_m[index]); \n",
    "            append!(prob_rl_doorpresented_gem, SR_gem[gem[i]]); \n",
    "            append!(ev_rl_doorpresented_m, SR_m[index].*reward_loss_trial[i]); \n",
    "            append!(ev_rl_doorpresented_gem, SR_gem[gem[i]].*reward_loss_trial[i]); \n",
    "        elseif (blackFirst[i]==-1)\n",
    "            append!(prob_rl_doorpresented_m, 1-SR_m[index]); \n",
    "            append!(prob_rl_doorpresented_gem, 1-SR_gem[gem[i]]);\n",
    "            append!(ev_rl_doorpresented_m, (1-SR_m[index]).*reward_loss_trial[i]); \n",
    "            append!(ev_rl_doorpresented_gem, (1-SR_gem[gem[i]]).*reward_loss_trial[i]);             \n",
    "        end\n",
    "            \n",
    "        # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "        # add that likelihood to the running likelihood\n",
    "        #only implement for force trials\n",
    "        if (force_t[i] == 0)\n",
    "            \n",
    "            #Q-values that determine the decision\n",
    "            Q_combined = (1-w).*Qmb + w.*Qmb_gem\n",
    "            Qd = beta_mb.*Q_combined\n",
    "            \n",
    "            lik += Qd[c1[i]] .- log(sum(exp.(Qd)))\n",
    "            \n",
    "        else\n",
    "        end\n",
    "\n",
    "        # updates go in here - these are updates of probability estimates (not contingent on outcome)\n",
    "        if (s[i]==1 & c1[i]==1)\n",
    "            SPE_m = 1 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*1\n",
    "            SPE_gem = 1 - SR_gem[gem[i]]\n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*1\n",
    "        elseif (s[i]==2 & c1[i]==2)\n",
    "            SPE_m = 1 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*1\n",
    "            SPE_gem = 1 - SR_gem[gem[i]]           \n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*1\n",
    "        else\n",
    "            SPE_m = 0 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*0\n",
    "            SPE_gem = 0 - SR_gem[gem[i]]            \n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*0\n",
    "        end\n",
    "        \n",
    "        append!(SPE_m_compile_signed, SPE_m); \n",
    "        append!(SPE_m_compile_abs, abs(SPE_m));    \n",
    "        append!(SPE_gem_compile_signed, SPE_gem);    \n",
    "        append!(SPE_gem_compile_abs, abs(SPE_gem));\n",
    "        \n",
    "        if (r[i]==1)\n",
    "            good_bad = 1\n",
    "        elseif (r[i]==-1)\n",
    "            good_bad = -1\n",
    "        elseif (r[i]==0) & (reward_loss_trial[i]==1)\n",
    "            good_bad = -1\n",
    "        elseif (r[i]==0) & (reward_loss_trial[i]==-1)\n",
    "            good_bad = 1\n",
    "        end\n",
    "        \n",
    "          append!(good_bad_compile, good_bad); \n",
    "\n",
    "\tend\n",
    "    \n",
    "    #compile trial by trial values here\n",
    "    trial_data = DataFrame(trial = t,\n",
    "    sub = sub,\n",
    "    block_n = block_n,\n",
    "    choice = c1,\n",
    "    outcomeState = s,\n",
    "    outcome = r,\n",
    "    gem = gem,\n",
    "    condition = condition,\n",
    "    market = market,\n",
    "    force_t = force_t,\n",
    "    prob_rl_chosen_m = prob_rl_chosen_m,\n",
    "    prob_rl_unchosen_m = prob_rl_unchosen_m,\n",
    "    ev_rl_chosen_m = ev_rl_chosen_m,\n",
    "    ev_rl_unchosen_m = ev_rl_unchosen_m,\n",
    "    prob_rl_chosen_gem = prob_rl_chosen_gem,\n",
    "    prob_rl_unchosen_gem = prob_rl_unchosen_gem,\n",
    "    ev_rl_chosen_gem =ev_rl_chosen_gem,\n",
    "    ev_rl_unchosen_gem = ev_rl_unchosen_gem,\n",
    "    SPE_m_compile_signed = SPE_m_compile_signed,\n",
    "    SPE_m_compile_abs = SPE_m_compile_abs,\n",
    "    SPE_gem_compile_signed = SPE_gem_compile_signed,\n",
    "    SPE_gem_compile_abs = SPE_gem_compile_abs,\n",
    "    EV_combined = EV_combined_compile,\n",
    "    prob_rl_chosen_combined = prob_combined_rl_chosen_compile,\n",
    "    prob_rl_doorpresented_m = prob_rl_doorpresented_m,\n",
    "        prob_rl_doorpresented_gem = prob_rl_doorpresented_gem,\n",
    "        ev_rl_doorpresented_m = ev_rl_doorpresented_m,\n",
    "        ev_rl_doorpresented_gem = ev_rl_doorpresented_gem,\n",
    "    good_bad = good_bad_compile)\n",
    "\n",
    "    # here if running em you can only return the likelihood\n",
    "    #return -lik\n",
    "    return (-lik, trial_data)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup variables for em\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#store list of actual subject numbers (in subj)\n",
    "subs = unique(df[:participantID])\n",
    "\n",
    "#put in a new column called \"sub\" which is identical to subj - em looks for this\n",
    "df[:sub] = df[:participantID];\n",
    "\n",
    "NS = length(subs)\n",
    "X = ones(NS)\n",
    "betas = [0. 0. 0.]\n",
    "sigma = [1., 1., 1.];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run em to get best fit parameters for each subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 91\n",
      "betas: [1.55 1.31 -0.16]\n",
      "sigma: [0.39, 0.12, 0.51]\n",
      "free energy: -1368.100213\n",
      "change: [3.3e-5, 0.000519, -0.000209, 0.000133, 0.000976, 3.6e-5]\n",
      "max: 0.000976\n"
     ]
    }
   ],
   "source": [
    "# run em\n",
    "# x contains the parameters for each subject (note not the same as variable X)\n",
    "# l and h are per-subject likelihood and hessians\n",
    "(betas, sigma, x, l, h) = em(df, subs, X, betas, sigma, rl_model; emtol=emtol, parallel=parallel, full=full);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341.407367279341"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggll_iaic = iaic(x, l, h, betas, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Model Statistics \n",
    "(LOOCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 1..2..3..4..5..6..7..8..9..10..11..12..13..14..15..16..17..18..19..20..21..22..23..24..25..26..27..28..29..1339.5228078278947"
     ]
    }
   ],
   "source": [
    "\n",
    "#compute unbiased per subject marginal likelihoods via cross validation.\n",
    "liks = loocv(df, subs, x, X, betas, sigma, rl_model; emtol=emtol, parallel=parallel, full=full)\n",
    "\n",
    "print(sum(liks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write loocv scores to csv file and save\n",
    "\n",
    "(if you have run loocv above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"loocv_scores.csv\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#put loocv scores into dataframe\n",
    "loocv_scores = DataFrame(sub = subs,\n",
    "liks = vec(liks));\n",
    "\n",
    "CSV.write(\"loocv_scores.csv\", DataFrame(loocv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and write p values, std error and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# standard errors on the subject-level means, based on an asymptotic Gaussian approx \n",
    "# (these may be inflated esp for small n)\n",
    "(standarderrors, pvalues, covmtx) = emerrors(df, subs, x, X, h, betas, sigma, rl_model);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_stats = DataFrame(stderror = vec(standarderrors),\n",
    "pvalues = vec(pvalues),\n",
    "covmtx_1 = vec(covmtx[:,1]),\n",
    "covmtx_2 = vec(covmtx[:,2]),\n",
    "covmtx_3 = vec(covmtx[:,3]));\n",
    "\n",
    "# save model stats to csv file\n",
    "CSV.write(\"model_stats.csv\", DataFrame(model_stats));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write per subject model parameters to csv files and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"subject_params.csv\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# put parameters into variable d\n",
    "d=x;\n",
    "\n",
    "# now put parameters into dataframe\n",
    "params = DataFrame(sub = subs,\n",
    "slope = vec(d[:,1]), \n",
    "w_slope_unconverte= vec(d[:,2]),\n",
    "lr_unconverted = vec(d[:, 3]));\n",
    "\n",
    "CSV.write(\"subject_params.csv\", DataFrame(params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract trial by trial values and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Deprecated syntax `implicit assignment to global variable `x``.\n",
      "│ Use `global x` instead.\n",
      "└ @ nothing none:0\n",
      "┌ Warning: Loop variable `x` around In[18]:6 overwrites a variable in an enclosing scope. In the future the variable will be local to the loop instead.\n",
      "└ @ nothing In[18]:6\n",
      "┌ Warning: `convert(::Type{Array}, dfr::DataFrameRow)` is deprecated, use `permutedims(Vector(dfr))` instead.\n",
      "│   caller = top-level scope at In[18]:12\n",
      "└ @ Core ./In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9094, 34)(9094, 29)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[18]:32\n",
      "└ @ Core In[18]:32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"trial_by_trial_vals.csv\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize parameter structures once again\n",
    "#(df, subs, X, betas, sigma) = genVars(df, 3);\n",
    "\n",
    "# initalise this - will store all trial to trial parameters\n",
    "trial_data_compile = [];\n",
    "\n",
    "# run model for each subject using best fit parameters\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = convert(Array, params[x, [:slope, :w_slope_unconverte, :lr_unconverted]])\n",
    "    data_sub = df[df[:sub].==subs[x], :]\n",
    "    \n",
    "    # run model using these parameters - note must have commented in the model to return all of these variables (and not only -lik)\n",
    "    (minus_li, trial_data) = rl_model(betas_sub, data_sub)\n",
    "    \n",
    "    if x.==1\n",
    "        \n",
    "        trial_data_compile = trial_data\n",
    "        \n",
    "    else\n",
    "        \n",
    "        append!(trial_data_compile, trial_data)\n",
    "        \n",
    "    end\n",
    " \n",
    "end\n",
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(trial_data_compile))\n",
    "    \n",
    "# print header of data compile\n",
    "head(trial_data_compile)\n",
    "\n",
    "CSV.write(\"trial_by_trial_vals.csv\", DataFrame(trial_data_compile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
