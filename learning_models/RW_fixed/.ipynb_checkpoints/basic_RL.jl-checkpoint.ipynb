{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Start up commands/load relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling CSV [336ed68f-0bac-5ca0-87d4-7b16caf5d00b]\n",
      "└ @ Base loading.jl:1187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 4:\t┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "      From worker 4:\t│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "      From worker 4:\t└ @ Base loading.jl:941\n",
      "      From worker 5:\t┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "      From worker 5:\t│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "      From worker 5:\t└ @ Base loading.jl:941\n",
      "      From worker 3:\t┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "      From worker 3:\t│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "      From worker 3:\t└ @ Base loading.jl:941\n",
      "      From worker 2:\t┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "      From worker 2:\t│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "      From worker 2:\t└ @ Base loading.jl:941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:941\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:299\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/common.jl:67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17\n",
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17\n",
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17\n",
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17\n",
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17.\n",
      "└ @ ~/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/genVars.jl:17\n"
     ]
    }
   ],
   "source": [
    "# load required libraries\n",
    "using Distributed\n",
    "\n",
    "# # set everything up\n",
    "parallel = true # Run on multiple CPUs. If youhttp://localhost:8888/notebooks/Dropbox/Daw_Lab/PreySelection/v103/models/model_subjective1beta2lr_delayreward/model_subjective1beta2lr_delayreward.jl.ipynb# are having trouble, set parallel = false: easier to debug\n",
    "\n",
    "# this activates the multiprocessing threads\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "    addprocs(4)\n",
    "end\n",
    "\n",
    "# load required libraries\n",
    "@everywhere using DataFrames\n",
    "@everywhere using ForwardDiff\n",
    "@everywhere using PyCall\n",
    "@everywhere using Distributions\n",
    "@everywhere using PyPlot\n",
    "@everywhere using CSV\n",
    "@everywhere using SpecialFunctions\n",
    "@everywhere using SharedArrays\n",
    "@everywhere using LinearAlgebra\n",
    "\n",
    "@everywhere PyCall.@pyimport scipy.optimize as so\n",
    "\n",
    "# this is the code for the actual fitting routines\n",
    "@everywhere include(\"em.jl\")\n",
    "@everywhere include(\"common.jl\")\n",
    "@everywhere include(\"likfuns.jl\")\n",
    "\n",
    "# this is generates starting matricies for betas, sigmas etc to feed into model\n",
    "@everywhere include(\"genVars.jl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data read and process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: readtable is deprecated, use CSV.read from the CSV package instead\n",
      "│   caller = top-level scope at In[2]:1\n",
      "└ @ Core In[2]:1\n",
      "┌ Warning: `a::AbstractArray - b::Number` is deprecated, use `a .- b` instead.\n",
      "│   caller = top-level scope at In[2]:6\n",
      "└ @ Core In[2]:6\n",
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[2]:12\n",
      "└ @ Core In[2]:12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sub</th><th>trial</th><th>c1</th><th>s</th><th>r</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>6 rows × 5 columns</p><tr><th>1</th><td>1</td><td>1</td><td>-99</td><td>2</td><td>-0.5</td></tr><tr><th>2</th><td>1</td><td>2</td><td>2</td><td>1</td><td>0.5</td></tr><tr><th>3</th><td>1</td><td>3</td><td>2</td><td>2</td><td>0.5</td></tr><tr><th>4</th><td>1</td><td>4</td><td>-99</td><td>2</td><td>-0.5</td></tr><tr><th>5</th><td>1</td><td>5</td><td>2</td><td>2</td><td>0.5</td></tr><tr><th>6</th><td>1</td><td>6</td><td>1</td><td>1</td><td>0.5</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& sub & trial & c1 & s & r\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & -99 & 2 & -0.5 \\\\\n",
       "\t2 & 1 & 2 & 2 & 1 & 0.5 \\\\\n",
       "\t3 & 1 & 3 & 2 & 2 & 0.5 \\\\\n",
       "\t4 & 1 & 4 & -99 & 2 & -0.5 \\\\\n",
       "\t5 & 1 & 5 & 2 & 2 & 0.5 \\\\\n",
       "\t6 & 1 & 6 & 1 & 1 & 0.5 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×5 DataFrame\n",
       "│ Row │ sub    │ trial  │ c1     │ s     │ r       │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼────────┼────────┼────────┼───────┼─────────┤\n",
       "│ 1   │ 1      │ 1      │ -99    │ 2     │ -0.5    │\n",
       "│ 2   │ 1      │ 2      │ 2      │ 1     │ 0.5     │\n",
       "│ 3   │ 1      │ 3      │ 2      │ 2     │ 0.5     │\n",
       "│ 4   │ 1      │ 4      │ -99    │ 2     │ -0.5    │\n",
       "│ 5   │ 1      │ 5      │ 2      │ 2     │ 0.5     │\n",
       "│ 6   │ 1      │ 6      │ 1      │ 1     │ 0.5     │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv file of the data\n",
    "#this already has subjects 19, 25 and 26 removed and just contains states, rewards, choices along with trial and subject number\n",
    "#missed responses have also been removed\n",
    "#reward coded as 1 when shock is avoided, -1 when shock is delivered\n",
    "df = readtable(\"/Users/neil/GitHubRepo/Projects/Aversive2Step/data/processed/julia_raw_data_ex_19_25_26.csv\")\n",
    "\n",
    "# change states from 2,3 to 1,2; this allows you to use states as index to update relevant values based on states encountered\n",
    "df[:s] = df[:s]-1\n",
    "\n",
    "# here - rescale rewards to sit between -0.5 (=shock) and 0.5 (=no shock)\n",
    "df[:r] = df[:r]./2\n",
    "\n",
    "# display header\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Read in summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: readtable is deprecated, use CSV.read from the CSV package instead\n",
      "│   caller = top-level scope at In[3]:1\n",
      "└ @ Core In[3]:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>subjects</th><th>nmissed</th><th>failedfinger</th><th>eye_dropout_s1</th><th>eye_dropout_s2</th><th>eye_dropout_meanoversessions</th><th>n_left_actions</th><th>n_right_actions</th><th>ncommontrans</th><th>nraretrans</th><th>n_NoShock_Common</th><th>n_NoShock_Rare</th><th>n_Shock_Common</th><th>n_Shock_Rare</th><th>n_pav_state_2</th><th>n_pav_state_3</th><th>total_nshocks</th><th>cs_plus_mean_t1</th><th>cs_plus_mean_t2</th><th>cs_minus_mean_t1</th><th>cs_minus_mean_t2</th><th>US_plus_percentage_prev</th><th>US_minus_percentage_prev</th><th>PercentStay_NoShock_Common</th><th>PercentStay_NoShock_Rare</th><th>PercentStay_Shock_Common</th><th>PercentStay_Shock_Rare</th><th>age</th><th>gender</th><th>BIS_BAS_Fun</th><th>BIS_BAS_Reward</th><th>BIS_BAS_Drive</th><th>BIS</th><th>BIS_BAS_Unclear</th><th>STAI_Trait</th><th>BDI</th><th>Intol_uncertainty_combined</th><th>Intol_uncertainty_f1</th><th>Intol_uncertainty_f2</th><th>ACQ</th><th>shock_setting</th><th>intensity_rating_pre</th><th>intensity_rating_post</th><th>resting_basline</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>String⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th></tr></thead><tbody><p>38 rows × 44 columns</p><tr><th>1</th><td>1</td><td>0</td><td>2</td><td>0.0150814</td><td>0.00982814</td><td>0.0124548</td><td>70</td><td>50</td><td>84</td><td>36</td><td>66</td><td>26</td><td>18</td><td>10</td><td>32</td><td>28</td><td>46</td><td>0.333333</td><td>0.222222</td><td>0.619048</td><td>0.666667</td><td>0.101695</td><td>0.474576</td><td>0.969697</td><td>0.923077</td><td>0.5</td><td>1.0</td><td>19</td><td>male</td><td>7</td><td>9</td><td>13</td><td>17</td><td>8</td><td>51</td><td>6</td><td>71</td><td>38</td><td>33</td><td>61</td><td>6.25</td><td>7.0</td><td>6.0</td><td>9687.14</td></tr><tr><th>2</th><td>2</td><td>2</td><td>6</td><td>0.0678527</td><td>0.0306338</td><td>0.0492432</td><td>8</td><td>110</td><td>87</td><td>31</td><td>77</td><td>19</td><td>10</td><td>12</td><td>26</td><td>34</td><td>34</td><td>0.25</td><td>0.166667</td><td>0.6875</td><td>0.6875</td><td>0.0847458</td><td>0.525424</td><td>0.960526</td><td>1.0</td><td>0.9</td><td>1.0</td><td>22</td><td>female</td><td>10</td><td>10</td><td>9</td><td>11</td><td>10</td><td>53</td><td>0</td><td>84</td><td>36</td><td>48</td><td>76</td><td>2.5</td><td>5.5</td><td>4.0</td><td>6985.17</td></tr><tr><th>3</th><td>3</td><td>4</td><td>1</td><td>0.0404631</td><td>0.0406216</td><td>0.0405423</td><td>32</td><td>84</td><td>87</td><td>29</td><td>73</td><td>17</td><td>14</td><td>12</td><td>29</td><td>31</td><td>40</td><td>0.357143</td><td>0.285714</td><td>0.521739</td><td>0.565217</td><td>0.0847458</td><td>0.423729</td><td>0.972222</td><td>0.941176</td><td>0.571429</td><td>1.0</td><td>19</td><td>female</td><td>9</td><td>5</td><td>5</td><td>11</td><td>9</td><td>57</td><td>4</td><td>75</td><td>32</td><td>43</td><td>62</td><td>6.75</td><td>6.0</td><td>7.0</td><td>7139.4</td></tr><tr><th>4</th><td>4</td><td>0</td><td>2</td><td>0.0344639</td><td>0.0989166</td><td>0.0666902</td><td>31</td><td>89</td><td>83</td><td>37</td><td>69</td><td>29</td><td>14</td><td>8</td><td>32</td><td>28</td><td>38</td><td>0.3125</td><td>0.5</td><td>0.522727</td><td>0.477273</td><td>0.186441</td><td>0.338983</td><td>0.926471</td><td>0.931034</td><td>0.357143</td><td>0.625</td><td>19</td><td>female</td><td>10</td><td>10</td><td>9</td><td>13</td><td>9</td><td>49</td><td>0</td><td>59</td><td>25</td><td>34</td><td>60</td><td>4.25</td><td>7.0</td><td>7.0</td><td>6980.83</td></tr><tr><th>5</th><td>5</td><td>2</td><td>1</td><td>0.192682</td><td>0.0886042</td><td>0.140643</td><td>85</td><td>33</td><td>85</td><td>33</td><td>64</td><td>21</td><td>21</td><td>12</td><td>31</td><td>29</td><td>49</td><td>0.25</td><td>0.25</td><td>0.636364</td><td>0.522727</td><td>0.0847458</td><td>0.474576</td><td>0.809524</td><td>0.619048</td><td>0.571429</td><td>0.416667</td><td>21</td><td>female</td><td>10</td><td>10</td><td>10</td><td>10</td><td>8</td><td>49</td><td>4</td><td>83</td><td>45</td><td>38</td><td>60</td><td>5.25</td><td>7.0</td><td>4.0</td><td>8349.47</td></tr><tr><th>6</th><td>6</td><td>7</td><td>6</td><td>0.226035</td><td>0.373101</td><td>0.299568</td><td>40</td><td>73</td><td>73</td><td>40</td><td>62</td><td>23</td><td>11</td><td>17</td><td>35</td><td>25</td><td>44</td><td>0.3125</td><td>0.4375</td><td>0.545455</td><td>0.318182</td><td>0.101695</td><td>0.40678</td><td>0.639344</td><td>0.652174</td><td>0.363636</td><td>0.588235</td><td>18</td><td>female</td><td>5</td><td>8</td><td>9</td><td>15</td><td>10</td><td>45</td><td>6</td><td>48</td><td>25</td><td>23</td><td>69</td><td>3.5</td><td>7.0</td><td>8.0</td><td>7723.11</td></tr><tr><th>7</th><td>7</td><td>2</td><td>3</td><td>0.0154738</td><td>0.0195168</td><td>0.0174953</td><td>55</td><td>63</td><td>86</td><td>32</td><td>69</td><td>24</td><td>17</td><td>8</td><td>28</td><td>32</td><td>37</td><td>0.583333</td><td>0.666667</td><td>0.5</td><td>0.5</td><td>0.101695</td><td>0.440678</td><td>0.955882</td><td>0.833333</td><td>0.764706</td><td>0.75</td><td>20</td><td>male</td><td>10</td><td>11</td><td>10</td><td>15</td><td>12</td><td>54</td><td>8</td><td>113</td><td>64</td><td>49</td><td>41</td><td>3.5</td><td>7.0</td><td>7.0</td><td>7427.54</td></tr><tr><th>8</th><td>8</td><td>4</td><td>1</td><td>0.0936648</td><td>0.0280646</td><td>0.0608647</td><td>59</td><td>57</td><td>82</td><td>34</td><td>54</td><td>22</td><td>28</td><td>12</td><td>27</td><td>33</td><td>58</td><td>0.5</td><td>0.555556</td><td>0.357143</td><td>0.571429</td><td>0.169492</td><td>0.338983</td><td>0.169811</td><td>0.363636</td><td>0.25</td><td>0.166667</td><td>33</td><td>male</td><td>7</td><td>10</td><td>10</td><td>10</td><td>10</td><td>51</td><td>4</td><td>77</td><td>37</td><td>40</td><td>46</td><td>8.0</td><td>7.0</td><td>7.0</td><td>5273.04</td></tr><tr><th>9</th><td>9</td><td>0</td><td>0</td><td>0.00308074</td><td>0.00252462</td><td>0.00280268</td><td>31</td><td>89</td><td>83</td><td>37</td><td>51</td><td>22</td><td>32</td><td>15</td><td>32</td><td>28</td><td>67</td><td>0.25</td><td>0.2</td><td>0.625</td><td>0.575</td><td>0.0847458</td><td>0.322034</td><td>0.96</td><td>0.863636</td><td>0.3125</td><td>0.733333</td><td>33</td><td>male</td><td>8</td><td>10</td><td>10</td><td>18</td><td>11</td><td>42</td><td>0</td><td>57</td><td>30</td><td>27</td><td>42</td><td>6.75</td><td>7.0</td><td>7.0</td><td>8154.0</td></tr><tr><th>10</th><td>10</td><td>1</td><td>1</td><td>0.00356965</td><td>0.00443274</td><td>0.00400119</td><td>41</td><td>78</td><td>76</td><td>43</td><td>61</td><td>27</td><td>15</td><td>16</td><td>29</td><td>31</td><td>53</td><td>0.272727</td><td>0.454545</td><td>0.605263</td><td>0.578947</td><td>0.20339</td><td>0.355932</td><td>0.540984</td><td>0.37037</td><td>0.142857</td><td>0.5</td><td>19</td><td>male</td><td>11</td><td>7</td><td>14</td><td>10</td><td>7</td><td>47</td><td>6</td><td>41</td><td>21</td><td>27</td><td>50</td><td>4.0</td><td>7.0</td><td>6.0</td><td>5623.83</td></tr><tr><th>11</th><td>11</td><td>0</td><td>0</td><td>0.0131109</td><td>0.013795</td><td>0.013453</td><td>62</td><td>58</td><td>94</td><td>26</td><td>73</td><td>19</td><td>21</td><td>7</td><td>30</td><td>30</td><td>42</td><td>0.428571</td><td>0.428571</td><td>0.630435</td><td>0.543478</td><td>0.101695</td><td>0.457627</td><td>0.972222</td><td>0.894737</td><td>0.904762</td><td>0.857143</td><td>30</td><td>female</td><td>5</td><td>9</td><td>10</td><td>16</td><td>8</td><td>43</td><td>21</td><td>64</td><td>24</td><td>40</td><td>64</td><td>4.25</td><td>7.0</td><td>6.0</td><td>9377.57</td></tr><tr><th>12</th><td>12</td><td>6</td><td>2</td><td>0.0533189</td><td>0.0465024</td><td>0.0499106</td><td>94</td><td>20</td><td>78</td><td>36</td><td>50</td><td>28</td><td>28</td><td>8</td><td>28</td><td>32</td><td>52</td><td>0.5625</td><td>0.4375</td><td>0.5</td><td>0.409091</td><td>0.169492</td><td>0.254237</td><td>0.734694</td><td>0.678571</td><td>0.785714</td><td>0.75</td><td>24</td><td>male</td><td>8</td><td>6</td><td>5</td><td>17</td><td>11</td><td>41</td><td>0</td><td>70</td><td>44</td><td>26</td><td>67</td><td>2.75</td><td>7.5</td><td>7.5</td><td>5069.23</td></tr><tr><th>13</th><td>13</td><td>1</td><td>0</td><td>0.00937355</td><td>0.0158995</td><td>0.0126365</td><td>16</td><td>103</td><td>81</td><td>38</td><td>62</td><td>19</td><td>19</td><td>19</td><td>29</td><td>31</td><td>52</td><td>0.0714286</td><td>0.0714286</td><td>0.565217</td><td>0.608696</td><td>0.0508475</td><td>0.474576</td><td>0.983607</td><td>0.947368</td><td>0.894737</td><td>1.0</td><td>19</td><td>male</td><td>5</td><td>8</td><td>10</td><td>16</td><td>6</td><td>57</td><td>5</td><td>62</td><td>30</td><td>32</td><td>60</td><td>3.75</td><td>7.0</td><td>7.0</td><td>7103.81</td></tr><tr><th>14</th><td>14</td><td>1</td><td>2</td><td>0.0127901</td><td>0.00867068</td><td>0.0107304</td><td>63</td><td>56</td><td>81</td><td>38</td><td>55</td><td>24</td><td>26</td><td>14</td><td>32</td><td>28</td><td>63</td><td>0.347826</td><td>0.26087</td><td>0.648649</td><td>0.756757</td><td>0.186441</td><td>0.305085</td><td>0.888889</td><td>0.75</td><td>0.653846</td><td>0.857143</td><td>23</td><td>female</td><td>9</td><td>9</td><td>8</td><td>13</td><td>8</td><td>48</td><td>9</td><td>93</td><td>44</td><td>49</td><td>72</td><td>3.75</td><td>7.0</td><td>5.0</td><td>5132.35</td></tr><tr><th>15</th><td>15</td><td>1</td><td>6</td><td>0.0324304</td><td>0.0247234</td><td>0.0285769</td><td>82</td><td>37</td><td>90</td><td>29</td><td>66</td><td>25</td><td>24</td><td>4</td><td>24</td><td>36</td><td>39</td><td>0.272727</td><td>0.454545</td><td>0.510204</td><td>0.367347</td><td>0.0847458</td><td>0.322034</td><td>0.492308</td><td>0.44</td><td>0.625</td><td>1.0</td><td>29</td><td>male</td><td>11</td><td>9</td><td>12</td><td>21</td><td>11</td><td>46</td><td>0</td><td>38</td><td>15</td><td>23</td><td>60</td><td>7.25</td><td>7.0</td><td>7.0</td><td>5838.34</td></tr><tr><th>16</th><td>16</td><td>3</td><td>1</td><td>0.114628</td><td>0.0597723</td><td>0.0872002</td><td>61</td><td>56</td><td>71</td><td>46</td><td>50</td><td>37</td><td>21</td><td>9</td><td>27</td><td>33</td><td>49</td><td>0.684211</td><td>0.684211</td><td>0.365854</td><td>0.487805</td><td>0.220339</td><td>0.338983</td><td>0.84</td><td>1.0</td><td>0.95</td><td>0.333333</td><td>19</td><td>female</td><td>5</td><td>5</td><td>4</td><td>9</td><td>5</td><td>58</td><td>8</td><td>61</td><td>31</td><td>30</td><td>60</td><td>4.5</td><td>7.0</td><td>7.0</td><td>5720.02</td></tr><tr><th>17</th><td>17</td><td>5</td><td>4</td><td>0.103876</td><td>0.102473</td><td>0.103175</td><td>79</td><td>36</td><td>84</td><td>31</td><td>60</td><td>23</td><td>24</td><td>8</td><td>24</td><td>36</td><td>50</td><td>0.555556</td><td>0.388889</td><td>0.404762</td><td>0.47619</td><td>0.220339</td><td>0.305085</td><td>0.389831</td><td>0.652174</td><td>0.458333</td><td>0.125</td><td>21</td><td>female</td><td>5</td><td>5</td><td>5</td><td>18</td><td>7</td><td>55</td><td>2</td><td>61</td><td>24</td><td>37</td><td>62</td><td>5.5</td><td>7.0</td><td>6.0</td><td>5300.57</td></tr><tr><th>18</th><td>18</td><td>0</td><td>3</td><td>0.00520394</td><td>0.0112866</td><td>0.00824529</td><td>61</td><td>59</td><td>81</td><td>39</td><td>64</td><td>26</td><td>17</td><td>13</td><td>31</td><td>29</td><td>44</td><td>0.285714</td><td>0.428571</td><td>0.478261</td><td>0.543478</td><td>0.101695</td><td>0.355932</td><td>0.703125</td><td>0.52</td><td>0.470588</td><td>0.230769</td><td>18</td><td>female</td><td>5</td><td>7</td><td>7</td><td>11</td><td>10</td><td>52</td><td>13</td><td>74</td><td>42</td><td>32</td><td>67</td><td>6.5</td><td>7.0</td><td>6.0</td><td>7524.59</td></tr><tr><th>19</th><td>20</td><td>3</td><td>2</td><td>0.199709</td><td>0.102817</td><td>0.151263</td><td>57</td><td>60</td><td>84</td><td>33</td><td>67</td><td>26</td><td>17</td><td>7</td><td>34</td><td>26</td><td>37</td><td>0.538462</td><td>0.461538</td><td>0.531915</td><td>0.489362</td><td>0.118644</td><td>0.440678</td><td>1.0</td><td>1.0</td><td>0.875</td><td>1.0</td><td>24</td><td>female</td><td>6</td><td>5</td><td>9</td><td>13</td><td>9</td><td>56</td><td>4</td><td>68</td><td>30</td><td>38</td><td>73</td><td>4.0</td><td>6.0</td><td>7.5</td><td>6402.23</td></tr><tr><th>20</th><td>21</td><td>1</td><td>1</td><td>0.190307</td><td>0.111296</td><td>0.150801</td><td>13</td><td>106</td><td>87</td><td>32</td><td>65</td><td>22</td><td>22</td><td>10</td><td>29</td><td>31</td><td>41</td><td>0.444444</td><td>0.333333</td><td>0.529412</td><td>0.568627</td><td>0.0677966</td><td>0.440678</td><td>0.938462</td><td>0.818182</td><td>0.761905</td><td>0.7</td><td>22</td><td>male</td><td>10</td><td>7</td><td>7</td><td>13</td><td>7</td><td>52</td><td>1</td><td>74</td><td>32</td><td>42</td><td>67</td><td>4.5</td><td>7.0</td><td>7.0</td><td>4545.23</td></tr><tr><th>21</th><td>22</td><td>0</td><td>1</td><td>0.0173088</td><td>0.0407252</td><td>0.029017</td><td>56</td><td>64</td><td>82</td><td>38</td><td>54</td><td>22</td><td>28</td><td>16</td><td>22</td><td>38</td><td>52</td><td>0.25</td><td>0.125</td><td>0.5</td><td>0.634615</td><td>0.0677966</td><td>0.389831</td><td>0.849057</td><td>0.772727</td><td>0.607143</td><td>0.5625</td><td>18</td><td>male</td><td>4</td><td>5</td><td>4</td><td>13</td><td>6</td><td>54</td><td>7</td><td>60</td><td>27</td><td>33</td><td>85</td><td>6.0</td><td>7.0</td><td>7.0</td><td>6884.64</td></tr><tr><th>22</th><td>23</td><td>4</td><td>1</td><td>0.03284</td><td>0.0427378</td><td>0.0377889</td><td>10</td><td>106</td><td>86</td><td>30</td><td>75</td><td>21</td><td>11</td><td>9</td><td>27</td><td>33</td><td>30</td><td>0.1</td><td>0.1</td><td>0.64</td><td>0.64</td><td>0.0338983</td><td>0.491525</td><td>0.972973</td><td>0.857143</td><td>0.545455</td><td>0.888889</td><td>18</td><td>female</td><td>16</td><td>11</td><td>14</td><td>10</td><td>7</td><td>49</td><td>24</td><td>88</td><td>43</td><td>45</td><td>78</td><td>4.25</td><td>7.0</td><td>8.0</td><td>7177.76</td></tr><tr><th>23</th><td>24</td><td>1</td><td>0</td><td>0.168167</td><td>0.0877624</td><td>0.127965</td><td>64</td><td>55</td><td>85</td><td>34</td><td>71</td><td>25</td><td>14</td><td>9</td><td>23</td><td>37</td><td>39</td><td>0.5625</td><td>0.25</td><td>0.522727</td><td>0.409091</td><td>0.0847458</td><td>0.423729</td><td>0.485714</td><td>0.4</td><td>0.285714</td><td>0.888889</td><td>19</td><td>female</td><td>4</td><td>9</td><td>10</td><td>18</td><td>7</td><td>45</td><td>2</td><td>43</td><td>21</td><td>22</td><td>61</td><td>4.5</td><td>7.0</td><td>NaN</td><td>8290.32</td></tr><tr><th>24</th><td>27</td><td>0</td><td>2</td><td>0.108875</td><td>0.115317</td><td>0.112096</td><td>63</td><td>57</td><td>75</td><td>45</td><td>52</td><td>29</td><td>23</td><td>16</td><td>24</td><td>36</td><td>52</td><td>0.846154</td><td>0.0769231</td><td>0.361702</td><td>0.595745</td><td>0.0508475</td><td>0.440678</td><td>0.0769231</td><td>0.103448</td><td>0.272727</td><td>0.0625</td><td>29</td><td>female</td><td>8</td><td>7</td><td>9</td><td>16</td><td>8</td><td>58</td><td>5</td><td>77</td><td>43</td><td>34</td><td>64</td><td>4.25</td><td>7.0</td><td>7.0</td><td>3884.43</td></tr><tr><th>25</th><td>28</td><td>0</td><td>2</td><td>0.0657728</td><td>0.0399318</td><td>0.0528523</td><td>81</td><td>39</td><td>77</td><td>43</td><td>52</td><td>29</td><td>25</td><td>14</td><td>26</td><td>34</td><td>66</td><td>0.518519</td><td>0.518519</td><td>0.454545</td><td>0.484848</td><td>0.271186</td><td>0.220339</td><td>0.903846</td><td>1.0</td><td>0.92</td><td>0.928571</td><td>23</td><td>female</td><td>6</td><td>7</td><td>7</td><td>16</td><td>10</td><td>46</td><td>1</td><td>50</td><td>21</td><td>29</td><td>59</td><td>4.0</td><td>7.0</td><td>5.0</td><td>6613.58</td></tr><tr><th>26</th><td>29</td><td>2</td><td>0</td><td>0.0325579</td><td>0.0653791</td><td>0.0489685</td><td>57</td><td>61</td><td>88</td><td>30</td><td>70</td><td>25</td><td>18</td><td>5</td><td>32</td><td>28</td><td>35</td><td>0.0833333</td><td>0.0</td><td>0.5</td><td>0.5625</td><td>0.118644</td><td>0.322034</td><td>0.898551</td><td>0.84</td><td>0.0555556</td><td>0.8</td><td>19</td><td>male</td><td>10</td><td>8</td><td>7</td><td>23</td><td>10</td><td>46</td><td>3</td><td>44</td><td>17</td><td>27</td><td>65</td><td>7.5</td><td>7.0</td><td>6.5</td><td>5425.31</td></tr><tr><th>27</th><td>30</td><td>4</td><td>1</td><td>0.0278249</td><td>0.0219461</td><td>0.0248855</td><td>23</td><td>93</td><td>74</td><td>42</td><td>63</td><td>28</td><td>11</td><td>14</td><td>32</td><td>28</td><td>38</td><td>0.615385</td><td>0.384615</td><td>0.510638</td><td>0.446809</td><td>0.152542</td><td>0.355932</td><td>0.870968</td><td>0.785714</td><td>0.272727</td><td>0.642857</td><td>21</td><td>female</td><td>10</td><td>8</td><td>9</td><td>10</td><td>10</td><td>47</td><td>9</td><td>90</td><td>45</td><td>45</td><td>68</td><td>2.5</td><td>7.0</td><td>7.0</td><td>6589.28</td></tr><tr><th>28</th><td>31</td><td>0</td><td>9</td><td>0.096813</td><td>0.183352</td><td>0.140082</td><td>85</td><td>35</td><td>83</td><td>37</td><td>66</td><td>22</td><td>17</td><td>15</td><td>32</td><td>28</td><td>59</td><td>0.333333</td><td>0.62963</td><td>0.69697</td><td>0.666667</td><td>0.186441</td><td>0.305085</td><td>0.907692</td><td>0.863636</td><td>0.117647</td><td>0.133333</td><td>29</td><td>male</td><td>10</td><td>6</td><td>9</td><td>7</td><td>10</td><td>61</td><td>31</td><td>131</td><td>75</td><td>56</td><td>62</td><td>7.5</td><td>7.0</td><td>5.0</td><td>4156.44</td></tr><tr><th>29</th><td>32</td><td>3</td><td>4</td><td>0.0864721</td><td>0.0924759</td><td>0.089474</td><td>66</td><td>51</td><td>76</td><td>41</td><td>55</td><td>29</td><td>21</td><td>12</td><td>29</td><td>31</td><td>53</td><td>0.15</td><td>0.65</td><td>0.6</td><td>0.4</td><td>0.152542</td><td>0.338983</td><td>0.345455</td><td>0.428571</td><td>0.380952</td><td>0.416667</td><td>21</td><td>female</td><td>7</td><td>5</td><td>9</td><td>11</td><td>5</td><td>47</td><td>6</td><td>44</td><td>23</td><td>21</td><td>59</td><td>5.75</td><td>7.0</td><td>7.0</td><td>5900.2</td></tr><tr><th>30</th><td>33</td><td>5</td><td>3</td><td>0.0431343</td><td>0.0776605</td><td>0.0603974</td><td>29</td><td>86</td><td>88</td><td>27</td><td>59</td><td>16</td><td>29</td><td>11</td><td>31</td><td>29</td><td>60</td><td>0.15</td><td>0.2</td><td>0.65</td><td>0.6</td><td>0.135593</td><td>0.305085</td><td>0.932203</td><td>0.733333</td><td>0.62069</td><td>0.909091</td><td>20</td><td>male</td><td>9</td><td>6</td><td>8</td><td>11</td><td>7</td><td>54</td><td>12</td><td>60</td><td>31</td><td>29</td><td>68</td><td>3.75</td><td>7.0</td><td>7.0</td><td>6347.62</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccccccccccccccccccccccccccccccccccccc}\n",
       "\t& subjects & nmissed & failedfinger & eye\\_dropout\\_s1 & eye\\_dropout\\_s2 & eye\\_dropout\\_meanoversessions & n\\_left\\_actions & n\\_right\\_actions & ncommontrans & nraretrans & n\\_NoShock\\_Common & n\\_NoShock\\_Rare & n\\_Shock\\_Common & n\\_Shock\\_Rare & n\\_pav\\_state\\_2 & n\\_pav\\_state\\_3 & total\\_nshocks & cs\\_plus\\_mean\\_t1 & cs\\_plus\\_mean\\_t2 & cs\\_minus\\_mean\\_t1 & cs\\_minus\\_mean\\_t2 & US\\_plus\\_percentage\\_prev & US\\_minus\\_percentage\\_prev & PercentStay\\_NoShock\\_Common & PercentStay\\_NoShock\\_Rare & PercentStay\\_Shock\\_Common & PercentStay\\_Shock\\_Rare & age & gender & BIS\\_BAS\\_Fun & BIS\\_BAS\\_Reward & BIS\\_BAS\\_Drive & BIS & BIS\\_BAS\\_Unclear & STAI\\_Trait & BDI & Intol\\_uncertainty\\_combined & Intol\\_uncertainty\\_f1 & Intol\\_uncertainty\\_f2 & ACQ & shock\\_setting & intensity\\_rating\\_pre & intensity\\_rating\\_post & resting\\_basline\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 0 & 2 & 0.0150814 & 0.00982814 & 0.0124548 & 70 & 50 & 84 & 36 & 66 & 26 & 18 & 10 & 32 & 28 & 46 & 0.333333 & 0.222222 & 0.619048 & 0.666667 & 0.101695 & 0.474576 & 0.969697 & 0.923077 & 0.5 & 1.0 & 19 & male & 7 & 9 & 13 & 17 & 8 & 51 & 6 & 71 & 38 & 33 & 61 & 6.25 & 7.0 & 6.0 & 9687.14 \\\\\n",
       "\t2 & 2 & 2 & 6 & 0.0678527 & 0.0306338 & 0.0492432 & 8 & 110 & 87 & 31 & 77 & 19 & 10 & 12 & 26 & 34 & 34 & 0.25 & 0.166667 & 0.6875 & 0.6875 & 0.0847458 & 0.525424 & 0.960526 & 1.0 & 0.9 & 1.0 & 22 & female & 10 & 10 & 9 & 11 & 10 & 53 & 0 & 84 & 36 & 48 & 76 & 2.5 & 5.5 & 4.0 & 6985.17 \\\\\n",
       "\t3 & 3 & 4 & 1 & 0.0404631 & 0.0406216 & 0.0405423 & 32 & 84 & 87 & 29 & 73 & 17 & 14 & 12 & 29 & 31 & 40 & 0.357143 & 0.285714 & 0.521739 & 0.565217 & 0.0847458 & 0.423729 & 0.972222 & 0.941176 & 0.571429 & 1.0 & 19 & female & 9 & 5 & 5 & 11 & 9 & 57 & 4 & 75 & 32 & 43 & 62 & 6.75 & 6.0 & 7.0 & 7139.4 \\\\\n",
       "\t4 & 4 & 0 & 2 & 0.0344639 & 0.0989166 & 0.0666902 & 31 & 89 & 83 & 37 & 69 & 29 & 14 & 8 & 32 & 28 & 38 & 0.3125 & 0.5 & 0.522727 & 0.477273 & 0.186441 & 0.338983 & 0.926471 & 0.931034 & 0.357143 & 0.625 & 19 & female & 10 & 10 & 9 & 13 & 9 & 49 & 0 & 59 & 25 & 34 & 60 & 4.25 & 7.0 & 7.0 & 6980.83 \\\\\n",
       "\t5 & 5 & 2 & 1 & 0.192682 & 0.0886042 & 0.140643 & 85 & 33 & 85 & 33 & 64 & 21 & 21 & 12 & 31 & 29 & 49 & 0.25 & 0.25 & 0.636364 & 0.522727 & 0.0847458 & 0.474576 & 0.809524 & 0.619048 & 0.571429 & 0.416667 & 21 & female & 10 & 10 & 10 & 10 & 8 & 49 & 4 & 83 & 45 & 38 & 60 & 5.25 & 7.0 & 4.0 & 8349.47 \\\\\n",
       "\t6 & 6 & 7 & 6 & 0.226035 & 0.373101 & 0.299568 & 40 & 73 & 73 & 40 & 62 & 23 & 11 & 17 & 35 & 25 & 44 & 0.3125 & 0.4375 & 0.545455 & 0.318182 & 0.101695 & 0.40678 & 0.639344 & 0.652174 & 0.363636 & 0.588235 & 18 & female & 5 & 8 & 9 & 15 & 10 & 45 & 6 & 48 & 25 & 23 & 69 & 3.5 & 7.0 & 8.0 & 7723.11 \\\\\n",
       "\t7 & 7 & 2 & 3 & 0.0154738 & 0.0195168 & 0.0174953 & 55 & 63 & 86 & 32 & 69 & 24 & 17 & 8 & 28 & 32 & 37 & 0.583333 & 0.666667 & 0.5 & 0.5 & 0.101695 & 0.440678 & 0.955882 & 0.833333 & 0.764706 & 0.75 & 20 & male & 10 & 11 & 10 & 15 & 12 & 54 & 8 & 113 & 64 & 49 & 41 & 3.5 & 7.0 & 7.0 & 7427.54 \\\\\n",
       "\t8 & 8 & 4 & 1 & 0.0936648 & 0.0280646 & 0.0608647 & 59 & 57 & 82 & 34 & 54 & 22 & 28 & 12 & 27 & 33 & 58 & 0.5 & 0.555556 & 0.357143 & 0.571429 & 0.169492 & 0.338983 & 0.169811 & 0.363636 & 0.25 & 0.166667 & 33 & male & 7 & 10 & 10 & 10 & 10 & 51 & 4 & 77 & 37 & 40 & 46 & 8.0 & 7.0 & 7.0 & 5273.04 \\\\\n",
       "\t9 & 9 & 0 & 0 & 0.00308074 & 0.00252462 & 0.00280268 & 31 & 89 & 83 & 37 & 51 & 22 & 32 & 15 & 32 & 28 & 67 & 0.25 & 0.2 & 0.625 & 0.575 & 0.0847458 & 0.322034 & 0.96 & 0.863636 & 0.3125 & 0.733333 & 33 & male & 8 & 10 & 10 & 18 & 11 & 42 & 0 & 57 & 30 & 27 & 42 & 6.75 & 7.0 & 7.0 & 8154.0 \\\\\n",
       "\t10 & 10 & 1 & 1 & 0.00356965 & 0.00443274 & 0.00400119 & 41 & 78 & 76 & 43 & 61 & 27 & 15 & 16 & 29 & 31 & 53 & 0.272727 & 0.454545 & 0.605263 & 0.578947 & 0.20339 & 0.355932 & 0.540984 & 0.37037 & 0.142857 & 0.5 & 19 & male & 11 & 7 & 14 & 10 & 7 & 47 & 6 & 41 & 21 & 27 & 50 & 4.0 & 7.0 & 6.0 & 5623.83 \\\\\n",
       "\t11 & 11 & 0 & 0 & 0.0131109 & 0.013795 & 0.013453 & 62 & 58 & 94 & 26 & 73 & 19 & 21 & 7 & 30 & 30 & 42 & 0.428571 & 0.428571 & 0.630435 & 0.543478 & 0.101695 & 0.457627 & 0.972222 & 0.894737 & 0.904762 & 0.857143 & 30 & female & 5 & 9 & 10 & 16 & 8 & 43 & 21 & 64 & 24 & 40 & 64 & 4.25 & 7.0 & 6.0 & 9377.57 \\\\\n",
       "\t12 & 12 & 6 & 2 & 0.0533189 & 0.0465024 & 0.0499106 & 94 & 20 & 78 & 36 & 50 & 28 & 28 & 8 & 28 & 32 & 52 & 0.5625 & 0.4375 & 0.5 & 0.409091 & 0.169492 & 0.254237 & 0.734694 & 0.678571 & 0.785714 & 0.75 & 24 & male & 8 & 6 & 5 & 17 & 11 & 41 & 0 & 70 & 44 & 26 & 67 & 2.75 & 7.5 & 7.5 & 5069.23 \\\\\n",
       "\t13 & 13 & 1 & 0 & 0.00937355 & 0.0158995 & 0.0126365 & 16 & 103 & 81 & 38 & 62 & 19 & 19 & 19 & 29 & 31 & 52 & 0.0714286 & 0.0714286 & 0.565217 & 0.608696 & 0.0508475 & 0.474576 & 0.983607 & 0.947368 & 0.894737 & 1.0 & 19 & male & 5 & 8 & 10 & 16 & 6 & 57 & 5 & 62 & 30 & 32 & 60 & 3.75 & 7.0 & 7.0 & 7103.81 \\\\\n",
       "\t14 & 14 & 1 & 2 & 0.0127901 & 0.00867068 & 0.0107304 & 63 & 56 & 81 & 38 & 55 & 24 & 26 & 14 & 32 & 28 & 63 & 0.347826 & 0.26087 & 0.648649 & 0.756757 & 0.186441 & 0.305085 & 0.888889 & 0.75 & 0.653846 & 0.857143 & 23 & female & 9 & 9 & 8 & 13 & 8 & 48 & 9 & 93 & 44 & 49 & 72 & 3.75 & 7.0 & 5.0 & 5132.35 \\\\\n",
       "\t15 & 15 & 1 & 6 & 0.0324304 & 0.0247234 & 0.0285769 & 82 & 37 & 90 & 29 & 66 & 25 & 24 & 4 & 24 & 36 & 39 & 0.272727 & 0.454545 & 0.510204 & 0.367347 & 0.0847458 & 0.322034 & 0.492308 & 0.44 & 0.625 & 1.0 & 29 & male & 11 & 9 & 12 & 21 & 11 & 46 & 0 & 38 & 15 & 23 & 60 & 7.25 & 7.0 & 7.0 & 5838.34 \\\\\n",
       "\t16 & 16 & 3 & 1 & 0.114628 & 0.0597723 & 0.0872002 & 61 & 56 & 71 & 46 & 50 & 37 & 21 & 9 & 27 & 33 & 49 & 0.684211 & 0.684211 & 0.365854 & 0.487805 & 0.220339 & 0.338983 & 0.84 & 1.0 & 0.95 & 0.333333 & 19 & female & 5 & 5 & 4 & 9 & 5 & 58 & 8 & 61 & 31 & 30 & 60 & 4.5 & 7.0 & 7.0 & 5720.02 \\\\\n",
       "\t17 & 17 & 5 & 4 & 0.103876 & 0.102473 & 0.103175 & 79 & 36 & 84 & 31 & 60 & 23 & 24 & 8 & 24 & 36 & 50 & 0.555556 & 0.388889 & 0.404762 & 0.47619 & 0.220339 & 0.305085 & 0.389831 & 0.652174 & 0.458333 & 0.125 & 21 & female & 5 & 5 & 5 & 18 & 7 & 55 & 2 & 61 & 24 & 37 & 62 & 5.5 & 7.0 & 6.0 & 5300.57 \\\\\n",
       "\t18 & 18 & 0 & 3 & 0.00520394 & 0.0112866 & 0.00824529 & 61 & 59 & 81 & 39 & 64 & 26 & 17 & 13 & 31 & 29 & 44 & 0.285714 & 0.428571 & 0.478261 & 0.543478 & 0.101695 & 0.355932 & 0.703125 & 0.52 & 0.470588 & 0.230769 & 18 & female & 5 & 7 & 7 & 11 & 10 & 52 & 13 & 74 & 42 & 32 & 67 & 6.5 & 7.0 & 6.0 & 7524.59 \\\\\n",
       "\t19 & 20 & 3 & 2 & 0.199709 & 0.102817 & 0.151263 & 57 & 60 & 84 & 33 & 67 & 26 & 17 & 7 & 34 & 26 & 37 & 0.538462 & 0.461538 & 0.531915 & 0.489362 & 0.118644 & 0.440678 & 1.0 & 1.0 & 0.875 & 1.0 & 24 & female & 6 & 5 & 9 & 13 & 9 & 56 & 4 & 68 & 30 & 38 & 73 & 4.0 & 6.0 & 7.5 & 6402.23 \\\\\n",
       "\t20 & 21 & 1 & 1 & 0.190307 & 0.111296 & 0.150801 & 13 & 106 & 87 & 32 & 65 & 22 & 22 & 10 & 29 & 31 & 41 & 0.444444 & 0.333333 & 0.529412 & 0.568627 & 0.0677966 & 0.440678 & 0.938462 & 0.818182 & 0.761905 & 0.7 & 22 & male & 10 & 7 & 7 & 13 & 7 & 52 & 1 & 74 & 32 & 42 & 67 & 4.5 & 7.0 & 7.0 & 4545.23 \\\\\n",
       "\t21 & 22 & 0 & 1 & 0.0173088 & 0.0407252 & 0.029017 & 56 & 64 & 82 & 38 & 54 & 22 & 28 & 16 & 22 & 38 & 52 & 0.25 & 0.125 & 0.5 & 0.634615 & 0.0677966 & 0.389831 & 0.849057 & 0.772727 & 0.607143 & 0.5625 & 18 & male & 4 & 5 & 4 & 13 & 6 & 54 & 7 & 60 & 27 & 33 & 85 & 6.0 & 7.0 & 7.0 & 6884.64 \\\\\n",
       "\t22 & 23 & 4 & 1 & 0.03284 & 0.0427378 & 0.0377889 & 10 & 106 & 86 & 30 & 75 & 21 & 11 & 9 & 27 & 33 & 30 & 0.1 & 0.1 & 0.64 & 0.64 & 0.0338983 & 0.491525 & 0.972973 & 0.857143 & 0.545455 & 0.888889 & 18 & female & 16 & 11 & 14 & 10 & 7 & 49 & 24 & 88 & 43 & 45 & 78 & 4.25 & 7.0 & 8.0 & 7177.76 \\\\\n",
       "\t23 & 24 & 1 & 0 & 0.168167 & 0.0877624 & 0.127965 & 64 & 55 & 85 & 34 & 71 & 25 & 14 & 9 & 23 & 37 & 39 & 0.5625 & 0.25 & 0.522727 & 0.409091 & 0.0847458 & 0.423729 & 0.485714 & 0.4 & 0.285714 & 0.888889 & 19 & female & 4 & 9 & 10 & 18 & 7 & 45 & 2 & 43 & 21 & 22 & 61 & 4.5 & 7.0 & NaN & 8290.32 \\\\\n",
       "\t24 & 27 & 0 & 2 & 0.108875 & 0.115317 & 0.112096 & 63 & 57 & 75 & 45 & 52 & 29 & 23 & 16 & 24 & 36 & 52 & 0.846154 & 0.0769231 & 0.361702 & 0.595745 & 0.0508475 & 0.440678 & 0.0769231 & 0.103448 & 0.272727 & 0.0625 & 29 & female & 8 & 7 & 9 & 16 & 8 & 58 & 5 & 77 & 43 & 34 & 64 & 4.25 & 7.0 & 7.0 & 3884.43 \\\\\n",
       "\t25 & 28 & 0 & 2 & 0.0657728 & 0.0399318 & 0.0528523 & 81 & 39 & 77 & 43 & 52 & 29 & 25 & 14 & 26 & 34 & 66 & 0.518519 & 0.518519 & 0.454545 & 0.484848 & 0.271186 & 0.220339 & 0.903846 & 1.0 & 0.92 & 0.928571 & 23 & female & 6 & 7 & 7 & 16 & 10 & 46 & 1 & 50 & 21 & 29 & 59 & 4.0 & 7.0 & 5.0 & 6613.58 \\\\\n",
       "\t26 & 29 & 2 & 0 & 0.0325579 & 0.0653791 & 0.0489685 & 57 & 61 & 88 & 30 & 70 & 25 & 18 & 5 & 32 & 28 & 35 & 0.0833333 & 0.0 & 0.5 & 0.5625 & 0.118644 & 0.322034 & 0.898551 & 0.84 & 0.0555556 & 0.8 & 19 & male & 10 & 8 & 7 & 23 & 10 & 46 & 3 & 44 & 17 & 27 & 65 & 7.5 & 7.0 & 6.5 & 5425.31 \\\\\n",
       "\t27 & 30 & 4 & 1 & 0.0278249 & 0.0219461 & 0.0248855 & 23 & 93 & 74 & 42 & 63 & 28 & 11 & 14 & 32 & 28 & 38 & 0.615385 & 0.384615 & 0.510638 & 0.446809 & 0.152542 & 0.355932 & 0.870968 & 0.785714 & 0.272727 & 0.642857 & 21 & female & 10 & 8 & 9 & 10 & 10 & 47 & 9 & 90 & 45 & 45 & 68 & 2.5 & 7.0 & 7.0 & 6589.28 \\\\\n",
       "\t28 & 31 & 0 & 9 & 0.096813 & 0.183352 & 0.140082 & 85 & 35 & 83 & 37 & 66 & 22 & 17 & 15 & 32 & 28 & 59 & 0.333333 & 0.62963 & 0.69697 & 0.666667 & 0.186441 & 0.305085 & 0.907692 & 0.863636 & 0.117647 & 0.133333 & 29 & male & 10 & 6 & 9 & 7 & 10 & 61 & 31 & 131 & 75 & 56 & 62 & 7.5 & 7.0 & 5.0 & 4156.44 \\\\\n",
       "\t29 & 32 & 3 & 4 & 0.0864721 & 0.0924759 & 0.089474 & 66 & 51 & 76 & 41 & 55 & 29 & 21 & 12 & 29 & 31 & 53 & 0.15 & 0.65 & 0.6 & 0.4 & 0.152542 & 0.338983 & 0.345455 & 0.428571 & 0.380952 & 0.416667 & 21 & female & 7 & 5 & 9 & 11 & 5 & 47 & 6 & 44 & 23 & 21 & 59 & 5.75 & 7.0 & 7.0 & 5900.2 \\\\\n",
       "\t30 & 33 & 5 & 3 & 0.0431343 & 0.0776605 & 0.0603974 & 29 & 86 & 88 & 27 & 59 & 16 & 29 & 11 & 31 & 29 & 60 & 0.15 & 0.2 & 0.65 & 0.6 & 0.135593 & 0.305085 & 0.932203 & 0.733333 & 0.62069 & 0.909091 & 20 & male & 9 & 6 & 8 & 11 & 7 & 54 & 12 & 60 & 31 & 29 & 68 & 3.75 & 7.0 & 7.0 & 6347.62 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "38×44 DataFrame. Omitted printing of 39 columns\n",
       "│ Row │ subjects │ nmissed │ failedfinger │ eye_dropout_s1 │ eye_dropout_s2 │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m       │ \u001b[90mFloat64⍰\u001b[39m       │ \u001b[90mFloat64⍰\u001b[39m       │\n",
       "├─────┼──────────┼─────────┼──────────────┼────────────────┼────────────────┤\n",
       "│ 1   │ 1        │ 0       │ 2            │ 0.0150814      │ 0.00982814     │\n",
       "│ 2   │ 2        │ 2       │ 6            │ 0.0678527      │ 0.0306338      │\n",
       "│ 3   │ 3        │ 4       │ 1            │ 0.0404631      │ 0.0406216      │\n",
       "│ 4   │ 4        │ 0       │ 2            │ 0.0344639      │ 0.0989166      │\n",
       "│ 5   │ 5        │ 2       │ 1            │ 0.192682       │ 0.0886042      │\n",
       "│ 6   │ 6        │ 7       │ 6            │ 0.226035       │ 0.373101       │\n",
       "│ 7   │ 7        │ 2       │ 3            │ 0.0154738      │ 0.0195168      │\n",
       "│ 8   │ 8        │ 4       │ 1            │ 0.0936648      │ 0.0280646      │\n",
       "│ 9   │ 9        │ 0       │ 0            │ 0.00308074     │ 0.00252462     │\n",
       "│ 10  │ 10       │ 1       │ 1            │ 0.00356965     │ 0.00443274     │\n",
       "⋮\n",
       "│ 28  │ 31       │ 0       │ 9            │ 0.096813       │ 0.183352       │\n",
       "│ 29  │ 32       │ 3       │ 4            │ 0.0864721      │ 0.0924759      │\n",
       "│ 30  │ 33       │ 5       │ 3            │ 0.0431343      │ 0.0776605      │\n",
       "│ 31  │ 34       │ 4       │ 2            │ 0.0446211      │ 0.00483035     │\n",
       "│ 32  │ 35       │ 1       │ 2            │ 0.0657007      │ 0.0574983      │\n",
       "│ 33  │ 36       │ 5       │ 3            │ 0.0196676      │ 0.0295088      │\n",
       "│ 34  │ 37       │ 1       │ 9            │ 0.00410249     │ 0.00373083     │\n",
       "│ 35  │ 38       │ 1       │ 3            │ 0.00318681     │ 0.00980935     │\n",
       "│ 36  │ 39       │ 2       │ 1            │ 0.0649174      │ 0.0433804      │\n",
       "│ 37  │ 40       │ 3       │ 3            │ 0.00988646     │ 0.0329601      │\n",
       "│ 38  │ 41       │ 9       │ 3            │ 0.0244525      │ 0.0279757      │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in summary stats as well - can combine with parameters, LOOcv scores etc later on\n",
    "summary_stats = readtable(\"/Users/neil/GitHubRepo/Projects/Aversive2Step/data/processed/data_summary.csv\")\n",
    "\n",
    "#delete subjects 19, 25 and 26\n",
    "summary_stats = summary_stats[summary_stats[:subjects].!=19, :]\n",
    "summary_stats = summary_stats[summary_stats[:subjects].!=25, :]\n",
    "summary_stats = summary_stats[summary_stats[:subjects].!=26, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RL Model (Basic)\n",
    "\n",
    "Model comprises:\n",
    "\n",
    "(1) 3 beta weights - one for MB component, one for TD0 component of MF, one for TD1 component of MF. These beta weights are used to create one composite decision value for each action which is input into softmax to predict choice on each trial.\n",
    "\n",
    "(2) Here there is no seperate trace of Qvals for Pav trials. On Pav trials, agents assume to update the value of the state (just as if they had made a choice to get there).\n",
    "\n",
    "(3) One learning rate for all trial types and updates (i.e. no distinction between Pav and Instrumental or between MB and MF updates). \n",
    "\n",
    "(4) Perseverance parameter to model tendency to simply repeat past choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@everywhere function rl_model(params, data)\n",
    "    \n",
    "    #model parameteres\n",
    "\tbeta_mb = params[1] #weight for MB\n",
    "\tbeta_mf0 = params[2] #weight for MF TD0\n",
    "    beta_mf1 = params[3] #weight for MF TD1\n",
    "    lr = 0.5 + 0.5 * erf(params[4] / sqrt(2)) #learning rate\n",
    "    \n",
    "    # perseveration/stickiness parameter\n",
    "    ps = params[5]\n",
    "            \n",
    "    c1 = data[:c1] # choice 1, 1 and 2 for left vs. right\n",
    "    r = data[:r] # coded as -1 and 1; note that here -1 is shock \n",
    "    s = data[:s] # stage 2 state, coded as 1 and 2 \n",
    "    t = data[:trial] # trial\n",
    "    sub = data[:sub] # subject number\n",
    "    \n",
    "    Q0 = zeros(typeof(beta_mb), 2) #TD0\n",
    "    Q0s2 = zeros(typeof(beta_mb), 2) #values of stage 2 states\n",
    "    Q1 = zeros(typeof(beta_mb), 2) #TD1\n",
    "\tQm = zeros(typeof(beta_mb), 2) #MB values for state most commonly transitioned to for left/right action\n",
    "\n",
    "    #initialize these arrays (will store trial to trial values)\n",
    "    Q0_raw_left = []; Q0_raw_right = [];\n",
    "    Q1_raw_left = []; Q1_raw_right = [];\n",
    "    Q0s2_raw_left = []; Q0s2_raw_right = [];\n",
    "    Q0s2_raw_encounter_check = []; Q0s2_raw_NOTencounter_check = []; \n",
    "    Qd_left = []; Qd_right = [];\n",
    "    \n",
    "    # initialize likelihood\n",
    "    lik = 0 \n",
    "\n",
    "    # tracking previous choice to determine perseveration\n",
    "    prevc = 0 \n",
    "\n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        # store these on each trial        \n",
    "        \n",
    "        # note that Q values are before update occurs on that trial (so can model choice based on existing Qvals)\n",
    "        # model raw values\n",
    "        append!(Q0_raw_left, Q0[1]); append!(Q0_raw_right, Q0[2])\n",
    "        append!(Q1_raw_left, Q1[1]); append!(Q1_raw_right, Q1[2])\n",
    "        append!(Q0s2_raw_left, Q0s2[1]); append!(Q0s2_raw_right, Q0s2[2])\n",
    "        append!(Q0s2_raw_encounter_check, Q0s2[s[i]]); append!(Q0s2_raw_NOTencounter_check, Q0s2[abs(3-s[i])])\n",
    "        \n",
    "        #if a choice trial (won't be the case for the pavlovian trials)\n",
    "        if (c1[i]>0) \n",
    "            \n",
    "            # calculate model-based component of Q values - in this design is simply the value of the state each action most commonly transitions to            \n",
    "\t\t\tQm = [Q0s2[1], Q0s2[2]] #or technically Qm = [.7*Q0[2] + .3*Q0[3],.3*Q0[2] + .7*Q0[3]]           \n",
    "            \n",
    "            # ultimately, the Q-values that determine the decision are a weighted combination of MB and MF values\n",
    "            Qd = beta_mb.* Qm + beta_mf0.*(Q0) + beta_mf1.*(Q1)\n",
    "            \n",
    "            append!(Qd_left, Qd[1]); append!(Qd_right, Qd[2]);\n",
    "\n",
    "            # plus perseveration bonus to last choice \n",
    "\t\t\tif prevc>0\n",
    "\t\t\t\tQd[prevc] += ps # increments Qd[prevc] by ps \n",
    "\t\t\tend\n",
    "            \n",
    "            # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "            # add that likelihood to the running likelihood\n",
    "            lik += Qd[c1[i]] - log(sum(exp.(Qd)))\n",
    "                  \n",
    "            # updates go in here\n",
    "            Q0[c1[i]] = (1-lr) * Q0[c1[i]] + lr*Q0s2[s[i]] #TD0\n",
    "            Q1[c1[i]] = (1-lr) * Q1[c1[i]] + lr*r[i] #TD1\n",
    "\n",
    "            # store previous choice to apply perseverance bonus\n",
    "            prevc = c1[i]\n",
    "\n",
    "        else\n",
    "           \n",
    "            append!(Qd_left, NaN); \n",
    "            append!(Qd_right, NaN)\n",
    "            \n",
    "        end\n",
    "        \n",
    "        #update second stage state values according to outcomes\n",
    "\t\tQ0s2[s[i]] = (1-lr) * Q0s2[s[i]] + lr*r[i]\n",
    "                        \n",
    "\tend\n",
    "\n",
    "    # compile trial by trial values here\n",
    "    trial_data = DataFrame(trial = t,\n",
    "            sub = sub,\n",
    "            choice = c1,\n",
    "            state = s,\n",
    "            reward = r,\n",
    "            Q0_raw_left = Q0_raw_left,\n",
    "            Q0_raw_right = Q0_raw_right,\n",
    "            Q1_raw_left = Q1_raw_left,\n",
    "            Q1_raw_right = Q1_raw_right,\n",
    "            Q0s2_raw_left = Q0s2_raw_left,\n",
    "            Q0s2_raw_right = Q0s2_raw_right,\n",
    "            Qd_left = Qd_left,\n",
    "            Qd_right = Qd_right,\n",
    "            Q0s2_raw_encounter_check = Q0s2_raw_encounter_check,\n",
    "            Q0s2_raw_NOTencounter_check = Q0s2_raw_NOTencounter_check)\n",
    "        \n",
    "    # here if running em you can only return the likelihood\n",
    "    #return -lik\n",
    "    \n",
    "    # but if you run in order to extract trials, subs etc then want to return this\n",
    "    return (-lik, trial_data)\n",
    "       \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Parameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run model for one subject\n",
    "(aids debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.17766166719353"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize parameter structures\n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# run model for sub 1\n",
    "rl_model(betas,df[df[:sub].==subs[1],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run em to get best fit parameters for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 56\n",
      "betas: [0.82, 0.97, 1.68, 0.44, 0.52]\n",
      "sigma: [1.11 0.94 0.73 -0.2 0.57; 0.94 1.52 1.0 -0.89 0.5; 0.73 1.0 1.95 -1.17 0.14; -0.2 -0.89 -1.17 1.23 0.07; 0.57 0.5 0.14 0.07 1.14]\n",
      "change: [0.000386, 0.000526, 1.5e-5, 0.000723, 2.5e-5, 0.000209, 0.000192, 0.000569, -0.002481, 9.7e-5, 0.000225, 0.000568, -0.001655, 6.4e-5, 5.7e-5, -0.000596, 7.6e-5, 0.000989, 1.7e-5, 3.3e-5]\n",
      "max: 0.000989\n",
      " 62.518367 seconds (25.31 M allocations: 1.218 GiB, 1.14% gc time)\n"
     ]
    }
   ],
   "source": [
    "# initialized parameter structures (again)\n",
    "# note that some of the variables (e.g. betas, sigma) are entered and returned by em function \n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# run for full learner\n",
    "# x contains the parameters for each subject (note not the same as variable X)\n",
    "# l and h are per-subject likelihood and hessians\n",
    "@time (betas, sigma, x, l, h) = em(df, subs, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true, quiet=false);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Generate Model Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "IBIC, IAIC and LOOcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 1..2..3..4..5..6..7..8..9..10..11..12..13..14..15..16..17..18..19..20..21..22..23..24..25..26..27..28..29..30..31..32..33..34..35..36..37..38..2115.867328322269"
     ]
    }
   ],
   "source": [
    "## model selection/comparison/scoring\n",
    "\n",
    "# laplace approximation to the aggregate log marginal likelihood of the whole dataset\n",
    "# marginalized over the individual params\n",
    "\n",
    "aggll = lml(x, l, h)\n",
    "\n",
    "# to compare this between models you need to correct for the group-level free parameters\n",
    "# either aic or bic\n",
    "\n",
    "aggll_ibic = ibic(x, l, h, betas, sigma, nrow(df))\n",
    "aggll_iaic = iaic(x, l, h, betas, sigma)\n",
    "\n",
    "# or you can compute unbiased per subject marginal likelihoods via subject-level cross validation\n",
    "# you can do paired t tests on these between models\n",
    "# these are also appropriate for SPM_BMS etc\n",
    "\n",
    "# takes ages so comment in when want to run, otherwise just use IAIC above\n",
    "liks = loocv(df, subs, x, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true)\n",
    "#aggll_loo = sum(liks)\n",
    "\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll: $aggll_iaic\\nloo nll:  $aggll_loo\")\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll:\")\n",
    "print(aggll_iaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Write loocv scores to csv file\n",
    "\n",
    "(if you have run this part above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"loocv_scores.csv\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put loocv scores into dataframe\n",
    "loocv_scores = DataFrame(sub = subs,\n",
    "liks = vec(liks));\n",
    "\n",
    "#write to csv\n",
    "CSV.write(\"loocv_scores.csv\", DataFrame(loocv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Calculate and write p values, std error and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "in #53 at none\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "in #53 at none\n",
      "┌ Warning: `ccdf(d::UnivariateDistribution, X::AbstractArray)` is deprecated, use `ccdf.(d, X)` instead.\n",
      "│   caller = emerrors(::DataFrame, ::Array{Union{Missing, Int64},1}, ::SharedArray{Float64,2}, ::Array{Float64,3}, ::SharedArray{Float64,3}, ::Array{Float64,1}, ::Array{Float64,2}, ::Function) at em.jl:300\n",
      "└ @ Main /Users/neil/GitHubRepo/Projects/Aversive2Step/scripts/models/choices/basic_RL/em.jl:300\n"
     ]
    }
   ],
   "source": [
    "# standard errors on the subject-level means, based on an asymptotic Gaussian approx \n",
    "# (these may be inflated esp for small n)\n",
    "(standarderrors, pvalues, covmtx) = emerrors(df, subs, x, X, h, betas, sigma, rl_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_stats = DataFrame(stderror = vec(standarderrors),\n",
    "pvalues = vec(pvalues),\n",
    "covmtx_1 = vec(covmtx[:,1]),\n",
    "covmtx_2 = vec(covmtx[:,2]),\n",
    "covmtx_3 = vec(covmtx[:,3]),\n",
    "covmtx_4 = vec(covmtx[:,4]),\n",
    "covmtx_5 = vec(covmtx[:,5]));\n",
    "\n",
    "# save model stats to csv file\n",
    "CSV.write(\"model_stats.csv\", DataFrame(model_stats));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.220126, 0.304594, 0.28578, 0.234077, 0.181174]"
     ]
    }
   ],
   "source": [
    "print(standarderrors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000192496, 0.00143686, 4.31146e-9, 0.0613721, 0.00390847]"
     ]
    }
   ],
   "source": [
    "print(pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0484552 0.0230662 0.0202132 -0.00713082 0.0152626; 0.0230662 0.0927777 0.0170571 -0.0270004 0.0109654; 0.0202132 0.0170571 0.08167 -0.0341728 0.00118983; -0.00713082 -0.0270004 -0.0341728 0.0547919 0.00250652; 0.0152626 0.0109654 0.00118983 0.00250652 0.032824]"
     ]
    }
   ],
   "source": [
    "print(covmtx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Write per subject model parameters to csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Save a copy of just the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"subject_params.csv\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put parameters into variable d\n",
    "d=x';\n",
    "\n",
    "# now put parameters into dataframe\n",
    "params = DataFrame(sub = subs,\n",
    "betamb = vec(d[:,1]), \n",
    "beta_mf0 = vec(d[:,2]),\n",
    "beta_mf1 = vec(d[:,3]),\n",
    "eta_unconverted = vec(d[:,4]),\n",
    "eta_converted = vec(0.5 .+ 0.5*erf.(d[:,4] / sqrt(2))),\n",
    "sticky = vec(d[:,5]));\n",
    "\n",
    "# save parameters to csv file\n",
    "CSV.write(\"subject_params.csv\", DataFrame(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Save a copy with summary stats as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"summary_stats.csv\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = params[:,2:end]\n",
    "summary_stats = [summary_stats params]\n",
    "CSV.write(\"summary_stats.csv\", DataFrame(summary_stats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Generate trial by trial values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get best fit parameters from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if you already have best fit parameters saved, can read in here (rather than running model to find)\n",
    "params_full = readtable(\"subject_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run model for each sub using best fit parameters\n",
    "\n",
    "Note: must rerun model with it set to return trial data (uncomment this)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Deprecated syntax `implicit assignment to global variable `x``.\n",
      "│ Use `global x` instead.\n",
      "└ @ nothing none:0\n",
      "┌ Warning: Loop variable `x` around In[22]:6 overwrites a variable in an enclosing scope. In the future the variable will be local to the loop instead.\n",
      "└ @ nothing In[22]:6\n",
      "┌ Warning: `convert(::Type{Array}, dfr::DataFrameRow)` is deprecated, use `permutedims(Vector(dfr))` instead.\n",
      "│   caller = top-level scope at In[22]:12\n",
      "└ @ Core ./In[22]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6752, 5)(6752, 15)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[22]:32\n",
      "└ @ Core In[22]:32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>trial</th><th>sub</th><th>choice</th><th>state</th><th>reward</th><th>Q0_raw_left</th><th>Q0_raw_right</th><th>Q1_raw_left</th><th>Q1_raw_right</th><th>Q0s2_raw_left</th><th>Q0s2_raw_right</th><th>Qd_left</th><th>Qd_right</th><th>Q0s2_raw_encounter_check</th><th>Q0s2_raw_NOTencounter_check</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64</th><th>Float64</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th></tr></thead><tbody><p>6 rows × 15 columns</p><tr><th>1</th><td>1</td><td>1</td><td>-99</td><td>2</td><td>-0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>NaN</td><td>NaN</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>2</td><td>1</td><td>2</td><td>1</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>-0.583678</td><td>0.0</td><td>-0.288255</td></tr><tr><th>3</th><td>3</td><td>1</td><td>2</td><td>2</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.288255</td><td>0.288255</td><td>-0.288255</td><td>0.583678</td><td>0.212897</td><td>-0.288255</td><td>0.288255</td></tr><tr><th>4</th><td>4</td><td>1</td><td>-99</td><td>2</td><td>-0.5</td><td>0.0</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.288255</td><td>0.166181</td><td>NaN</td><td>NaN</td><td>0.166181</td><td>0.288255</td></tr><tr><th>5</th><td>5</td><td>1</td><td>2</td><td>2</td><td>0.5</td><td>0.0</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.288255</td><td>-0.217878</td><td>0.583678</td><td>0.360036</td><td>-0.217878</td><td>0.288255</td></tr><tr><th>6</th><td>6</td><td>1</td><td>1</td><td>1</td><td>0.5</td><td>0.0</td><td>-0.195985</td><td>0.0</td><td>0.462025</td><td>0.288255</td><td>0.195985</td><td>0.583678</td><td>1.28125</td><td>0.288255</td><td>0.195985</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccccccc}\n",
       "\t& trial & sub & choice & state & reward & Q0\\_raw\\_left & Q0\\_raw\\_right & Q1\\_raw\\_left & Q1\\_raw\\_right & Q0s2\\_raw\\_left & Q0s2\\_raw\\_right & Qd\\_left & Qd\\_right & Q0s2\\_raw\\_encounter\\_check & Q0s2\\_raw\\_NOTencounter\\_check\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & -99 & 2 & -0.5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & NaN & NaN & 0.0 & 0.0 \\\\\n",
       "\t2 & 2 & 1 & 2 & 1 & 0.5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & -0.288255 & 0.0 & -0.583678 & 0.0 & -0.288255 \\\\\n",
       "\t3 & 3 & 1 & 2 & 2 & 0.5 & 0.0 & 0.0 & 0.0 & 0.288255 & 0.288255 & -0.288255 & 0.583678 & 0.212897 & -0.288255 & 0.288255 \\\\\n",
       "\t4 & 4 & 1 & -99 & 2 & -0.5 & 0.0 & -0.166181 & 0.0 & 0.410328 & 0.288255 & 0.166181 & NaN & NaN & 0.166181 & 0.288255 \\\\\n",
       "\t5 & 5 & 1 & 2 & 2 & 0.5 & 0.0 & -0.166181 & 0.0 & 0.410328 & 0.288255 & -0.217878 & 0.583678 & 0.360036 & -0.217878 & 0.288255 \\\\\n",
       "\t6 & 6 & 1 & 1 & 1 & 0.5 & 0.0 & -0.195985 & 0.0 & 0.462025 & 0.288255 & 0.195985 & 0.583678 & 1.28125 & 0.288255 & 0.195985 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×15 DataFrame. Omitted printing of 9 columns\n",
       "│ Row │ trial  │ sub    │ choice │ state │ reward  │ Q0_raw_left │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mAny\u001b[39m         │\n",
       "├─────┼────────┼────────┼────────┼───────┼─────────┼─────────────┤\n",
       "│ 1   │ 1      │ 1      │ -99    │ 2     │ -0.5    │ 0.0         │\n",
       "│ 2   │ 2      │ 1      │ 2      │ 1     │ 0.5     │ 0.0         │\n",
       "│ 3   │ 3      │ 1      │ 2      │ 2     │ 0.5     │ 0.0         │\n",
       "│ 4   │ 4      │ 1      │ -99    │ 2     │ -0.5    │ 0.0         │\n",
       "│ 5   │ 5      │ 1      │ 2      │ 2     │ 0.5     │ 0.0         │\n",
       "│ 6   │ 6      │ 1      │ 1      │ 1     │ 0.5     │ 0.0         │"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize parameter structures once again\n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# initalise this - will store all trial to trial parameters\n",
    "trial_data_compile = []\n",
    "\n",
    "# run model for each subject using best fit parameters\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = convert(Array, params[x, [:betamb, :beta_mf0, :beta_mf1, :eta_unconverted, :sticky]])\n",
    "    data_sub = df[df[:sub].==subs[x], :]\n",
    "    \n",
    "    # run model using these parameters - note must have commented in the model to return all of these variables (and not only -lik)\n",
    "    (minus_li, trial_data) = rl_model(betas_sub, data_sub)\n",
    "    \n",
    "    if x.==1\n",
    "        \n",
    "        trial_data_compile = trial_data\n",
    "        \n",
    "    else\n",
    "        \n",
    "        append!(trial_data_compile, trial_data)\n",
    "        \n",
    "    end\n",
    " \n",
    "end\n",
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(trial_data_compile))\n",
    "\n",
    "# print header of data compile\n",
    "head(trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Seperate out Q values for options encountered/not encountered and Q values for options choosen/not choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `find(A::AbstractVector)` is deprecated, use `findall(A)` instead.\n",
      "│   caller = top-level scope at In[23]:1\n",
      "└ @ Core In[23]:1\n",
      "┌ Warning: `find(A::AbstractVector)` is deprecated, use `findall(A)` instead.\n",
      "│   caller = top-level scope at In[23]:3\n",
      "└ @ Core In[23]:3\n",
      "┌ Warning: `find(A::AbstractVector)` is deprecated, use `findall(A)` instead.\n",
      "│   caller = top-level scope at In[23]:25\n",
      "└ @ Core In[23]:25\n",
      "┌ Warning: `find(A::AbstractVector)` is deprecated, use `findall(A)` instead.\n",
      "│   caller = top-level scope at In[23]:28\n",
      "└ @ Core In[23]:28\n",
      "┌ Warning: `find(A::AbstractVector)` is deprecated, use `findall(A)` instead.\n",
      "│   caller = top-level scope at In[23]:29\n",
      "└ @ Core In[23]:29\n",
      "┌ Warning: `find(A::AbstractVector)` is deprecated, use `findall(A)` instead.\n",
      "│   caller = top-level scope at In[23]:52\n",
      "└ @ Core In[23]:52\n",
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[23]:55\n",
      "└ @ Core In[23]:55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>trial</th><th>sub</th><th>choice</th><th>state</th><th>reward</th><th>Q0_raw_left</th><th>Q0_raw_right</th><th>Q1_raw_left</th><th>Q1_raw_right</th><th>Q0s2_raw_left</th><th>Q0s2_raw_right</th><th>Qd_left</th><th>Qd_right</th><th>Q0s2_raw_encounter_check</th><th>Q0s2_raw_NOTencounter_check</th><th>Q0_raw_encounter</th><th>Q0_raw_NOTencounter</th><th>Q1_raw_encounter</th><th>Q1_raw_NOTencounter</th><th>Q0s2_raw_encounter</th><th>Q0s2_raw_NOTencounter</th><th>Q0_raw_choosen</th><th>Q0_raw_NOTchoosen</th><th>Q1_raw_choosen</th><th>Q1_raw_NOTchoosen</th><th>Q0s2_raw_choosen</th><th>Q0s2_raw_NOTchoosen</th><th>QD_raw_choosen</th><th>QD_raw_NOTchoosen</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64</th><th>Float64</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>6 rows × 29 columns</p><tr><th>1</th><td>1</td><td>1</td><td>-99</td><td>2</td><td>-0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>NaN</td><td>NaN</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>2</th><td>2</td><td>1</td><td>2</td><td>1</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>-0.583678</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>-0.583678</td><td>0.0</td></tr><tr><th>3</th><td>3</td><td>1</td><td>2</td><td>2</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.288255</td><td>0.288255</td><td>-0.288255</td><td>0.583678</td><td>0.212897</td><td>-0.288255</td><td>0.288255</td><td>0.0</td><td>0.0</td><td>0.288255</td><td>0.0</td><td>-0.288255</td><td>0.288255</td><td>0.0</td><td>0.0</td><td>0.288255</td><td>0.0</td><td>-0.288255</td><td>0.288255</td><td>0.212897</td><td>0.583678</td></tr><tr><th>4</th><td>4</td><td>1</td><td>-99</td><td>2</td><td>-0.5</td><td>0.0</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.288255</td><td>0.166181</td><td>NaN</td><td>NaN</td><td>0.166181</td><td>0.288255</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.0</td><td>0.166181</td><td>0.288255</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>5</th><td>5</td><td>1</td><td>2</td><td>2</td><td>0.5</td><td>0.0</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.288255</td><td>-0.217878</td><td>0.583678</td><td>0.360036</td><td>-0.217878</td><td>0.288255</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.0</td><td>-0.217878</td><td>0.288255</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.0</td><td>-0.217878</td><td>0.288255</td><td>0.360036</td><td>0.583678</td></tr><tr><th>6</th><td>6</td><td>1</td><td>1</td><td>1</td><td>0.5</td><td>0.0</td><td>-0.195985</td><td>0.0</td><td>0.462025</td><td>0.288255</td><td>0.195985</td><td>0.583678</td><td>1.28125</td><td>0.288255</td><td>0.195985</td><td>0.0</td><td>-0.195985</td><td>0.0</td><td>0.462025</td><td>0.288255</td><td>0.195985</td><td>0.0</td><td>-0.195985</td><td>0.0</td><td>0.462025</td><td>0.288255</td><td>0.195985</td><td>0.583678</td><td>1.28125</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccccccccccccccccccccc}\n",
       "\t& trial & sub & choice & state & reward & Q0\\_raw\\_left & Q0\\_raw\\_right & Q1\\_raw\\_left & Q1\\_raw\\_right & Q0s2\\_raw\\_left & Q0s2\\_raw\\_right & Qd\\_left & Qd\\_right & Q0s2\\_raw\\_encounter\\_check & Q0s2\\_raw\\_NOTencounter\\_check & Q0\\_raw\\_encounter & Q0\\_raw\\_NOTencounter & Q1\\_raw\\_encounter & Q1\\_raw\\_NOTencounter & Q0s2\\_raw\\_encounter & Q0s2\\_raw\\_NOTencounter & Q0\\_raw\\_choosen & Q0\\_raw\\_NOTchoosen & Q1\\_raw\\_choosen & Q1\\_raw\\_NOTchoosen & Q0s2\\_raw\\_choosen & Q0s2\\_raw\\_NOTchoosen & QD\\_raw\\_choosen & QD\\_raw\\_NOTchoosen\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & -99 & 2 & -0.5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & NaN & NaN & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\n",
       "\t2 & 2 & 1 & 2 & 1 & 0.5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & -0.288255 & 0.0 & -0.583678 & 0.0 & -0.288255 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & -0.288255 & 0.0 & 0.0 & 0.0 & 0.0 & -0.288255 & 0.0 & -0.583678 & 0.0 \\\\\n",
       "\t3 & 3 & 1 & 2 & 2 & 0.5 & 0.0 & 0.0 & 0.0 & 0.288255 & 0.288255 & -0.288255 & 0.583678 & 0.212897 & -0.288255 & 0.288255 & 0.0 & 0.0 & 0.288255 & 0.0 & -0.288255 & 0.288255 & 0.0 & 0.0 & 0.288255 & 0.0 & -0.288255 & 0.288255 & 0.212897 & 0.583678 \\\\\n",
       "\t4 & 4 & 1 & -99 & 2 & -0.5 & 0.0 & -0.166181 & 0.0 & 0.410328 & 0.288255 & 0.166181 & NaN & NaN & 0.166181 & 0.288255 & -0.166181 & 0.0 & 0.410328 & 0.0 & 0.166181 & 0.288255 & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\n",
       "\t5 & 5 & 1 & 2 & 2 & 0.5 & 0.0 & -0.166181 & 0.0 & 0.410328 & 0.288255 & -0.217878 & 0.583678 & 0.360036 & -0.217878 & 0.288255 & -0.166181 & 0.0 & 0.410328 & 0.0 & -0.217878 & 0.288255 & -0.166181 & 0.0 & 0.410328 & 0.0 & -0.217878 & 0.288255 & 0.360036 & 0.583678 \\\\\n",
       "\t6 & 6 & 1 & 1 & 1 & 0.5 & 0.0 & -0.195985 & 0.0 & 0.462025 & 0.288255 & 0.195985 & 0.583678 & 1.28125 & 0.288255 & 0.195985 & 0.0 & -0.195985 & 0.0 & 0.462025 & 0.288255 & 0.195985 & 0.0 & -0.195985 & 0.0 & 0.462025 & 0.288255 & 0.195985 & 0.583678 & 1.28125 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×29 DataFrame. Omitted printing of 23 columns\n",
       "│ Row │ trial  │ sub    │ choice │ state │ reward  │ Q0_raw_left │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mAny\u001b[39m         │\n",
       "├─────┼────────┼────────┼────────┼───────┼─────────┼─────────────┤\n",
       "│ 1   │ 1      │ 1      │ -99    │ 2     │ -0.5    │ 0.0         │\n",
       "│ 2   │ 2      │ 1      │ 2      │ 1     │ 0.5     │ 0.0         │\n",
       "│ 3   │ 3      │ 1      │ 2      │ 2     │ 0.5     │ 0.0         │\n",
       "│ 4   │ 4      │ 1      │ -99    │ 2     │ -0.5    │ 0.0         │\n",
       "│ 5   │ 5      │ 1      │ 2      │ 2     │ 0.5     │ 0.0         │\n",
       "│ 6   │ 6      │ 1      │ 1      │ 1     │ 0.5     │ 0.0         │"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for encountered option Q values, index states 1 and 2\n",
    "index_s1 = find(trial_data_compile[:state].==1)\n",
    "index_s2 = find(trial_data_compile[:state].==2)\n",
    "\n",
    "index_encounter = [index_s1; index_s2]\n",
    "\n",
    "# now use indexes to pull out Qvalues for options encountered for Q0, Q1 and Qs (raw and scaled values)\n",
    "# note that state 1 corresponds to left and 2 to right. \n",
    "# therefore if state encountered is 1, then pick left Q value for Q value of the option encountered, \n",
    "# and right Q value for the option not encountered\n",
    "Q0_raw_encounter = [trial_data_compile[index_s1,:Q0_raw_left]; trial_data_compile[index_s2,:Q0_raw_right]]\n",
    "Q0_raw_NOTencounter = [trial_data_compile[index_s1,:Q0_raw_right]; trial_data_compile[index_s2,:Q0_raw_left]]\n",
    "trial_data_compile[:Q0_raw_encounter] = vcat(Q0_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q0_raw_NOTencounter] = vcat(Q0_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q1_raw_encounter = [trial_data_compile[index_s1,:Q1_raw_left]; trial_data_compile[index_s2,:Q1_raw_right]]\n",
    "Q1_raw_NOTencounter = [trial_data_compile[index_s1,:Q1_raw_right]; trial_data_compile[index_s2,:Q1_raw_left]]\n",
    "trial_data_compile[:Q1_raw_encounter] = vcat(Q1_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q1_raw_NOTencounter] = vcat(Q1_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q0s2_raw_encounter = [trial_data_compile[index_s1,:Q0s2_raw_left]; trial_data_compile[index_s2,:Q0s2_raw_right]]\n",
    "Q0s2_raw_NOTencounter = [trial_data_compile[index_s1,:Q0s2_raw_right]; trial_data_compile[index_s2,:Q0s2_raw_left]]\n",
    "trial_data_compile[:Q0s2_raw_encounter] = vcat(Q0s2_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q0s2_raw_NOTencounter] = vcat(Q0s2_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "# for choosen option Q values, index choices 1 and 2 and 99 (so that length of columns is correct)\n",
    "index_c1 = find(trial_data_compile[:choice].==1)\n",
    "index_c2 = find(trial_data_compile[:choice].==2)\n",
    "index_c99 = find(trial_data_compile[:choice].==-99)\n",
    "\n",
    "index_choice = [index_c1; index_c2; index_c99]\n",
    "\n",
    "Q0_raw_choosen = [trial_data_compile[index_c1,:Q0_raw_left]; trial_data_compile[index_c2,:Q0_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q0_raw_NOTchoosen = [trial_data_compile[index_c1,:Q0_raw_right]; trial_data_compile[index_c2,:Q0_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q0_raw_choosen] = vcat(Q0_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q0_raw_NOTchoosen] = vcat(Q0_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "Q1_raw_choosen = [trial_data_compile[index_c1,:Q1_raw_left]; trial_data_compile[index_c2,:Q1_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q1_raw_NOTchoosen = [trial_data_compile[index_c1,:Q1_raw_right]; trial_data_compile[index_c2,:Q1_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q1_raw_choosen] = vcat(Q1_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q1_raw_NOTchoosen] = vcat(Q1_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "Q0s2_raw_choosen = [trial_data_compile[index_c1,:Q0s2_raw_left]; trial_data_compile[index_c2,:Q0s2_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q0s2_raw_NOTchoosen = [trial_data_compile[index_c1,:Q0s2_raw_right]; trial_data_compile[index_c2,:Q0s2_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q0s2_raw_choosen] = vcat(Q0s2_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q0s2_raw_NOTchoosen] = vcat(Q0s2_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "QD_raw_choosen = [trial_data_compile[index_c1,:Qd_left]; trial_data_compile[index_c2,:Qd_right]; trial_data_compile[index_c99,:choice]]\n",
    "QD_raw_NOTchoosen = [trial_data_compile[index_c1,:Qd_right]; trial_data_compile[index_c2,:Qd_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:QD_raw_choosen] = vcat(QD_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:QD_raw_NOTchoosen] = vcat(QD_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "# #replace -99 choices with NaNs for Q values choosen/not choosen\n",
    "trial_data_compile[find(trial_data_compile[:choice].==-99), [:Q0_raw_choosen, :Q0_raw_NOTchoosen, :Q1_raw_choosen, :Q1_raw_NOTchoosen, :Q0s2_raw_choosen, :Q0s2_raw_NOTchoosen, :QD_raw_choosen, :QD_raw_NOTchoosen]] = NaN\n",
    "\n",
    "head(trial_data_compile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Calculate probabilities of choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Deprecated syntax `implicit assignment to global variable `x``.\n",
      "│ Use `global x` instead.\n",
      "└ @ nothing none:0\n",
      "┌ Warning: Loop variable `x` around In[26]:10 overwrites a variable in an enclosing scope. In the future the variable will be local to the loop instead.\n",
      "└ @ nothing In[26]:10\n",
      "┌ Warning: `convert(::Type{Array}, dfr::DataFrameRow)` is deprecated, use `permutedims(Vector(dfr))` instead.\n",
      "│   caller = top-level scope at In[26]:17\n",
      "└ @ Core ./In[26]:17\n"
     ]
    }
   ],
   "source": [
    "#calculate probability of chosen and unchosen from Q values \n",
    "\n",
    "ProbChosen_ALL = []\n",
    "ProbUnchosen_ALL =  []\n",
    "ProbChosen_minus_Unchosen_ALL = []\n",
    "\n",
    "ProbChosen_ALL_MB = []\n",
    "ProbChosen_ALL_MF = []\n",
    "ProbChosen_ALL_MB_min_MF = []\n",
    "\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "    \n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub =     convert(Array, params[x, [:betamb, :beta_mf0, :beta_mf1, :sticky]])\n",
    "    beta_MB = betas_sub[1] #beta MB\n",
    "    betas_MF0 = betas_sub[2] #beta MF0\n",
    "    betas_MF1 = betas_sub[3] #beta MF1\n",
    "    betas_stick = betas_sub[4]    \n",
    "    \n",
    "    subset_data = trial_data_compile[trial_data_compile[:sub].==subs[x], :]\n",
    "    \n",
    "    n_trials = size(subset_data); n_trials = n_trials[1]\n",
    "\n",
    "    ProbChosen = zeros(n_trials)\n",
    "    ProbUnchosen = zeros(n_trials)\n",
    "    ProbChosen_minus_Unchosen = zeros(n_trials)\n",
    "    ProbChosen_MB = zeros(n_trials)\n",
    "    ProbChosen_MF = zeros(n_trials)\n",
    "    \n",
    "    choices = subset_data[:choice]\n",
    "    Q0select = subset_data[:Q0_raw_choosen]\n",
    "    Q0NOTselect = subset_data[:Q0_raw_NOTchoosen] \n",
    "    Q1select = subset_data[:Q1_raw_choosen]\n",
    "    Q1NOTselect = subset_data[:Q1_raw_NOTchoosen] \n",
    "    QSselect = subset_data[:Q0s2_raw_choosen]\n",
    "    QSNOTselect = subset_data[:Q0s2_raw_NOTchoosen] \n",
    "    \n",
    "    prev_choice = NaN;\n",
    "    \n",
    "    for t = 1:n_trials\n",
    "    \n",
    "        curr_choice = choices[t]\n",
    "        \n",
    "        #if not a pav trial \n",
    "        if curr_choice>0\n",
    "            \n",
    "            #if first choice (note first trial will be pav, missed responses already taken out) \n",
    "            #then do not include sticky parameter into softmax\n",
    "            if n_trials == 2\n",
    "                ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t])) \n",
    "                ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                ProbChosen_MB[t] = exp(beta_MB*QSselect[t])/(exp(beta_MB*QSselect[t]) + exp(beta_MB*QSNOTselect[t])) \n",
    "                ProbChosen_MF[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t]) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t]))\n",
    "                prev_choice = curr_choice\n",
    "                \n",
    "            #if not the first choice then do not include sticky parameter into softmax    \n",
    "            elseif n_trials > 2\n",
    "                \n",
    "                # where sticky param is added depends whether the current choice equals the current choice\n",
    "                # if it is then add into the chosen probability\n",
    "                if curr_choice==prev_choice\n",
    "                    ProbChosen[t] = exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + betas_stick)/(exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + betas_stick) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t])) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t];\n",
    "                    ProbChosen_MB[t] = exp(beta_MB*QSselect[t] + betas_stick)/(exp(beta_MB*QSselect[t] + betas_stick) + exp(beta_MB*QSNOTselect[t])) \n",
    "                    ProbChosen_MF[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + betas_stick)/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + betas_stick) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t])) \n",
    "                    prev_choice = curr_choice;\n",
    "                # if it is then add into the not chosen probability\n",
    "                elseif curr_choice!=prev_choice\n",
    "                    ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + exp((betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t]) + betas_stick)) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                    ProbChosen_MB[t] = exp(beta_MB*QSselect[t])/(exp(beta_MB*QSselect[t]) + exp((beta_MB*QSNOTselect[t]) + betas_stick)) \n",
    "                    ProbChosen_MF[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t]) + exp((betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t]) + betas_stick)) \n",
    "                    prev_choice = curr_choice;\n",
    "                end\n",
    "                \n",
    "            end\n",
    "                \n",
    "        else\n",
    "            \n",
    "            ProbChosen[t]  = NaN;\n",
    "            ProbUnchosen[t] = NaN;\n",
    "            ProbChosen_minus_Unchosen[t] = NaN;\n",
    "            ProbChosen_MB[t] = NaN;\n",
    "            ProbChosen_MF[t] = NaN;\n",
    "            \n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    ProbChosen_ALL = [ProbChosen_ALL; ProbChosen];\n",
    "    ProbUnchosen_ALL = [ProbUnchosen_ALL; ProbUnchosen];\n",
    "    ProbChosen_minus_Unchosen_ALL = [ProbChosen_minus_Unchosen_ALL; ProbChosen_minus_Unchosen];\n",
    "    ProbChosen_ALL_MB = [ProbChosen_ALL_MB; ProbChosen_MB];\n",
    "    ProbChosen_ALL_MF = [ProbChosen_ALL_MF; ProbChosen_MF];\n",
    "    ProbChosen_ALL_MB_min_MF = [ProbChosen_ALL_MB_min_MF; ProbChosen_MB - ProbChosen_MF];\n",
    "\n",
    "end\n",
    "\n",
    "#Now bung into data frame and merge with rest\n",
    "Q_probs = DataFrame([ProbChosen_ALL, \n",
    "        ProbUnchosen_ALL, \n",
    "        ProbChosen_minus_Unchosen_ALL,\n",
    "        ProbChosen_ALL_MB,\n",
    "        ProbChosen_ALL_MF,\n",
    "        ProbChosen_ALL_MB_min_MF])\n",
    "        \n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_probs, [:ProbChosen, \n",
    "        :ProbUnchosen, \n",
    "        :ProbChosen_minus_Unchosen,\n",
    "        :ProbChosen_MB,\n",
    "        :ProbChosen_MF,\n",
    "        :ProbChosen_MB_min_MF])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous full compile)\n",
    "trial_data_compile = hcat(trial_data_compile, Q_probs); #could also do just: [full_Q_compile Q_probs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[27]:1\n",
      "└ @ Core In[27]:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>trial</th><th>sub</th><th>choice</th><th>state</th><th>reward</th><th>Q0_raw_left</th><th>Q0_raw_right</th><th>Q1_raw_left</th><th>Q1_raw_right</th><th>Q0s2_raw_left</th><th>Q0s2_raw_right</th><th>Qd_left</th><th>Qd_right</th><th>Q0s2_raw_encounter_check</th><th>Q0s2_raw_NOTencounter_check</th><th>Q0_raw_encounter</th><th>Q0_raw_NOTencounter</th><th>Q1_raw_encounter</th><th>Q1_raw_NOTencounter</th><th>Q0s2_raw_encounter</th><th>Q0s2_raw_NOTencounter</th><th>Q0_raw_choosen</th><th>Q0_raw_NOTchoosen</th><th>Q1_raw_choosen</th><th>Q1_raw_NOTchoosen</th><th>Q0s2_raw_choosen</th><th>Q0s2_raw_NOTchoosen</th><th>QD_raw_choosen</th><th>QD_raw_NOTchoosen</th><th>ProbChosen</th><th>ProbUnchosen</th><th>ProbChosen_minus_Unchosen</th><th>ProbChosen_MB</th><th>ProbChosen_MF</th><th>ProbChosen_MB_min_MF</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64</th><th>Float64</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th><th>Any</th></tr></thead><tbody><p>6 rows × 35 columns</p><tr><th>1</th><td>1</td><td>1</td><td>-99</td><td>2</td><td>-0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>NaN</td><td>NaN</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>2</th><td>2</td><td>1</td><td>2</td><td>1</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>-0.583678</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.288255</td><td>0.0</td><td>-0.583678</td><td>0.0</td><td>0.152752</td><td>0.847248</td><td>-0.694497</td><td>0.152752</td><td>0.244253</td><td>-0.0915013</td></tr><tr><th>3</th><td>3</td><td>1</td><td>2</td><td>2</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.288255</td><td>0.288255</td><td>-0.288255</td><td>0.583678</td><td>0.212897</td><td>-0.288255</td><td>0.288255</td><td>0.0</td><td>0.0</td><td>0.288255</td><td>0.0</td><td>-0.288255</td><td>0.288255</td><td>0.0</td><td>0.0</td><td>0.288255</td><td>0.0</td><td>-0.288255</td><td>0.288255</td><td>0.212897</td><td>0.583678</td><td>0.681076</td><td>0.318924</td><td>0.362152</td><td>0.490537</td><td>0.872815</td><td>-0.382277</td></tr><tr><th>4</th><td>4</td><td>1</td><td>-99</td><td>2</td><td>-0.5</td><td>0.0</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.288255</td><td>0.166181</td><td>NaN</td><td>NaN</td><td>0.166181</td><td>0.288255</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.0</td><td>0.166181</td><td>0.288255</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>5</th><td>5</td><td>1</td><td>2</td><td>2</td><td>0.5</td><td>0.0</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.288255</td><td>-0.217878</td><td>0.583678</td><td>0.360036</td><td>-0.217878</td><td>0.288255</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.0</td><td>-0.217878</td><td>0.288255</td><td>-0.166181</td><td>0.0</td><td>0.410328</td><td>0.0</td><td>-0.217878</td><td>0.288255</td><td>0.360036</td><td>0.583678</td><td>0.712152</td><td>0.287848</td><td>0.424305</td><td>0.526138</td><td>0.873328</td><td>-0.34719</td></tr><tr><th>6</th><td>6</td><td>1</td><td>1</td><td>1</td><td>0.5</td><td>0.0</td><td>-0.195985</td><td>0.0</td><td>0.462025</td><td>0.288255</td><td>0.195985</td><td>0.583678</td><td>1.28125</td><td>0.288255</td><td>0.195985</td><td>0.0</td><td>-0.195985</td><td>0.0</td><td>0.462025</td><td>0.288255</td><td>0.195985</td><td>0.0</td><td>-0.195985</td><td>0.0</td><td>0.462025</td><td>0.288255</td><td>0.195985</td><td>0.583678</td><td>1.28125</td><td>0.138587</td><td>0.861413</td><td>-0.722825</td><td>0.280362</td><td>0.117751</td><td>0.162611</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccccccccccccccccccccccccccc}\n",
       "\t& trial & sub & choice & state & reward & Q0\\_raw\\_left & Q0\\_raw\\_right & Q1\\_raw\\_left & Q1\\_raw\\_right & Q0s2\\_raw\\_left & Q0s2\\_raw\\_right & Qd\\_left & Qd\\_right & Q0s2\\_raw\\_encounter\\_check & Q0s2\\_raw\\_NOTencounter\\_check & Q0\\_raw\\_encounter & Q0\\_raw\\_NOTencounter & Q1\\_raw\\_encounter & Q1\\_raw\\_NOTencounter & Q0s2\\_raw\\_encounter & Q0s2\\_raw\\_NOTencounter & Q0\\_raw\\_choosen & Q0\\_raw\\_NOTchoosen & Q1\\_raw\\_choosen & Q1\\_raw\\_NOTchoosen & Q0s2\\_raw\\_choosen & Q0s2\\_raw\\_NOTchoosen & QD\\_raw\\_choosen & QD\\_raw\\_NOTchoosen & ProbChosen & ProbUnchosen & ProbChosen\\_minus\\_Unchosen & ProbChosen\\_MB & ProbChosen\\_MF & ProbChosen\\_MB\\_min\\_MF\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & -99 & 2 & -0.5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & NaN & NaN & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\n",
       "\t2 & 2 & 1 & 2 & 1 & 0.5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & -0.288255 & 0.0 & -0.583678 & 0.0 & -0.288255 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & -0.288255 & 0.0 & 0.0 & 0.0 & 0.0 & -0.288255 & 0.0 & -0.583678 & 0.0 & 0.152752 & 0.847248 & -0.694497 & 0.152752 & 0.244253 & -0.0915013 \\\\\n",
       "\t3 & 3 & 1 & 2 & 2 & 0.5 & 0.0 & 0.0 & 0.0 & 0.288255 & 0.288255 & -0.288255 & 0.583678 & 0.212897 & -0.288255 & 0.288255 & 0.0 & 0.0 & 0.288255 & 0.0 & -0.288255 & 0.288255 & 0.0 & 0.0 & 0.288255 & 0.0 & -0.288255 & 0.288255 & 0.212897 & 0.583678 & 0.681076 & 0.318924 & 0.362152 & 0.490537 & 0.872815 & -0.382277 \\\\\n",
       "\t4 & 4 & 1 & -99 & 2 & -0.5 & 0.0 & -0.166181 & 0.0 & 0.410328 & 0.288255 & 0.166181 & NaN & NaN & 0.166181 & 0.288255 & -0.166181 & 0.0 & 0.410328 & 0.0 & 0.166181 & 0.288255 & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\n",
       "\t5 & 5 & 1 & 2 & 2 & 0.5 & 0.0 & -0.166181 & 0.0 & 0.410328 & 0.288255 & -0.217878 & 0.583678 & 0.360036 & -0.217878 & 0.288255 & -0.166181 & 0.0 & 0.410328 & 0.0 & -0.217878 & 0.288255 & -0.166181 & 0.0 & 0.410328 & 0.0 & -0.217878 & 0.288255 & 0.360036 & 0.583678 & 0.712152 & 0.287848 & 0.424305 & 0.526138 & 0.873328 & -0.34719 \\\\\n",
       "\t6 & 6 & 1 & 1 & 1 & 0.5 & 0.0 & -0.195985 & 0.0 & 0.462025 & 0.288255 & 0.195985 & 0.583678 & 1.28125 & 0.288255 & 0.195985 & 0.0 & -0.195985 & 0.0 & 0.462025 & 0.288255 & 0.195985 & 0.0 & -0.195985 & 0.0 & 0.462025 & 0.288255 & 0.195985 & 0.583678 & 1.28125 & 0.138587 & 0.861413 & -0.722825 & 0.280362 & 0.117751 & 0.162611 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×35 DataFrame. Omitted printing of 29 columns\n",
       "│ Row │ trial  │ sub    │ choice │ state │ reward  │ Q0_raw_left │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mAny\u001b[39m         │\n",
       "├─────┼────────┼────────┼────────┼───────┼─────────┼─────────────┤\n",
       "│ 1   │ 1      │ 1      │ -99    │ 2     │ -0.5    │ 0.0         │\n",
       "│ 2   │ 2      │ 1      │ 2      │ 1     │ 0.5     │ 0.0         │\n",
       "│ 3   │ 3      │ 1      │ 2      │ 2     │ 0.5     │ 0.0         │\n",
       "│ 4   │ 4      │ 1      │ -99    │ 2     │ -0.5    │ 0.0         │\n",
       "│ 5   │ 5      │ 1      │ 2      │ 2     │ 0.5     │ 0.0         │\n",
       "│ 6   │ 6      │ 1      │ 1      │ 1     │ 0.5     │ 0.0         │"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save data to csv in model folder\n",
    "NOTE: after this note you must save as an xlsx file to run in matlab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"trial_data_compile.csv\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"trial_data_compile.csv\", DataFrame(trial_data_compile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load in pupil data for each timepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
