{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### script which runs baseline model, finds best fir params and then seperately extracts Q values for each subject trial by trial \n",
    "#### no seperate trace of Qvals for Pav trials\n",
    "#### one learning rate for all trial types\n",
    "\n",
    "#### note don't run all at once. First run models to generate best fit params for each subject\n",
    "#### then edit models to return additional variables and run bottom half (which brings back Q values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set everything up\n",
    "parallel = false # Run on multiple CPUs. If you are having trouble, set parallel = false: easier to debug\n",
    "\n",
    "full = false     # Maintain full covariance matrix (vs a diagional one) at the group level. \n",
    "                # may want to make this false for complicated models\n",
    "\n",
    "emtol = 1e-3    # tolerance for em convergence\n",
    "\n",
    "\n",
    "# this activates the multiprocessing threads\n",
    "\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "\taddprocs()\n",
    "end\n",
    "\n",
    "# load required libraries\n",
    "\n",
    "using DataFrames\n",
    "using ForwardDiff\n",
    "using PyCall\n",
    "using Distributions\n",
    "@everywhere PyCall.@pyimport scipy.optimize as so\n",
    "\n",
    "# this is the code for the actual fitting routines\n",
    "@everywhere include(\"em.jl\")\n",
    "@everywhere include(\"common.jl\")\n",
    "@everywhere include(\"likfuns.jl\")\n",
    "\n",
    "# this is generates starting matricies for betas, sigmas etc to feed into model\n",
    "@everywhere include(\"genVars.jl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sub</th><th>trial</th><th>c1</th><th>s</th><th>r</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>1</td><td>-99</td><td>2</td><td>-1</td></tr><tr><th>2</th><td>1</td><td>2</td><td>2</td><td>1</td><td>1</td></tr><tr><th>3</th><td>1</td><td>3</td><td>2</td><td>2</td><td>1</td></tr><tr><th>4</th><td>1</td><td>4</td><td>-99</td><td>2</td><td>-1</td></tr><tr><th>5</th><td>1</td><td>5</td><td>2</td><td>2</td><td>1</td></tr><tr><th>6</th><td>1</td><td>6</td><td>1</td><td>1</td><td>1</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×5 DataFrames.DataFrame\n",
       "│ Row │ sub │ trial │ c1  │ s │ r  │\n",
       "├─────┼─────┼───────┼─────┼───┼────┤\n",
       "│ 1   │ 1   │ 1     │ -99 │ 2 │ -1 │\n",
       "│ 2   │ 1   │ 2     │ 2   │ 1 │ 1  │\n",
       "│ 3   │ 1   │ 3     │ 2   │ 2 │ 1  │\n",
       "│ 4   │ 1   │ 4     │ -99 │ 2 │ -1 │\n",
       "│ 5   │ 1   │ 5     │ 2   │ 2 │ 1  │\n",
       "│ 6   │ 1   │ 6     │ 1   │ 1 │ 1  │"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv file of the data\n",
    "df = readtable(\"/Users/neil/Dropbox/Daw_Lab/TwoStepAversive/data/julia_raw_data_ex_19_25_26.csv\")\n",
    "\n",
    "#change states from 2,3 to 1,2\n",
    "df[:s] = df[:s]-1\n",
    "\n",
    "#display header\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First get best fit parameters for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91msyntax: incomplete: \"function\" at In[3]:2 requires end\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91msyntax: incomplete: \"function\" at In[3]:2 requires end\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "# model free only\n",
    "@everywhere function MF_learner(params, data)\n",
    "    \n",
    "\tbeta_mf0 = params[1]\n",
    "    beta_mf1 = params[2]    \n",
    "    lr = 0.5 + 0.5 * erf(params[3] / sqrt(2)) #some weird means of constraining learning rate. note that learning rate that pops out needs to be converted\n",
    "    ps = params[4] #perseveration/stickiness parameter\n",
    "    #decay_param = 0.5 + 0.5 * erf(params[5] / sqrt(2))\n",
    "\n",
    "    c1 = data[:c1] # choice 1, 1 and 2 for left vs. right\n",
    "    r = data[:r] # coded as -1 and 1, here -1., note that here -1 is shock \n",
    "    s = data[:s] # stage 2 state, coded as 1 and 2 \n",
    "    t = data[:trial]\n",
    "    sub = data[:sub]\n",
    "\n",
    "    Q0 = zeros(typeof(beta_mf0),2) # c1, left vs. right\n",
    "    Q0s2 = zeros(typeof(beta_mf0),2) # values of stage 2 states\n",
    "    Q1 = zeros(typeof(beta_mf0),2) #\n",
    "\tQm = zeros(typeof(beta_mf0),2) \n",
    "\n",
    "    trial_store = zeros(typeof(beta_mf0),1)\n",
    "    sub_store = zeros(typeof(beta_mf0),1) \n",
    "    \n",
    "    Q0_store_raw = zeros(typeof(beta_mf0),2)\n",
    "    Q1_store_raw = zeros(typeof(beta_mf0),2)\n",
    "    Q0s2_store_raw = zeros(typeof(beta_mf0),2)\n",
    "    \n",
    "    Q0_store_rescaled = zeros(typeof(beta_mf0),2)\n",
    "    Q1_store_rescaled = zeros(typeof(beta_mf0),2)\n",
    "    Q0s2_store_rescaled = zeros(typeof(beta_mf0),2)\n",
    "    \n",
    "    PE0_store = zeros(typeof(beta_mf0),1)\n",
    "    PE1_store = zeros(typeof(beta_mf0),1)\n",
    "    PES_store = zeros(typeof(beta_mf0),1)\n",
    "    \n",
    "    lik = 0 # initialize likelihood\n",
    "\n",
    "    prevc = 0 # tracking previous choice to determine perseveration\n",
    "\n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        #store these badgers\n",
    "        \n",
    "        trial_store = [trial_store t[i]]\n",
    "        sub_store = [sub_store sub[i]]\n",
    "        \n",
    "        Q0_store_raw = [Q0_store_raw Q0]\n",
    "        Q1_store_raw = [Q1_store_raw Q1]\n",
    "        Q0s2_store_raw = [Q0s2_store_raw Q0s2]\n",
    "        \n",
    "        Q0_store_rescaled = [Q0_store_rescaled lr^2.*Q0]\n",
    "        Q1_store_rescaled = [Q1_store_rescaled lr.*Q1]\n",
    "        Q0s2_store_rescaled = [Q0s2_store_rescaled lr.*Q0s2]\n",
    "        \n",
    "        if (c1[i]>0) # won't be the case for the pavlovian trials\n",
    "            \n",
    "            \n",
    "\t\t\tQm = [Q0s2[1],Q0s2[2]]          \n",
    "            \n",
    "            # ultimately, the Q-values that determine the decision are a weighted combination of MB and MF values\n",
    "            # why only take Q0[1] and not both vals?\n",
    "            Qd = beta_mf0 *(Q0) + beta_mf1 *(Q1)\n",
    "            \n",
    "            # plus perseveration bonus to last choice \n",
    "            # potentially consider different perseveration\n",
    "\t\t\tif prevc>0\n",
    "\t\t\t\tQd[prevc] += ps #increments Qd[prevc] by ps \n",
    "\t\t\tend\n",
    "            \n",
    "            # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "            # add that likelihood to the running likelihood\n",
    "\t\t\tlik += Qd[c1[i]] - log(sum(exp(Qd)))\n",
    "            \n",
    "            #store these\n",
    "            PE0_store = [PE0_store lr*Q0s2[s[i]] - lr^2*(Q0[c1[i]])]\n",
    "            PE1_store = [PE1_store r[i] - lr*(Q1[c1[i]])]\n",
    "            \n",
    "            Q0[c1[i]] = (1-lr) * Q0[c1[i]] + Q0s2[s[i]] # TD0 \n",
    "            Q1[c1[i]] = (1-lr) * Q1[c1[i]] + r[i] # TD1\n",
    "                        \n",
    "            #here add in decay - assuming you apply to this\n",
    "            #tmp_index_choice = mod(c1[i],2) + 1\n",
    "        \n",
    "            #Q0[tmp_index_choice] = (1-decay_param) * Q0[tmp_index_choice]\n",
    "            #Q1[tmp_index_choice] = (1-decay_param) * Q1[tmp_index_choice]\n",
    "            \n",
    "            prevc = c1[i]\n",
    "            \n",
    "        else\n",
    "            \n",
    "            #cannot store for these - note though that there is a TD0 for Pav potentially \n",
    "            PE0_store = [PE0_store NaN]\n",
    "            PE1_store = [PE1_store NaN]\n",
    "            \n",
    "        end\n",
    "        \n",
    "        if s[i]==1\n",
    "                PES_store = [PES_store lr*Q0s2[1] - lr*Q0s2[s[i]]]\n",
    "        else\n",
    "            \n",
    "        PES_store = [PES_store lr*Q0s2[c1[i]] - lr*Q0s2[s[i]]]\n",
    "        \n",
    "\t\tQ0s2[s[i]] = (1-lr) * Q0s2[s[i]] + r[i]\n",
    "        \n",
    "        #here put in decay\n",
    "        #tmp_index = mod(s[i],2) + 1\n",
    "        #Q0s2[tmp_index] = (1-decay_param) * Q0s2[tmp_index]\n",
    "\n",
    "        \n",
    "\tend\n",
    "    \n",
    "        # here if running em you can only return the likelihood\n",
    "        return -lik\n",
    "    \n",
    "        # but if you run in order to extract trials, subs etc then want to return this\n",
    "        #return (-lik, trial_store, sub_store, Q0_store_raw, Q1_store_raw, Q0s2_store_raw, Q0_store_rescaled, Q1_store_rescaled, Q0s2_store_rescaled, PE0_store, PE1_store, PES_store)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialized parameter structures for MF\n",
    "(data_MF_learner, subs_MF_learner, X_MF_learner, betas_MF_learner, sigma_MF_learner) = genVars(df, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: MF_learner not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: MF_learner not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "# run em for MF learners\n",
    "@time (betas_MF_learner, sigma_MF_learner, x_MF_learner, l_MF_learner, h_MF_learner) = em(data_MF_learner, subs_MF_learner, X_MF_learner, betas_MF_learner, sigma_MF_learner, MF_learner; emtol=1e-3, parallel=false, full=false, quiet=false);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=x_MF_learner';\n",
    "params_MF = DataFrame(sub = subs_MF_learner,\n",
    "betamf0=vec(d[:,1]), \n",
    "betamf1=vec(d[:,2]), \n",
    "eta_unconverted=vec(d[:,3]),\n",
    "eta_converted=vec(0.5 + 0.5 * erf(d[:,3] / sqrt(2))),\n",
    "sticky=vec(d[:,4]));\n",
    "\n",
    "#save parameters to csv file\n",
    "writetable(\"subject_params_MF_learner.csv\", DataFrame(params_MF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model based only\n",
    "@everywhere function MB_learner(params, data)\n",
    "\tbeta_mb = params[1]\n",
    "\tbeta_mf0 = 0\n",
    "    beta_mf1 = 0\n",
    "\n",
    "    lr = 0.5 + 0.5 * erf(params[2] / sqrt(2)) #some weird means of constraining learning rate. note that learning rate that pops out needs to be converted\n",
    "  \n",
    "    ps = params[3] #perseveration/stickiness parameter\n",
    "    \n",
    "   # decay_param = 0.5 + 0.5 * erf(params[4] / sqrt(2))\n",
    "    \n",
    "    c1 = data[:c1] # choice 1, 1 and 2 for left vs. right\n",
    "    r = data[:r] # coded as -1 and 1, here -1., note that here -1 is shock \n",
    "    s = data[:s] # stage 2 state, coded as 1 and 2 \n",
    "    t = data[:trial]\n",
    "    sub = data[:sub]\n",
    "    \n",
    "    Q0 = zeros(typeof(beta_mb),2) # c1, left vs. right\n",
    "    Q0s2 = zeros(typeof(beta_mb),2) # values of stage 2 states\n",
    "    Q1 = zeros(typeof(beta_mb),2) #\n",
    "\tQm = zeros(typeof(beta_mb),2)    \n",
    "        \n",
    "    trial_store = zeros(typeof(beta_mf0),1)\n",
    "    sub_store = zeros(typeof(beta_mf0),1) \n",
    "    \n",
    "    Q0_store_raw = zeros(typeof(beta_mb),2)\n",
    "    Q1_store_raw = zeros(typeof(beta_mb),2)\n",
    "    Q0s2_store_raw = zeros(typeof(beta_mb),2)\n",
    "    \n",
    "    Q0_store_rescaled = zeros(typeof(beta_mb),2)\n",
    "    Q1_store_rescaled = zeros(typeof(beta_mb),2)\n",
    "    Q0s2_store_rescaled = zeros(typeof(beta_mb),2)\n",
    "    \n",
    "    PE0_store = zeros(typeof(beta_mb),1)\n",
    "    PE1_store = zeros(typeof(beta_mb),1)\n",
    "    PES_store = zeros(typeof(beta_mb),1)\n",
    "    \n",
    "    lik = 0 # initialize likelihood\n",
    "\n",
    "    prevc = 0 # tracking previous choice to determine perseveration\n",
    "\n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        #store these badgers\n",
    "        trial_store = [trial_store t[i]]\n",
    "        sub_store = [sub_store sub[i]]\n",
    "        \n",
    "        Q0_store_raw = [Q0_store_raw Q0]\n",
    "        Q1_store_raw = [Q1_store_raw Q1]\n",
    "        Q0s2_store_raw = [Q0s2_store_raw Q0s2]\n",
    "        \n",
    "        Q0_store_rescaled = [Q0_store_rescaled lr^2.*Q0]\n",
    "        Q1_store_rescaled = [Q1_store_rescaled lr.*Q1]\n",
    "        Q0s2_store_rescaled = [Q0s2_store_rescaled lr.*Q0s2]\n",
    "        \n",
    "        if (c1[i]>0) # won't be the case for the pavlovian trials\n",
    "            \n",
    "            # calculate model-based component of Q values\n",
    "            # the Q for the ending states are usually given by roughly the maximum of the ending states\n",
    "            # Qm = [softmaximum(Q0[2,1],Q0[2,2]),softmaximum(Q0[3,1],Q0[3,2])]\n",
    "            \n",
    "\t\t\tQm = [Q0s2[1],Q0s2[2]] # or technically Qm = [.7*Q0[2] + .3*Q0[3],.3*Q0[2] + .7*Q0[3]]           \n",
    "            \n",
    "            # ultimately, the Q-values that determine the decision are a weighted combination of MB and MF values\n",
    "            # why only take Q0[1] and not both vals?\n",
    "            Qd = beta_mb * Qm \n",
    "            \n",
    "            # plus perseveration bonus to last choice \n",
    "            # potentially consider different perseveration\n",
    "\t\t\tif prevc>0\n",
    "\t\t\t\tQd[prevc] += ps #increments Qd[prevc] by ps \n",
    "\t\t\tend\n",
    "            \n",
    "            # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "            # add that likelihood to the running likelihood\n",
    "\t\t\tlik += Qd[c1[i]] - log(sum(exp(Qd)))\n",
    "            \n",
    "            PE0_store = [PE0_store lr*Q0s2[s[i]] - lr^2*(Q0[c1[i]])]\n",
    "            PE1_store = [PE1_store r[i] - lr*(Q1[c1[i]])]\n",
    "            \n",
    "            Q0[c1[i]] = (1-lr) * Q0[c1[i]] + Q0s2[s[i]] # TD0 \n",
    "            Q1[c1[i]] = (1-lr) * Q1[c1[i]] + r[i] # TD1\n",
    "            \n",
    "            #here add in decay - assuming you apply to this\n",
    "            #tmp_index_choice = mod(c1[i],2) + 1\n",
    "        \n",
    "            #Q0[tmp_index_choice] = (1-decay_param) * Q0[tmp_index_choice]\n",
    "            #Q1[tmp_index_choice] = (1-decay_param) * Q1[tmp_index_choice]\n",
    "            \n",
    "            prevc = c1[i]\n",
    "            \n",
    "        else\n",
    "            \n",
    "            #cannot store for these - note though that there is a TD0 for Pav potentially \n",
    "            PE0_store = [PE0_store NaN]\n",
    "            PE1_store = [PE1_store NaN]\n",
    "            \n",
    "        end\n",
    "        \n",
    "        PES_store = [PES_store lr*Q0s2[c1[i]] - lr*Q0s2[s[i]]]\n",
    "\n",
    "\t\tQ0s2[s[i]] = (1-lr) * Q0s2[s[i]] + r[i]\n",
    "                \n",
    "        #here put in decay\n",
    "        #tmp_index = mod(s[i],2) + 1\n",
    "        #Q0s2[tmp_index] = (1-decay_param) * Q0s2[tmp_index]\n",
    "\n",
    "\tend\n",
    "\n",
    "        # here if running em you can only return the likelihood\n",
    "        return -lik\n",
    "    \n",
    "        # but if you run in order to extract trials, subs etc then want to return this\n",
    "        #return (-lik, trial_store, sub_store, Q0_store_raw, Q1_store_raw, Q0s2_store_raw, Q0_store_rescaled, Q1_store_rescaled, Q0s2_store_rescaled, PE0_store, PE1_store, PES_store)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(data_MB_learner, subs_MB_learner, X_MB_learner, betas_MB_learner, sigma_MB_learner) = genVars(df, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.."
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "PyError (:PyObject_Call) <type 'exceptions.IndexError'>\nIndexError('Julia exception: BoundsError([0.0,0.0],(-99,))',)\n  File \"/Users/neil/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/scipy/optimize/_minimize.py\", line 450, in minimize\n    callback=callback, **options)\n  File \"/Users/neil/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py\", line 328, in _minimize_lbfgsb\n    f, g = func_and_grad(x)\n  File \"/Users/neil/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py\", line 278, in func_and_grad\n    f = fun(x, *args)\n  File \"/Users/neil/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/scipy/optimize/optimize.py\", line 292, in function_wrapper\n    return function(*(wrapper_args + args))\n",
     "output_type": "error",
     "traceback": [
      "PyError (:PyObject_Call) <type 'exceptions.IndexError'>\nIndexError('Julia exception: BoundsError([0.0,0.0],(-99,))',)\n  File \"/Users/neil/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/scipy/optimize/_minimize.py\", line 450, in minimize\n    callback=callback, **options)\n  File \"/Users/neil/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py\", line 328, in _minimize_lbfgsb\n    f, g = func_and_grad(x)\n  File \"/Users/neil/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py\", line 278, in func_and_grad\n    f = fun(x, *args)\n  File \"/Users/neil/.julia/v0.5/Conda/deps/usr/lib/python2.7/site-packages/scipy/optimize/optimize.py\", line 292, in function_wrapper\n    return function(*(wrapper_args + args))\n",
      "",
      " in pyerr_check at /Users/neil/.julia/v0.5/PyCall/src/exception.jl:56 [inlined]",
      " in pyerr_check at /Users/neil/.julia/v0.5/PyCall/src/exception.jl:61 [inlined]",
      " in macro expansion at /Users/neil/.julia/v0.5/PyCall/src/exception.jl:81 [inlined]",
      " in #_pycall#66(::Array{Any,1}, ::Function, ::PyCall.PyObject, ::Function, ::Vararg{Any,N}) at /Users/neil/.julia/v0.5/PyCall/src/PyCall.jl:658",
      " in (::PyCall.#kw##_pycall)(::Array{Any,1}, ::PyCall.#_pycall, ::PyCall.PyObject, ::Function, ::Vararg{Any,N}) at ./<missing>:0",
      " in #pycall#70(::Array{Any,1}, ::Function, ::PyCall.PyObject, ::Type{PyCall.PyAny}, ::Function, ::Vararg{Any,N}) at /Users/neil/.julia/v0.5/PyCall/src/PyCall.jl:675",
      " in (::PyCall.#kw##pycall)(::Array{Any,1}, ::PyCall.#pycall, ::PyCall.PyObject, ::Type{PyCall.PyAny}, ::Function, ::Vararg{Any,N}) at ./<missing>:0",
      " in #call#71(::Array{Any,1}, ::PyCall.PyObject, ::Function, ::Vararg{Any,N}) at /Users/neil/.julia/v0.5/PyCall/src/PyCall.jl:678",
      " in (::PyCall.#kw#PyObject)(::Array{Any,1}, ::PyCall.PyObject, ::Function, ::Vararg{Any,N}) at ./<missing>:0",
      " in optimizesubjectpython(::Function, ::Array{Float64,1}) at /Users/neil/Dropbox/Daw_Lab/TwoStepAversive/models/model1/common.jl:14",
      " in #estep#21(::Bool, ::Function, ::DataFrames.DataFrame, ::DataArrays.DataArray{Int64,1}, ::Array{Float64,2}, ::Array{Float64,3}, ::Array{Any,1}, ::Diagonal{Float64}, ::#MB_learner) at /Users/neil/Dropbox/Daw_Lab/TwoStepAversive/models/model1/em.jl:113",
      " in (::#kw##estep)(::Array{Any,1}, ::#estep, ::DataFrames.DataFrame, ::DataArrays.DataArray{Int64,1}, ::Array{Float64,2}, ::Array{Float64,3}, ::Array{Any,1}, ::Diagonal{Float64}, ::#MB_learner) at ./<missing>:0",
      " in #em#10(::Float64, ::Bool, ::Array{Any,1}, ::Bool, ::Int64, ::Bool, ::Function, ::DataFrames.DataFrame, ::DataArrays.DataArray{Int64,1}, ::Array{Float64,3}, ::Array{Any,1}, ::Diagonal{Float64}, ::#MB_learner) at /Users/neil/Dropbox/Daw_Lab/TwoStepAversive/models/model1/em.jl:30",
      " in (::#kw##em)(::Array{Any,1}, ::#em, ::DataFrames.DataFrame, ::DataArrays.DataArray{Int64,1}, ::Array{Float64,3}, ::Array{Any,1}, ::Diagonal{Float64}, ::Function) at ./<missing>:0",
      " in #em#9(::Float64, ::Bool, ::Array{Any,1}, ::Bool, ::Int64, ::Bool, ::Function, ::DataFrames.DataFrame, ::DataArrays.DataArray{Int64,1}, ::Array{Float64,3}, ::Array{Any,1}, ::Array{Float64,1}, ::#MB_learner) at /Users/neil/Dropbox/Daw_Lab/TwoStepAversive/models/model1/em.jl:9",
      " in (::#kw##em)(::Array{Any,1}, ::#em, ::DataFrames.DataFrame, ::DataArrays.DataArray{Int64,1}, ::Array{Float64,3}, ::Array{Any,1}, ::Array{Float64,1}, ::Function) at ./<missing>:0",
      " in include_string(::String, ::String) at ./loading.jl:441",
      " in include_string(::String, ::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?"
     ]
    }
   ],
   "source": [
    "# run for MB learner\n",
    "@time (betas_MB_learner, sigma_MB_learner, x_MB_learner, l_MB_learner, h_MB_learner) = em(data_MB_learner, subs_MB_learner, X_MB_learner, betas_MB_learner, sigma_MB_learner, MB_learner; emtol=1e-3, parallel=false, full=false, quiet=false);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=x_MB_learner';\n",
    "params_MB = DataFrame(sub = subs_MB_learner,\n",
    "betamb=vec(d[:,1]), \n",
    "eta_unconverted = vec(d[:,2]),\n",
    "eta_converted=vec(0.5 + 0.5 * erf(d[:,2] / sqrt(2))),\n",
    "sticky=vec(d[:,3]));\n",
    "\n",
    "#save parameters to csv file\n",
    "writetable(\"subject_params_MB_learner.csv\", DataFrame(params_MB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### both components (MB and MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# both_componets\n",
    "@everywhere function full_learner(params, data)\n",
    "\tbeta_mb = params[1]\n",
    "\tbeta_mf0 = params[2]\n",
    "    beta_mf1 = params[3]\n",
    "    lr = 0.5 + 0.5 * erf(params[4] / sqrt(2)) #some weird means of constraining learning rate. note that learning rate that pops out needs to be converted\n",
    "  \n",
    "    ps = params[5] #perseveration/stickiness parameter\n",
    "    \n",
    "   #decay_param = 0.5 + 0.5 * erf(params[6] / sqrt(2))\n",
    "    \n",
    "    c1 = data[:c1] # choice 1, 1 and 2 for left vs. right\n",
    "    r = data[:r] # coded as -1 and 1, here -1., note that here -1 is shock \n",
    "    s = data[:s] # stage 2 state, coded as 1 and 2 \n",
    "    t = data[:trial]\n",
    "    sub = data[:sub]\n",
    "    \n",
    "    Q0 = zeros(typeof(beta_mb),2) # c1, left vs. right\n",
    "    Q0s2 = zeros(typeof(beta_mb),2) # values of stage 2 states\n",
    "    Q1 = zeros(typeof(beta_mb),2) #\n",
    "\tQm = zeros(typeof(beta_mb),2) \n",
    "\n",
    "    trial_store = zeros(typeof(beta_mb),1)\n",
    "    sub_store = zeros(typeof(beta_mb),1) \n",
    "    \n",
    "    Q0_store_raw = zeros(typeof(beta_mb),2)\n",
    "    Q1_store_raw = zeros(typeof(beta_mb),2)\n",
    "    Q0s2_store_raw = zeros(typeof(beta_mb),2)\n",
    "    \n",
    "    Q0_store_rescaled = zeros(typeof(beta_mb),2)\n",
    "    Q1_store_rescaled = zeros(typeof(beta_mb),2)\n",
    "    Q0s2_store_rescaled = zeros(typeof(beta_mb),2)\n",
    "    \n",
    "    PE0_store = zeros(typeof(beta_mb),1)\n",
    "    PE1_store = zeros(typeof(beta_mb),1)\n",
    "    PES_store = zeros(typeof(beta_mb),1)\n",
    "        \n",
    "    lik = 0 # initialize likelihood\n",
    "\n",
    "    prevc = 0 # tracking previous choice to determine perseveration\n",
    "\n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        #store these badgers\n",
    "        trial_store = [trial_store t[i]]\n",
    "        sub_store = [sub_store sub[i]]\n",
    "        \n",
    "        Q0_store_raw = [Q0_store_raw Q0]\n",
    "        Q1_store_raw = [Q1_store_raw Q1]\n",
    "        Q0s2_store_raw = [Q0s2_store_raw Q0s2]\n",
    "        \n",
    "        Q0_store_rescaled = [Q0_store_rescaled lr^2.*Q0]\n",
    "        Q1_store_rescaled = [Q1_store_rescaled lr.*Q1]\n",
    "        Q0s2_store_rescaled = [Q0s2_store_rescaled lr.*Q0s2]\n",
    "        \n",
    "        if (c1[i]>0) # won't be the case for the pavlovian trials\n",
    "            \n",
    "            # calculate model-based component of Q values\n",
    "            # the Q for the ending states are usually given by roughly the maximum of the ending states\n",
    "            # Qm = [softmaximum(Q0[2,1],Q0[2,2]),softmaximum(Q0[3,1],Q0[3,2])]\n",
    "            \n",
    "\t\t\tQm = [Q0s2[1],Q0s2[2]] # or technically Qm = [.7*Q0[2] + .3*Q0[3],.3*Q0[2] + .7*Q0[3]]           \n",
    "            \n",
    "            # ultimately, the Q-values that determine the decision are a weighted combination of MB and MF values\n",
    "            # why only take Q0[1] and not both vals?\n",
    "            Qd = beta_mb.* Qm + beta_mf0.*(Q0) + beta_mf1.*(Q1)\n",
    "            \n",
    "            # plus perseveration bonus to last choice \n",
    "            # potentially consider different perseveration\n",
    "\t\t\tif prevc>0\n",
    "\t\t\t\tQd[prevc] += ps #increments Qd[prevc] by ps \n",
    "\t\t\tend\n",
    "            \n",
    "            # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "            # add that likelihood to the running likelihood\n",
    "\t\t\tlik += Qd[c1[i]] - log(sum(exp.(Qd)))\n",
    "            \n",
    "            PE0_store = [PE0_store lr^2*(Q0[c1[i]]) - lr*Q0s2[s[i]]]\n",
    "            \n",
    "            Q0[c1[i]] = (1-lr) * Q0[c1[i]] + Q0s2[s[i]] # TD0 \n",
    "            Q1[c1[i]] = (1-lr) * Q1[c1[i]] + r[i] # TD1\n",
    "            \n",
    "            #here add in decay - assuming you apply to this\n",
    "            #tmp_index_choice = mod(c1[i],2) + 1\n",
    "        \n",
    "            #Q0[tmp_index_choice] = (1-decay_param) * Q0[tmp_index_choice]\n",
    "            #Q1[tmp_index_choice] = (1-decay_param) * Q1[tmp_index_choice]\n",
    "            \n",
    "            prevc = c1[i]\n",
    "        \n",
    "        else\n",
    "            \n",
    "            #cannot store for these - note though that there is a TD0 for Pav potentially \n",
    "            PE0_store = [PE0_store NaN]\n",
    "            PE1_store = [PE1_store NaN]\n",
    "            PES_store = [PES_store lr*Q0s2[c1[i]] - lr*Q0s2[s[i]]]\n",
    "\n",
    "            \n",
    "        end\n",
    "        \n",
    "        \n",
    "\t\tQ0s2[s[i]] = (1-lr) * Q0s2[s[i]] + r[i]\n",
    "                \n",
    "        #here put in decay\n",
    "        #tmp_index = mod(s[i],2) + 1\n",
    "        #Q0s2[tmp_index] = (1-decay_param) * Q0s2[tmp_index]\n",
    "\n",
    "\tend\n",
    "    \n",
    "        # here if running em you can only return the likelihood\n",
    "        #return -lik\n",
    "    \n",
    "        # but if you run in order to extract trials, subs etc then want to return this\n",
    "        return (-lik, trial_store, sub_store, Q0_store_raw, Q1_store_raw, Q0s2_store_raw, Q0_store_rescaled, Q1_store_rescaled, Q0s2_store_rescaled, PE0_store, PE1_store, PES_store)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialized parameter structures\n",
    "(data_full_learner, subs_full_learner, X_full_learner, betas_full_learner, sigma_full_learner) = genVars(df, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 101\n",
      "betas: [0.14, -0.01, 0.33, -0.87, 0.46]\n",
      "sigma: [0.05, 0.0, 0.07, 0.84, 1.01]\n",
      "change: [2.4e-5, -0.001311, 0.000105, -9.3e-5, 2.1e-5, 0.000178, 0.010085, 3.5e-5, 0.00055, 3.0e-6]\n",
      "max: 0.010085\n",
      "7172.590720 seconds (3.54 G allocations: 373.912 GiB, 1.28% gc time)\n"
     ]
    }
   ],
   "source": [
    "# run for full learner\n",
    "@time (betas_full_learner, sigma_full_learner, x_full_learner, l_full_learner, h_full_learner) = em(data_full_learner, subs_full_learner, X_full_learner, betas_full_learner, sigma_full_learner, full_learner; emtol=1e-3, parallel=false, full=false, quiet=false);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=x_full_learner';\n",
    "params_full = DataFrame(sub = subs_full_learner,\n",
    "betamb=vec(d[:,1]), \n",
    "beta_mf0 =vec(d[:,2]),\n",
    "beta_mf1 =vec(d[:,3]),\n",
    "eta_unconverted = vec(d[:,4]),\n",
    "eta_converted=vec(0.5 + 0.5 * erf(d[:,4] / sqrt(2))),\n",
    "sticky=vec(d[:,5]));\n",
    "\n",
    "#save parameters to csv file\n",
    "writetable(\"subject_params_full_learner.csv\", DataFrame(params_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run each model with these parameters for each subject to get trial by trial Q values\n",
    "### -note must rerun models with the return arguments commented back in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialized parameter structures \n",
    "(data_MF_learner, subs_MF_learner, X_MF_learner, betas_MF_learner, sigma_MF_learner) = genVars(df, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#until I know how to get around this, start these with a random number, otherwise complains\n",
    "trial_all_MF = rand(1, 1)\n",
    "sub_all_MF = rand(1, 1) \n",
    "\n",
    "Q0_all_MF_raw = rand(2, 1)\n",
    "Q1_all_MF_raw = rand(2, 1)\n",
    "Qs_all_MF_raw = rand(2, 1)\n",
    "\n",
    "Q0_all_MF_rescaled = rand(2, 1)\n",
    "Q1_all_MF_rescaled = rand(2, 1)\n",
    "Qs_all_MF_rescaled = rand(2, 1)\n",
    "\n",
    "PE0_all_MF = rand(1, 1)\n",
    "PE1_all_MF = rand(1, 1)\n",
    "PES_all_MF = rand(1, 1)\n",
    "\n",
    "for x = 1:length(subs_MF_learner)\n",
    "\n",
    "    sub_outcomes = data_MF_learner[data_MF_learner[:sub].==subs_MF_learner[1],:]\n",
    "    sub_outcomes = sub_outcomes[:s]\n",
    "    \n",
    "    #pull out optimal betas for subject - these are used in the model\n",
    "    #think about whether you want the unconverted/converted learning score\n",
    "    betas_MF_learner[1] = x_MF_learner[1,x]\n",
    "    betas_MF_learner[2] = x_MF_learner[2,x]\n",
    "    betas_MF_learner[3] = x_MF_learner[3,x]  \n",
    "    betas_MF_learner[4] = x_MF_learner[4,x]\n",
    "    \n",
    "    #(minus_li, trial_store, sub_store, Q0_store, Q1_store, Q0s2_store, PE0_store, PE1_store, PES_store) = MF_learner(betas_MF_learner, data_MF_learner[data_MF_learner[:sub].==subs_MF_learner[x], :])\n",
    "    (minus_li, trial_store, sub_store, Q0_store_raw, Q1_store_raw, Q0s2_store_raw, Q0_store_rescaled, Q1_store_rescaled, Q0s2_store_rescaled, PE0_store, PE1_store, PES_store) = MF_learner(betas_MF_learner, data_MF_learner[data_MF_learner[:sub].==subs_MF_learner[x], :])\n",
    "    \n",
    "    #display(Qs)\n",
    "    trial_all_MF = [trial_all_MF trial_store]\n",
    "    sub_all_MF = [sub_all_MF sub_store]\n",
    "    \n",
    "    Q0_all_MF_raw = [Q0_all_MF_raw Q0_store_raw]\n",
    "    Q1_all_MF_raw = [Q1_all_MF_raw Q1_store_raw]\n",
    "    Qs_all_MF_raw = [Qs_all_MF_raw Q0s2_store_raw]\n",
    "    \n",
    "    Q0_all_MF_rescaled = [Q0_all_MF_rescaled Q0_store_rescaled]\n",
    "    Q1_all_MF_rescaled = [Q1_all_MF_rescaled Q1_store_rescaled]\n",
    "    Qs_all_MF_rescaled = [Qs_all_MF_rescaled Q0s2_store_rescaled]\n",
    "\n",
    "    PE0_all_MF = [PE0_all_MF PE0_store]\n",
    "    PE1_all_MF = [PE1_all_MF PE1_store]\n",
    "    PES_all_MF = [PES_all_MF PES_store]   \n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and put all into dataframe\n",
    "MF_Q_compile = DataFrame([sub_all_MF' trial_all_MF' Q0_all_MF_raw' Q1_all_MF_raw' Qs_all_MF_raw' Q0_all_MF_rescaled' Q1_all_MF_rescaled' Qs_all_MF_rescaled' PE0_all_MF' PE1_all_MF' PES_all_MF'])\n",
    "\n",
    "#remove first row as well\n",
    "MF_Q_compile = MF_Q_compile[2:end,:];\n",
    "\n",
    "#this seems the only means of naming columns at the moment - may be some other method\n",
    "names!(MF_Q_compile, [:sub, :trial, :Q0_left_raw, :Q0_right_raw, :Q1_left_raw, :Q1_right_raw, :Qs_left_raw, :Qs_right_raw, :Q0_left_rescaled, :Q0_right_rescaled, :Q1_left_rescaled, :Q1_right_rescaled, :Qs_left_rescaled, :Qs_right_rescaled, :PE_0, :PE_1, :PES]);\n",
    "\n",
    "# must remove all rows where trial = 0\n",
    "MF_Q_compile = MF_Q_compile[MF_Q_compile[:trial].>0,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check these are the same sizes\n",
    "print(size(df))\n",
    "print(size(MF_Q_compile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MF_Q_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now draw out chosen vs unchosen Q values and encountered vs non encountered\n",
    "\n",
    "dim = size(df)\n",
    "\n",
    "#initalise these   \n",
    "Q0select_raw = zeros(dim[:1]);\n",
    "Q0NOTselect_raw = zeros(dim[:1]);\n",
    "Q0dv_select_raw = zeros(dim[:1]);\n",
    "Q1select_raw = zeros(dim[:1]);\n",
    "Q1NOTselect_raw = zeros(dim[:1]);\n",
    "Q1dv_select_raw = zeros(dim[:1]);\n",
    "QSselect_raw = zeros(dim[:1]);\n",
    "QSNOTselect_raw = zeros(dim[:1]);\n",
    "QSdv_select_raw = zeros(dim[:1]); \n",
    "\n",
    "Q0encounter_raw = zeros(dim[:1]);\n",
    "Q0NOTencounter_raw = zeros(dim[:1]);\n",
    "Q0dv_encounter_raw = zeros(dim[:1]);\n",
    "Q1encounter_raw = zeros(dim[:1]);\n",
    "Q1NOTencounter_raw = zeros(dim[:1]);\n",
    "Q1dv_encounter_raw = zeros(dim[:1]);\n",
    "QSencounter_raw = zeros(dim[:1]);\n",
    "QSNOTencounter_raw = zeros(dim[:1]);\n",
    "QSdv_encounter_raw = zeros(dim[:1]);\n",
    "\n",
    "Q0select_scaled = zeros(dim[:1]);\n",
    "Q0NOTselect_scaled = zeros(dim[:1]);\n",
    "Q0dv_select_scaled = zeros(dim[:1]);\n",
    "Q1select_scaled = zeros(dim[:1]);\n",
    "Q1NOTselect_scaled = zeros(dim[:1]);\n",
    "Q1dv_select_scaled = zeros(dim[:1]);\n",
    "QSselect_scaled = zeros(dim[:1]);\n",
    "QSNOTselect_scaled = zeros(dim[:1]);\n",
    "QSdv_select_scaled = zeros(dim[:1]); \n",
    "\n",
    "Q0encounter_scaled = zeros(dim[:1]);\n",
    "Q0NOTencounter_scaled = zeros(dim[:1]);\n",
    "Q0dv_encounter_scaled = zeros(dim[:1]);\n",
    "Q1encounter_scaled = zeros(dim[:1]);\n",
    "Q1NOTencounter_scaled = zeros(dim[:1]);\n",
    "Q1dv_encounter_scaled = zeros(dim[:1]);\n",
    "QSencounter_scaled = zeros(dim[:1]);\n",
    "QSNOTencounter_scaled = zeros(dim[:1]);\n",
    "QSdv_encounter_scaled = zeros(dim[:1]); \n",
    "                \n",
    "choices = df[:c1]; \n",
    "states = df[:s]; \n",
    "outcomes = df[:r];\n",
    "subs = df[:sub];  \n",
    "\n",
    "for i = 1:dim[1]\n",
    "   \n",
    "    if choices[i] > 0\n",
    "        \n",
    "        #careful with the indexing here\n",
    "        Q0select_raw[i] = MF_Q_compile[i,choices[i]+2];\n",
    "        Q0NOTselect_raw[i] = MF_Q_compile[i,abs(choices[i]-3)+2];\n",
    "        Q0dv_select_raw[i] = Q0select_raw[i] - Q0NOTselect_raw[i];\n",
    "        \n",
    "        Q1select_raw[i] = MF_Q_compile[i,choices[i]+4];\n",
    "        Q1NOTselect_raw[i] = MF_Q_compile[i,abs(choices[i]-3)+4];\n",
    "        Q1dv_select_raw[i] = Q1select_raw[i] - Q1NOTselect_raw[i];\n",
    "        \n",
    "        QSselect_raw[i] = MF_Q_compile[i,choices[i]+6];\n",
    "        QSNOTselect_raw[i] = MF_Q_compile[i,abs(choices[i]-3)+6];\n",
    "        QSdv_select_raw[i] = QSselect_raw[i] - QSNOTselect_raw[i];\n",
    "        \n",
    "        Q0select_scaled[i] = MF_Q_compile[i,choices[i]+8];\n",
    "        Q0NOTselect_scaled[i] = MF_Q_compile[i,abs(choices[i]-3)+8];\n",
    "        Q0dv_select_scaled[i] = Q0select_scaled[i] - Q0NOTselect_scaled[i];\n",
    "        \n",
    "        Q1select_scaled[i] = MF_Q_compile[i,choices[i]+10];\n",
    "        Q1NOTselect_scaled[i] = MF_Q_compile[i,abs(choices[i]-3)+10];\n",
    "        Q1dv_select_scaled[i] = Q1select_scaled[i] - Q1NOTselect_scaled[i];\n",
    "        \n",
    "        QSselect_scaled[i] = MF_Q_compile[i,choices[i]+12];\n",
    "        QSNOTselect_scaled[i] = MF_Q_compile[i,abs(choices[i]-3)+12];\n",
    "        QSdv_select_scaled[i] = QSselect_scaled[i] - QSNOTselect_scaled[i];\n",
    "        \n",
    "    else\n",
    "        \n",
    "        Q0select_raw[i] = NaN;\n",
    "        Q0NOTselect_raw[i] = NaN;\n",
    "        Q0dv_select_raw[i] = NaN;\n",
    "        \n",
    "        Q1select_raw[i] = NaN;\n",
    "        Q1NOTselect_raw[i] = NaN;\n",
    "        Q1dv_select_raw[i] = NaN;\n",
    "        \n",
    "        QSselect_raw[i] = NaN;\n",
    "        QSNOTselect_raw[i] = NaN;\n",
    "        QSdv_select_raw[i] = NaN;\n",
    "        \n",
    "        Q0select_scaled[i] = NaN;\n",
    "        Q0NOTselect_scaled[i] = NaN;\n",
    "        Q0dv_select_scaled[i] = NaN;\n",
    "        \n",
    "        Q1select_scaled[i] = NaN;\n",
    "        Q1NOTselect_scaled[i] = NaN;\n",
    "        Q1dv_select_scaled[i] = NaN;\n",
    "        \n",
    "        QSselect_scaled[i] = NaN;\n",
    "        QSNOTselect_scaled[i] = NaN;\n",
    "        QSdv_select_scaled[i] = NaN;\n",
    "        \n",
    "    end\n",
    "    \n",
    "    #encounters you don't want to restrict to choices (as encounter regardless of pav/choice trial...)\n",
    "    Q0encounter_raw[i] = MF_Q_compile[i,states[i]+2];\n",
    "    Q0NOTencounter_raw[i] = MF_Q_compile[i,abs(states[i]-3)+2];\n",
    "    Q0dv_encounter_raw[i] = Q0encounter_raw[i] - Q0NOTencounter_raw[i]; \n",
    "    \n",
    "    Q1encounter_raw[i] = MF_Q_compile[i,states[i]+4];\n",
    "    Q1NOTencounter_raw[i] = MF_Q_compile[i,abs(states[i]-3)+4];\n",
    "    Q1dv_encounter_raw[i] = Q1encounter_raw[i] - Q1NOTencounter_raw[i];\n",
    "    \n",
    "    QSencounter_raw[i] = MF_Q_compile[i,states[i]+6];\n",
    "    QSNOTencounter_raw[i] = MF_Q_compile[i,abs(states[i]-3)+6];\n",
    "    QSdv_encounter_raw[i] = QSencounter_raw[i] - QSNOTencounter_raw[i];\n",
    "    \n",
    "    Q0encounter_scaled[i] = MF_Q_compile[i,states[i]+8];\n",
    "    Q0NOTencounter_scaled[i] = MF_Q_compile[i,abs(states[i]-3)+8];\n",
    "    Q0dv_encounter_scaled[i] = Q0encounter_scaled[i] - Q0NOTencounter_scaled[i];   \n",
    "    \n",
    "    Q1encounter_scaled[i] = MF_Q_compile[i,states[i]+10];\n",
    "    Q1NOTencounter_scaled[i] = MF_Q_compile[i,abs(states[i]-3)+10];\n",
    "    Q1dv_encounter_scaled[i] = Q1encounter_scaled[i] - Q1NOTencounter_scaled[i];\n",
    "    \n",
    "    QSencounter_scaled[i] = MF_Q_compile[i,states[i]+12];\n",
    "    QSNOTencounter_scaled[i] = MF_Q_compile[i,abs(states[i]-3)+12];\n",
    "    QSdv_encounter_scaled[i] = QSencounter_scaled[i] - QSNOTencounter_scaled[i];\n",
    "                            \n",
    "end\n",
    "\n",
    "Q_select_encounter = DataFrame([choices, states, outcomes, \n",
    "        Q0select_raw, Q0NOTselect_raw, Q0dv_select_raw, Q1select_raw, Q1NOTselect_raw,\n",
    "        Q1dv_select_raw, QSselect_raw, QSNOTselect_raw, QSdv_select_raw, Q0encounter_raw, Q0NOTencounter_raw,\n",
    "        Q0dv_encounter_raw, Q1encounter_raw, Q1NOTencounter_raw, Q1dv_encounter_raw, QSencounter_raw, QSNOTencounter_raw, QSdv_encounter_raw,\n",
    "        Q0select_scaled, Q0NOTselect_scaled, Q0dv_select_scaled, Q1select_scaled, Q1NOTselect_scaled,\n",
    "        Q1dv_select_scaled, QSselect_scaled, QSNOTselect_scaled, QSdv_select_scaled, Q0encounter_scaled, Q0NOTencounter_scaled,\n",
    "        Q0dv_encounter_scaled, Q1encounter_scaled, Q1NOTencounter_scaled, Q1dv_encounter_scaled, QSencounter_scaled, QSNOTencounter_scaled, QSdv_encounter_scaled]) \n",
    "\n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_select_encounter, [:choices, :states, :outcomes, \n",
    "        :Q0select_raw, :Q0NOTselect_raw, :Q0dv_select_raw, :Q1select_raw, :Q1NOTselect_raw, \n",
    "        :Q1dv_select_raw, :QSselect_raw, :QSNOTselect_raw, :QSdv_select_raw, :Q0encounter_raw, :Q0NOTencounter_raw,\n",
    "        :Q0dv_encounter_raw, :Q1encounter_raw, :Q1NOTencounter_raw, :Q1dv_encounter_raw, :QSencounter_raw, :QSNOTencounter_raw, :QSdv_encounter_raw,\n",
    "        :Q0select_scaled, :Q0NOTselect_scaled, :Q0dv_select_scaled, :Q1select_scaled, :Q1NOTselect_scaled, \n",
    "        :Q1dv_select_scaled, :QSselect_scaled, :QSNOTselect_scaled, :QSdv_select_scaled, :Q0encounter_scaled, :Q0NOTencounter_scaled,\n",
    "        :Q0dv_encounter_scaled, :Q1encounter_scaled, :Q1NOTencounter_scaled, :Q1dv_encounter_scaled, :QSencounter_scaled, :QSNOTencounter_scaled, :QSdv_encounter_scaled])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous MF Q compile)\n",
    "MF_Q_compile = hcat(MF_Q_compile, Q_select_encounter); #could also do just: [MF_Q_compile Q_select_encounter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate probability of chosen and unchosen from Q values \n",
    "\n",
    "subs = df[:sub];\n",
    "subs = unique(subs)\n",
    "\n",
    "ProbChosen_ALL = []\n",
    "ProbUnchosen_ALL =  []\n",
    "ProbChosen_minus_Unchosen_ALL = []\n",
    "\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "\n",
    "    #extract best fit betas for this subject\n",
    "    betas_MF0 = x_MF_learner[1,x] #beta MF0\n",
    "    betas_MF1 = x_MF_learner[2,x] #beta MF1\n",
    "    betas_lr = x_MF_learner[3,x] #beta MF1\n",
    "    betas_stick = x_MF_learner[4,x] #sticky\n",
    "\n",
    "    #extract data for this subject\n",
    "    subset_data = MF_Q_compile[MF_Q_compile[:sub].==current_sub,:];\n",
    "\n",
    "    n_trials = size(subset_data)\n",
    "    n_trials = n_trials[1]\n",
    "\n",
    "    ProbChosen = zeros(n_trials)\n",
    "    ProbUnchosen = zeros(n_trials)\n",
    "    ProbChosen_minus_Unchosen = zeros(n_trials)\n",
    "\n",
    "    choices = subset_data[:choices]\n",
    "    Q0select = subset_data[:Q0select_raw]\n",
    "    Q0NOTselect = subset_data[:Q0NOTselect_raw] \n",
    "    Q1select = subset_data[:Q1select_raw]\n",
    "    Q1NOTselect = subset_data[:Q1NOTselect_raw] \n",
    "    \n",
    "    prev_choice = NaN;\n",
    "    \n",
    "    for t = 1:n_trials\n",
    "    \n",
    "        curr_choice = choices[t]\n",
    "        \n",
    "        #if not a pav trial \n",
    "        if curr_choice>0\n",
    "            \n",
    "            #if first choice (note first trial will be pav, missed responses already taken out) \n",
    "            #then do not include sticky parameter into softmax\n",
    "            if n_trials == 2\n",
    "                ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t]) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t])) \n",
    "                ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                prev_choice = curr_choice\n",
    "                \n",
    "            #if not the first choice then do not include sticky parameter into softmax    \n",
    "            elseif n_trials > 2\n",
    "                \n",
    "                # where sticky param is added depends whether the current choice equals the current choice\n",
    "                # if it is then add into the chosen probability\n",
    "                if curr_choice==prev_choice\n",
    "                    ProbChosen[t] = exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t]) + betas_stick)/(exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t]) + betas_stick) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t])) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t];\n",
    "                    prev_choice = curr_choice;\n",
    "                # if it is then add into the not chosen probability\n",
    "                elseif curr_choice!=prev_choice\n",
    "                    ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t]) + exp((betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t]) + betas_stick)) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                    prev_choice = curr_choice;\n",
    "                end\n",
    "                \n",
    "            end\n",
    "                \n",
    "        else\n",
    "            ProbChosen[t]  = NaN;\n",
    "            ProbUnchosen[t] = NaN;\n",
    "            ProbChosen_minus_Unchosen[t] = NaN;\n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    ProbChosen_ALL = [ProbChosen_ALL; ProbChosen]\n",
    "    ProbUnchosen_ALL = [ProbUnchosen_ALL; ProbUnchosen]\n",
    "    ProbChosen_minus_Unchosen_ALL = [ProbChosen_minus_Unchosen_ALL; ProbChosen_minus_Unchosen]\n",
    "    \n",
    "end\n",
    "\n",
    "#Now bung into data frame and merge with rest\n",
    "\n",
    "Q_probs = DataFrame([ProbChosen_ALL, ProbUnchosen_ALL, ProbChosen_minus_Unchosen_ALL]) \n",
    "\n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_probs, [:ProbChosen, :ProbUnchosen, :ProbChosen_minus_Unchosen])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous MF compile)\n",
    "MF_Q_compile = hcat(MF_Q_compile, Q_probs); #could also do just: [MF_Q_compile Q_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save parameters to csv file\n",
    "writetable(\"MF_learner_Qvalues.csv\", DataFrame(MF_Q_compile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialized parameter structures \n",
    "(data_MB_learner, subs_MB_learner, X_MB_learner, betas_MB_learner, sigma_MB_learner) = genVars(df, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#until I know how to get around this, start these with a random number, otherwise complains\n",
    "trial_all_MB = rand(1, 1)\n",
    "sub_all_MB = rand(1, 1)\n",
    "\n",
    "Q0_all_MB_raw = rand(2, 1)\n",
    "Q1_all_MB_raw = rand(2, 1)\n",
    "Qs_all_MB_raw = rand(2, 1)\n",
    "\n",
    "Q0_all_MB_rescaled  = rand(2, 1)\n",
    "Q1_all_MB_rescaled  = rand(2, 1)\n",
    "Qs_all_MB_rescaled  = rand(2, 1)\n",
    "\n",
    "PE0_all_MB = rand(1, 1)\n",
    "PE1_all_MB = rand(1, 1)\n",
    "PES_all_MB = rand(1, 1)\n",
    "\n",
    "for x = 1:length(subs_MB_learner)\n",
    "\n",
    "    #pull out optimal betas for subject - these are used in the model\n",
    "    #think about whether you want the unconverted/converted learning score\n",
    "    betas_MB_learner[1] = x_MB_learner[1,x]\n",
    "    betas_MB_learner[2] = x_MB_learner[2,x]\n",
    "    betas_MB_learner[3] = x_MB_learner[3,x]  \n",
    "   \n",
    "    (minus_li, trial_store, sub_store, Q0_store_raw, Q1_store_raw, Q0s2_store_raw, Q0_store_rescaled, Q1_store_rescaled, Q0s2_store_rescaled, PE0_store, PE1_store, PES_store) = MB_learner(betas_MB_learner, data_MB_learner[data_MB_learner[:sub].==subs_MB_learner[x], :])\n",
    "        \n",
    "    #display(Qs)\n",
    "    trial_all_MB = [trial_all_MB trial_store]\n",
    "    sub_all_MB = [sub_all_MB sub_store]\n",
    "    \n",
    "    Q0_all_MB_raw = [Q0_all_MB_raw Q0_store_raw]\n",
    "    Q1_all_MB_raw = [Q1_all_MB_raw Q1_store_raw]\n",
    "    Qs_all_MB_raw = [Qs_all_MB_raw Q0s2_store_raw]\n",
    "    \n",
    "    Q0_all_MB_rescaled = [Q0_all_MB_rescaled Q0_store_rescaled]\n",
    "    Q1_all_MB_rescaled = [Q1_all_MB_rescaled Q1_store_rescaled]\n",
    "    Qs_all_MB_rescaled = [Qs_all_MB_rescaled Q0s2_store_rescaled]\n",
    "    \n",
    "    PE0_all_MB = [PE0_all_MB PE0_store]\n",
    "    PE1_all_MB = [PE1_all_MB PE1_store]\n",
    "    PES_all_MB = [PES_all_MB PES_store]\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and put all into dataframe\n",
    "MB_Q_compile =  DataFrame([sub_all_MB' trial_all_MB' Q0_all_MB_raw' Q1_all_MB_raw' Qs_all_MB_raw' Q0_all_MB_rescaled' Q1_all_MB_rescaled' Qs_all_MB_rescaled' PE0_all_MB' PE1_all_MB' PES_all_MB'])\n",
    "\n",
    "#want to remove very first row\n",
    "MB_Q_compile = MB_Q_compile[2:end,:];\n",
    "\n",
    "#this seems the only means of naming columns at the moment - may be some other method\n",
    "names!(MB_Q_compile, [:sub, :trial, :Q0_left_raw, :Q0_right_raw, :Q1_left_raw, :Q1_right_raw, :Qs_left_raw, :Qs_right_raw, :Q0_left_rescaled, :Q0_right_rescaled, :Q1_left_rescaled, :Q1_right_rescaled, :Qs_left_rescaled, :Qs_right_rescaled, :PE_0, :PE_1, :PES]);\n",
    "\n",
    "# must remove all rows where trial = 0\n",
    "MB_Q_compile = MB_Q_compile[MB_Q_compile[:trial].>0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check these are the same sizes\n",
    "print(size(df))\n",
    "print(size(MB_Q_compile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now draw out chosen vs unchosen Q values and encountered vs non encountered\n",
    "\n",
    "dim = size(df)\n",
    "\n",
    "#initalise these   \n",
    "Q0select_raw = zeros(dim[:1]);\n",
    "Q0NOTselect_raw = zeros(dim[:1]);\n",
    "Q0dv_select_raw = zeros(dim[:1]);\n",
    "Q1select_raw = zeros(dim[:1]);\n",
    "Q1NOTselect_raw = zeros(dim[:1]);\n",
    "Q1dv_select_raw = zeros(dim[:1]);\n",
    "QSselect_raw = zeros(dim[:1]);\n",
    "QSNOTselect_raw = zeros(dim[:1]);\n",
    "QSdv_select_raw = zeros(dim[:1]); \n",
    "\n",
    "Q0encounter_raw = zeros(dim[:1]);\n",
    "Q0NOTencounter_raw = zeros(dim[:1]);\n",
    "Q0dv_encounter_raw = zeros(dim[:1]);\n",
    "Q1encounter_raw = zeros(dim[:1]);\n",
    "Q1NOTencounter_raw = zeros(dim[:1]);\n",
    "Q1dv_encounter_raw = zeros(dim[:1]);\n",
    "QSencounter_raw = zeros(dim[:1]);\n",
    "QSNOTencounter_raw = zeros(dim[:1]);\n",
    "QSdv_encounter_raw = zeros(dim[:1]);\n",
    "\n",
    "Q0select_scaled = zeros(dim[:1]);\n",
    "Q0NOTselect_scaled = zeros(dim[:1]);\n",
    "Q0dv_select_scaled = zeros(dim[:1]);\n",
    "Q1select_scaled = zeros(dim[:1]);\n",
    "Q1NOTselect_scaled = zeros(dim[:1]);\n",
    "Q1dv_select_scaled = zeros(dim[:1]);\n",
    "QSselect_scaled = zeros(dim[:1]);\n",
    "QSNOTselect_scaled = zeros(dim[:1]);\n",
    "QSdv_select_scaled = zeros(dim[:1]); \n",
    "\n",
    "Q0encounter_scaled = zeros(dim[:1]);\n",
    "Q0NOTencounter_scaled = zeros(dim[:1]);\n",
    "Q0dv_encounter_scaled = zeros(dim[:1]);\n",
    "Q1encounter_scaled = zeros(dim[:1]);\n",
    "Q1NOTencounter_scaled = zeros(dim[:1]);\n",
    "Q1dv_encounter_scaled = zeros(dim[:1]);\n",
    "QSencounter_scaled = zeros(dim[:1]);\n",
    "QSNOTencounter_scaled = zeros(dim[:1]);\n",
    "QSdv_encounter_scaled = zeros(dim[:1]); \n",
    "                \n",
    "choices = df[:c1]; \n",
    "states = df[:s]; \n",
    "outcomes = df[:r];\n",
    "subs = df[:sub];  \n",
    "\n",
    "for i = 1:dim[1]\n",
    "   \n",
    "    if choices[i] > 0\n",
    "        \n",
    "        #careful with the indexing here\n",
    "        Q0select_raw[i] = MB_Q_compile[i,choices[i]+2];\n",
    "        Q0NOTselect_raw[i] = MB_Q_compile[i,abs(choices[i]-3)+2];\n",
    "        Q0dv_select_raw[i] = Q0select_raw[i] - Q0NOTselect_raw[i];\n",
    "        \n",
    "        Q1select_raw[i] = MB_Q_compile[i,choices[i]+4];\n",
    "        Q1NOTselect_raw[i] = MB_Q_compile[i,abs(choices[i]-3)+4];\n",
    "        Q1dv_select_raw[i] = Q1select_raw[i] - Q1NOTselect_raw[i];\n",
    "        \n",
    "        QSselect_raw[i] = MB_Q_compile[i,choices[i]+6];\n",
    "        QSNOTselect_raw[i] = MB_Q_compile[i,abs(choices[i]-3)+6];\n",
    "        QSdv_select_raw[i] = QSselect_raw[i] - QSNOTselect_raw[i];\n",
    "        \n",
    "        Q0select_scaled[i] = MB_Q_compile[i,choices[i]+8];\n",
    "        Q0NOTselect_scaled[i] = MB_Q_compile[i,abs(choices[i]-3)+8];\n",
    "        Q0dv_select_scaled[i] = Q0select_scaled[i] - Q0NOTselect_scaled[i];\n",
    "        \n",
    "        Q1select_scaled[i] = MB_Q_compile[i,choices[i]+10];\n",
    "        Q1NOTselect_scaled[i] = MB_Q_compile[i,abs(choices[i]-3)+10];\n",
    "        Q1dv_select_scaled[i] = Q1select_scaled[i] - Q1NOTselect_scaled[i];\n",
    "        \n",
    "        QSselect_scaled[i] = MB_Q_compile[i,choices[i]+12];\n",
    "        QSNOTselect_scaled[i] = MB_Q_compile[i,abs(choices[i]-3)+12];\n",
    "        QSdv_select_scaled[i] = QSselect_scaled[i] - QSNOTselect_scaled[i];\n",
    "        \n",
    "    else\n",
    "        \n",
    "        Q0select_raw[i] = NaN;\n",
    "        Q0NOTselect_raw[i] = NaN;\n",
    "        Q0dv_select_raw[i] = NaN;\n",
    "        \n",
    "        Q1select_raw[i] = NaN;\n",
    "        Q1NOTselect_raw[i] = NaN;\n",
    "        Q1dv_select_raw[i] = NaN;\n",
    "        \n",
    "        QSselect_raw[i] = NaN;\n",
    "        QSNOTselect_raw[i] = NaN;\n",
    "        QSdv_select_raw[i] = NaN;\n",
    "        \n",
    "        Q0select_scaled[i] = NaN;\n",
    "        Q0NOTselect_scaled[i] = NaN;\n",
    "        Q0dv_select_scaled[i] = NaN;\n",
    "        \n",
    "        Q1select_scaled[i] = NaN;\n",
    "        Q1NOTselect_scaled[i] = NaN;\n",
    "        Q1dv_select_scaled[i] = NaN;\n",
    "        \n",
    "        QSselect_scaled[i] = NaN;\n",
    "        QSNOTselect_scaled[i] = NaN;\n",
    "        QSdv_select_scaled[i] = NaN;\n",
    "        \n",
    "    end\n",
    "    \n",
    "    #encounters you don't want to restrict to choices (as encounter regardless of pav/choice trial...)\n",
    "    Q0encounter_raw[i] = MB_Q_compile[i,states[i]+2];\n",
    "    Q0NOTencounter_raw[i] = MB_Q_compile[i,abs(states[i]-3)+2];\n",
    "    Q0dv_encounter_raw[i] = Q0encounter_raw[i] - Q0NOTencounter_raw[i]; \n",
    "    \n",
    "    Q1encounter_raw[i] = MB_Q_compile[i,states[i]+4];\n",
    "    Q1NOTencounter_raw[i] = MB_Q_compile[i,abs(states[i]-3)+4];\n",
    "    Q1dv_encounter_raw[i] = Q1encounter_raw[i] - Q1NOTencounter_raw[i];\n",
    "    \n",
    "    QSencounter_raw[i] = MB_Q_compile[i,states[i]+6];\n",
    "    QSNOTencounter_raw[i] = MB_Q_compile[i,abs(states[i]-3)+6];\n",
    "    QSdv_encounter_raw[i] = QSencounter_raw[i] - QSNOTencounter_raw[i];\n",
    "    \n",
    "    Q0encounter_scaled[i] = MB_Q_compile[i,states[i]+8];\n",
    "    Q0NOTencounter_scaled[i] = MB_Q_compile[i,abs(states[i]-3)+8];\n",
    "    Q0dv_encounter_scaled[i] = Q0encounter_scaled[i] - Q0NOTencounter_scaled[i];   \n",
    "    \n",
    "    Q1encounter_scaled[i] = MB_Q_compile[i,states[i]+10];\n",
    "    Q1NOTencounter_scaled[i] = MB_Q_compile[i,abs(states[i]-3)+10];\n",
    "    Q1dv_encounter_scaled[i] = Q1encounter_scaled[i] - Q1NOTencounter_scaled[i];\n",
    "    \n",
    "    QSencounter_scaled[i] = MB_Q_compile[i,states[i]+12];\n",
    "    QSNOTencounter_scaled[i] = MB_Q_compile[i,abs(states[i]-3)+12];\n",
    "    QSdv_encounter_scaled[i] = QSencounter_scaled[i] - QSNOTencounter_scaled[i];\n",
    "                            \n",
    "end\n",
    "\n",
    "Q_select_encounter = DataFrame([choices, states, outcomes, \n",
    "        Q0select_raw, Q0NOTselect_raw, Q0dv_select_raw, Q1select_raw, Q1NOTselect_raw,\n",
    "        Q1dv_select_raw, QSselect_raw, QSNOTselect_raw, QSdv_select_raw, Q0encounter_raw, Q0NOTencounter_raw,\n",
    "        Q0dv_encounter_raw, Q1encounter_raw, Q1NOTencounter_raw, Q1dv_encounter_raw, QSencounter_raw, QSNOTencounter_raw, QSdv_encounter_raw,\n",
    "        Q0select_scaled, Q0NOTselect_scaled, Q0dv_select_scaled, Q1select_scaled, Q1NOTselect_scaled,\n",
    "        Q1dv_select_scaled, QSselect_scaled, QSNOTselect_scaled, QSdv_select_scaled, Q0encounter_scaled, Q0NOTencounter_scaled,\n",
    "        Q0dv_encounter_scaled, Q1encounter_scaled, Q1NOTencounter_scaled, Q1dv_encounter_scaled, QSencounter_scaled, QSNOTencounter_scaled, QSdv_encounter_scaled]) \n",
    "\n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_select_encounter, [:choices, :states, :outcomes, \n",
    "        :Q0select_raw, :Q0NOTselect_raw, :Q0dv_select_raw, :Q1select_raw, :Q1NOTselect_raw, \n",
    "        :Q1dv_select_raw, :QSselect_raw, :QSNOTselect_raw, :QSdv_select_raw, :Q0encounter_raw, :Q0NOTencounter_raw,\n",
    "        :Q0dv_encounter_raw, :Q1encounter_raw, :Q1NOTencounter_raw, :Q1dv_encounter_raw, :QSencounter_raw, :QSNOTencounter_raw, :QSdv_encounter_raw,\n",
    "        :Q0select_scaled, :Q0NOTselect_scaled, :Q0dv_select_scaled, :Q1select_scaled, :Q1NOTselect_scaled, \n",
    "        :Q1dv_select_scaled, :QSselect_scaled, :QSNOTselect_scaled, :QSdv_select_scaled, :Q0encounter_scaled, :Q0NOTencounter_scaled,\n",
    "        :Q0dv_encounter_scaled, :Q1encounter_scaled, :Q1NOTencounter_scaled, :Q1dv_encounter_scaled, :QSencounter_scaled, :QSNOTencounter_scaled, :QSdv_encounter_scaled])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous MF Q compile)\n",
    "MB_Q_compile = hcat(MB_Q_compile, Q_select_encounter); #could also do just: [MB_Q_compile Q_select_encounter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head(MB_Q_compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate probability of chosen and unchosen from Q values \n",
    "\n",
    "subs = df[:sub];\n",
    "subs = unique(subs)\n",
    "\n",
    "ProbChosen_ALL = []\n",
    "ProbUnchosen_ALL =  []\n",
    "ProbChosen_minus_Unchosen_ALL = []\n",
    "\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "\n",
    "    #extract best fit betas for this subject\n",
    "    betas_MB = x_MB_learner[1,x] #beta MB\n",
    "    betas_lr = x_MB_learner[2,x] #beta LR\n",
    "    betas_stick = x_MB_learner[3,x] #sticky\n",
    "\n",
    "    #extract data for this subject\n",
    "    subset_data = MB_Q_compile[MB_Q_compile[:sub].==current_sub,:];\n",
    "\n",
    "    n_trials = size(subset_data)\n",
    "    n_trials = n_trials[1]\n",
    "\n",
    "    ProbChosen = zeros(n_trials)\n",
    "    ProbUnchosen = zeros(n_trials)\n",
    "    ProbChosen_minus_Unchosen = zeros(n_trials)\n",
    "\n",
    "    choices = subset_data[:choices]\n",
    "    QSselect = subset_data[:QSselect_raw]\n",
    "    QSNOTselect = subset_data[:QSNOTselect_raw] \n",
    "\n",
    "    prev_choice = NaN;\n",
    "    \n",
    "    for t = 1:n_trials\n",
    "    \n",
    "        curr_choice = choices[t]\n",
    "        \n",
    "        #if not a pav trial \n",
    "        if curr_choice>0\n",
    "            \n",
    "            #if first choice (note first trial will be pav, missed responses already taken out) \n",
    "            #then do not include sticky parameter into softmax\n",
    "            if n_trials == 2\n",
    "                ProbChosen[t] = exp(betas_MB*QSselect[t])/(exp(betas_MB*QSselect[t]) + exp(betas_MB*QSNOTselect[t]))\n",
    "                ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                prev_choice = curr_choice\n",
    "                \n",
    "            #if not the first choice then do not include sticky parameter into softmax    \n",
    "            elseif n_trials > 2\n",
    "                \n",
    "                # where sticky param is added depends whether the current choice equals the current choice\n",
    "                # if it is then add into the chosen probability\n",
    "                if curr_choice==prev_choice\n",
    "                    ProbChosen[t] = exp(betas_MB*QSselect[t] + betas_stick)/(exp(betas_MB*QSselect[t] + betas_stick) + exp(betas_MB*QSNOTselect[t]))\n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t];\n",
    "                    prev_choice = curr_choice;\n",
    "                # if it is then add into the not chosen probability\n",
    "                elseif curr_choice!=prev_choice\n",
    "                    ProbChosen[t] = exp(betas_MB*QSselect[t])/(exp(betas_MB*QSselect[t]) + exp(betas_MB*QSNOTselect[t] + betas_stick));\n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t];\n",
    "                    prev_choice = curr_choice;\n",
    "                end\n",
    "                \n",
    "            end\n",
    "                \n",
    "        else\n",
    "            ProbChosen[t]  = NaN;\n",
    "            ProbUnchosen[t] = NaN;\n",
    "            ProbChosen_minus_Unchosen[t] = NaN;\n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    ProbChosen_ALL = [ProbChosen_ALL; ProbChosen]\n",
    "    ProbUnchosen_ALL = [ProbUnchosen_ALL; ProbUnchosen]\n",
    "    ProbChosen_minus_Unchosen_ALL = [ProbChosen_minus_Unchosen_ALL; ProbChosen_minus_Unchosen]\n",
    "    \n",
    "end\n",
    "\n",
    "#Now bung into data frame and merge with rest\n",
    "\n",
    "\n",
    "Q_probs = DataFrame([ProbChosen_ALL, ProbUnchosen_ALL, ProbChosen_minus_Unchosen_ALL]) \n",
    "\n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_probs, [:ProbChosen, :ProbUnchosen, :ProbChosen_minus_Unchosen])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous MB compile)\n",
    "MB_Q_compile = hcat(MB_Q_compile, Q_probs); #could also do just: [MB_Q_compile Q_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save parameters to csv file\n",
    "writetable(\"MB_learner_Qvalues.csv\", DataFrame(MB_Q_compile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### both components (MB & MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialized parameter structures \n",
    "(data_full_learner, subs_full_learner, X_full_learner, betas_full_learner, sigma_full_learner) = genVars(df, 5);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#until I know how to get around this, start these with a random number, otherwise complains\n",
    "trial_all_full = rand(1, 1)\n",
    "sub_all_full = rand(1, 1)\n",
    "\n",
    "Q0_all_full_raw = rand(2, 1)\n",
    "Q1_all_full_raw = rand(2, 1)\n",
    "Qs_all_full_raw = rand(2, 1)\n",
    "\n",
    "Q0_all_full_rescaled  = rand(2, 1)\n",
    "Q1_all_full_rescaled  = rand(2, 1)\n",
    "Qs_all_full_rescaled  = rand(2, 1)\n",
    "\n",
    "PE0_all_full = rand(1, 1)\n",
    "PE1_all_full = rand(1, 1)\n",
    "PES_all_full = rand(1, 1)\n",
    "\n",
    "for x = 1:length(subs_full_learner)\n",
    "\n",
    "    #pull out optimal betas for subject - these are used in the model\n",
    "    #think about whether you want the unconverted/converted learning score\n",
    "    betas_full_learner[1] = x_full_learner[1,x]\n",
    "    betas_full_learner[2] = x_full_learner[2,x]\n",
    "    betas_full_learner[3] = x_full_learner[3,x]  \n",
    "    betas_full_learner[4] = x_full_learner[4,x]\n",
    "    betas_full_learner[5] = x_full_learner[5,x]  \n",
    "    \n",
    "    (minus_li, trial_store, sub_store, Q0_store_raw, Q1_store_raw, Q0s2_store_raw, Q0_store_rescaled, Q1_store_rescaled, Q0s2_store_rescaled, PE0_store, PE1_store, PES_store) = full_learner(betas_full_learner, data_full_learner[data_full_learner[:sub].==subs_full_learner[x], :])\n",
    "        \n",
    "    #display(Qs)\n",
    "    trial_all_full = [trial_all_full trial_store]\n",
    "    sub_all_full = [sub_all_full sub_store]\n",
    "    \n",
    "    Q0_all_full_raw = [Q0_all_full_raw Q0_store_raw]\n",
    "    Q1_all_full_raw = [Q1_all_full_raw Q1_store_raw]\n",
    "    Qs_all_full_raw = [Qs_all_full_raw Q0s2_store_raw]\n",
    "    \n",
    "    Q0_all_full_rescaled = [Q0_all_full_rescaled Q0_store_rescaled]\n",
    "    Q1_all_full_rescaled = [Q1_all_full_rescaled Q1_store_rescaled]\n",
    "    Qs_all_full_rescaled = [Qs_all_full_rescaled Q0s2_store_rescaled]\n",
    "    \n",
    "    PE0_all_full = [PE0_all_full PE0_store]\n",
    "    PE1_all_full = [PE1_all_full PE1_store]\n",
    "    PES_all_full = [PES_all_full PES_store]\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and put all into dataframe\n",
    "# note need to rejiggle a bit as trial one Q values need to be set back one to align with correct trial number\n",
    "\n",
    "full_Q_compile = DataFrame([sub_all_full' trial_all_full' Q0_all_full_raw' Q1_all_full_raw' Qs_all_full_raw' Q0_all_full_rescaled' Q1_all_full_rescaled' Qs_all_full_rescaled' PE0_all_full' PE1_all_full' PES_all_full'])\n",
    "\n",
    "#want to remove very first row\n",
    "full_Q_compile = full_Q_compile[2:end,:];\n",
    "\n",
    "#this seems the only means of naming columns at the moment - may be some other method\n",
    "names!(full_Q_compile, [:sub, :trial, :Q0_left_raw, :Q0_right_raw, :Q1_left_raw, :Q1_right_raw, :Qs_left_raw, :Qs_right_raw, :Q0_left_rescaled, :Q0_right_rescaled, :Q1_left_rescaled, :Q1_right_rescaled, :Qs_left_rescaled, :Qs_right_rescaled, :PE_0, :PE_1, :PES]);\n",
    "\n",
    "# must remove all rows where trial = 0\n",
    "full_Q_compile = full_Q_compile[full_Q_compile[:trial].>0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(full_Q_compile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now draw out chosen vs unchosen Q values and encountered vs non encountered\n",
    "\n",
    "dim = size(df)\n",
    "\n",
    "#initalise these   \n",
    "Q0select_raw = zeros(dim[:1]);\n",
    "Q0NOTselect_raw = zeros(dim[:1]);\n",
    "Q0dv_select_raw = zeros(dim[:1]);\n",
    "Q1select_raw = zeros(dim[:1]);\n",
    "Q1NOTselect_raw = zeros(dim[:1]);\n",
    "Q1dv_select_raw = zeros(dim[:1]);\n",
    "QSselect_raw = zeros(dim[:1]);\n",
    "QSNOTselect_raw = zeros(dim[:1]);\n",
    "QSdv_select_raw = zeros(dim[:1]); \n",
    "\n",
    "Q0encounter_raw = zeros(dim[:1]);\n",
    "Q0NOTencounter_raw = zeros(dim[:1]);\n",
    "Q0dv_encounter_raw = zeros(dim[:1]);\n",
    "Q1encounter_raw = zeros(dim[:1]);\n",
    "Q1NOTencounter_raw = zeros(dim[:1]);\n",
    "Q1dv_encounter_raw = zeros(dim[:1]);\n",
    "QSencounter_raw = zeros(dim[:1]);\n",
    "QSNOTencounter_raw = zeros(dim[:1]);\n",
    "QSdv_encounter_raw = zeros(dim[:1]);\n",
    "\n",
    "Q0select_scaled = zeros(dim[:1]);\n",
    "Q0NOTselect_scaled = zeros(dim[:1]);\n",
    "Q0dv_select_scaled = zeros(dim[:1]);\n",
    "Q1select_scaled = zeros(dim[:1]);\n",
    "Q1NOTselect_scaled = zeros(dim[:1]);\n",
    "Q1dv_select_scaled = zeros(dim[:1]);\n",
    "QSselect_scaled = zeros(dim[:1]);\n",
    "QSNOTselect_scaled = zeros(dim[:1]);\n",
    "QSdv_select_scaled = zeros(dim[:1]); \n",
    "\n",
    "Q0encounter_scaled = zeros(dim[:1]);\n",
    "Q0NOTencounter_scaled = zeros(dim[:1]);\n",
    "Q0dv_encounter_scaled = zeros(dim[:1]);\n",
    "Q1encounter_scaled = zeros(dim[:1]);\n",
    "Q1NOTencounter_scaled = zeros(dim[:1]);\n",
    "Q1dv_encounter_scaled = zeros(dim[:1]);\n",
    "QSencounter_scaled = zeros(dim[:1]);\n",
    "QSNOTencounter_scaled = zeros(dim[:1]);\n",
    "QSdv_encounter_scaled = zeros(dim[:1]); \n",
    "                \n",
    "choices = df[:c1]; \n",
    "states = df[:s]; \n",
    "outcomes = df[:r];\n",
    "subs = df[:sub];  \n",
    "\n",
    "for i = 1:dim[1]\n",
    "   \n",
    "    if choices[i] > 0\n",
    "        \n",
    "        #careful with the indexing here\n",
    "        Q0select_raw[i] = full_Q_compile[i,choices[i]+2];\n",
    "        Q0NOTselect_raw[i] = full_Q_compile[i,abs(choices[i]-3)+2];\n",
    "        Q0dv_select_raw[i] = Q0select_raw[i] - Q0NOTselect_raw[i];\n",
    "        \n",
    "        Q1select_raw[i] = full_Q_compile[i,choices[i]+4];\n",
    "        Q1NOTselect_raw[i] = full_Q_compile[i,abs(choices[i]-3)+4];\n",
    "        Q1dv_select_raw[i] = Q1select_raw[i] - Q1NOTselect_raw[i];\n",
    "        \n",
    "        QSselect_raw[i] = full_Q_compile[i,choices[i]+6];\n",
    "        QSNOTselect_raw[i] = full_Q_compile[i,abs(choices[i]-3)+6];\n",
    "        QSdv_select_raw[i] = QSselect_raw[i] - QSNOTselect_raw[i];\n",
    "        \n",
    "        Q0select_scaled[i] = full_Q_compile[i,choices[i]+8];\n",
    "        Q0NOTselect_scaled[i] = full_Q_compile[i,abs(choices[i]-3)+8];\n",
    "        Q0dv_select_scaled[i] = Q0select_scaled[i] - Q0NOTselect_scaled[i];\n",
    "        \n",
    "        Q1select_scaled[i] = full_Q_compile[i,choices[i]+10];\n",
    "        Q1NOTselect_scaled[i] = full_Q_compile[i,abs(choices[i]-3)+10];\n",
    "        Q1dv_select_scaled[i] = Q1select_scaled[i] - Q1NOTselect_scaled[i];\n",
    "        \n",
    "        QSselect_scaled[i] = full_Q_compile[i,choices[i]+12];\n",
    "        QSNOTselect_scaled[i] = full_Q_compile[i,abs(choices[i]-3)+12];\n",
    "        QSdv_select_scaled[i] = QSselect_scaled[i] - QSNOTselect_scaled[i];\n",
    "        \n",
    "    else\n",
    "        \n",
    "        Q0select_raw[i] = NaN;\n",
    "        Q0NOTselect_raw[i] = NaN;\n",
    "        Q0dv_select_raw[i] = NaN;\n",
    "        \n",
    "        Q1select_raw[i] = NaN;\n",
    "        Q1NOTselect_raw[i] = NaN;\n",
    "        Q1dv_select_raw[i] = NaN;\n",
    "        \n",
    "        QSselect_raw[i] = NaN;\n",
    "        QSNOTselect_raw[i] = NaN;\n",
    "        QSdv_select_raw[i] = NaN;\n",
    "        \n",
    "        Q0select_scaled[i] = NaN;\n",
    "        Q0NOTselect_scaled[i] = NaN;\n",
    "        Q0dv_select_scaled[i] = NaN;\n",
    "        \n",
    "        Q1select_scaled[i] = NaN;\n",
    "        Q1NOTselect_scaled[i] = NaN;\n",
    "        Q1dv_select_scaled[i] = NaN;\n",
    "        \n",
    "        QSselect_scaled[i] = NaN;\n",
    "        QSNOTselect_scaled[i] = NaN;\n",
    "        QSdv_select_scaled[i] = NaN;\n",
    "        \n",
    "    end\n",
    "    \n",
    "    #encounters you don't want to restrict to choices (as encounter regardless of pav/choice trial...)\n",
    "    Q0encounter_raw[i] = full_Q_compile[i,states[i]+2];\n",
    "    Q0NOTencounter_raw[i] = full_Q_compile[i,abs(states[i]-3)+2];\n",
    "    Q0dv_encounter_raw[i] = Q0encounter_raw[i] - Q0NOTencounter_raw[i]; \n",
    "    \n",
    "    Q1encounter_raw[i] = full_Q_compile[i,states[i]+4];\n",
    "    Q1NOTencounter_raw[i] = full_Q_compile[i,abs(states[i]-3)+4];\n",
    "    Q1dv_encounter_raw[i] = Q1encounter_raw[i] - Q1NOTencounter_raw[i];\n",
    "    \n",
    "    QSencounter_raw[i] = full_Q_compile[i,states[i]+6];\n",
    "    QSNOTencounter_raw[i] = full_Q_compile[i,abs(states[i]-3)+6];\n",
    "    QSdv_encounter_raw[i] = QSencounter_raw[i] - QSNOTencounter_raw[i];\n",
    "    \n",
    "    Q0encounter_scaled[i] = full_Q_compile[i,states[i]+8];\n",
    "    Q0NOTencounter_scaled[i] = full_Q_compile[i,abs(states[i]-3)+8];\n",
    "    Q0dv_encounter_scaled[i] = Q0encounter_scaled[i] - Q0NOTencounter_scaled[i];   \n",
    "    \n",
    "    Q1encounter_scaled[i] = full_Q_compile[i,states[i]+10];\n",
    "    Q1NOTencounter_scaled[i] = full_Q_compile[i,abs(states[i]-3)+10];\n",
    "    Q1dv_encounter_scaled[i] = Q1encounter_scaled[i] - Q1NOTencounter_scaled[i];\n",
    "    \n",
    "    QSencounter_scaled[i] = full_Q_compile[i,states[i]+12];\n",
    "    QSNOTencounter_scaled[i] = full_Q_compile[i,abs(states[i]-3)+12];\n",
    "    QSdv_encounter_scaled[i] = QSencounter_scaled[i] - QSNOTencounter_scaled[i];\n",
    "                            \n",
    "end\n",
    "\n",
    "Q_select_encounter = DataFrame([choices, states, outcomes, \n",
    "        Q0select_raw, Q0NOTselect_raw, Q0dv_select_raw, Q1select_raw, Q1NOTselect_raw,\n",
    "        Q1dv_select_raw, QSselect_raw, QSNOTselect_raw, QSdv_select_raw, Q0encounter_raw, Q0NOTencounter_raw,\n",
    "        Q0dv_encounter_raw, Q1encounter_raw, Q1NOTencounter_raw, Q1dv_encounter_raw, QSencounter_raw, QSNOTencounter_raw, QSdv_encounter_raw,\n",
    "        Q0select_scaled, Q0NOTselect_scaled, Q0dv_select_scaled, Q1select_scaled, Q1NOTselect_scaled,\n",
    "        Q1dv_select_scaled, QSselect_scaled, QSNOTselect_scaled, QSdv_select_scaled, Q0encounter_scaled, Q0NOTencounter_scaled,\n",
    "        Q0dv_encounter_scaled, Q1encounter_scaled, Q1NOTencounter_scaled, Q1dv_encounter_scaled, QSencounter_scaled, QSNOTencounter_scaled, QSdv_encounter_scaled]) \n",
    "\n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_select_encounter, [:choices, :states, :outcomes, \n",
    "        :Q0select_raw, :Q0NOTselect_raw, :Q0dv_select_raw, :Q1select_raw, :Q1NOTselect_raw, \n",
    "        :Q1dv_select_raw, :QSselect_raw, :QSNOTselect_raw, :QSdv_select_raw, :Q0encounter_raw, :Q0NOTencounter_raw,\n",
    "        :Q0dv_encounter_raw, :Q1encounter_raw, :Q1NOTencounter_raw, :Q1dv_encounter_raw, :QSencounter_raw, :QSNOTencounter_raw, :QSdv_encounter_raw,\n",
    "        :Q0select_scaled, :Q0NOTselect_scaled, :Q0dv_select_scaled, :Q1select_scaled, :Q1NOTselect_scaled, \n",
    "        :Q1dv_select_scaled, :QSselect_scaled, :QSNOTselect_scaled, :QSdv_select_scaled, :Q0encounter_scaled, :Q0NOTencounter_scaled,\n",
    "        :Q0dv_encounter_scaled, :Q1encounter_scaled, :Q1NOTencounter_scaled, :Q1dv_encounter_scaled, :QSencounter_scaled, :QSNOTencounter_scaled, :QSdv_encounter_scaled])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous MF Q compile)\n",
    "full_Q_compile = hcat(full_Q_compile, Q_select_encounter); #could also do just: [full_Q_compile Q_select_encounter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head(full_Q_compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate probability of chosen and unchosen from Q values \n",
    "\n",
    "subs = df[:sub];\n",
    "subs = unique(subs)\n",
    "\n",
    "ProbChosen_ALL = []\n",
    "ProbUnchosen_ALL =  []\n",
    "ProbChosen_minus_Unchosen_ALL = []\n",
    "\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "\n",
    "    #extract best fit betas for this subject\n",
    "    beta_MB = x_full_learner[1,x] #beta MB\n",
    "    betas_MF0 = x_full_learner[2,x] #beta MF0\n",
    "    betas_MF1 = x_full_learner[3,x] #beta MF1\n",
    "    betas_lr = x_full_learner[4,x] #beta lr\n",
    "    betas_stick = x_full_learner[5,x] #sticky\n",
    "\n",
    "    #extract data for this subject\n",
    "    subset_data = full_Q_compile[full_Q_compile[:sub].==current_sub,:];\n",
    "\n",
    "    n_trials = size(subset_data)\n",
    "    n_trials = n_trials[1]\n",
    "\n",
    "    ProbChosen = zeros(n_trials)\n",
    "    ProbUnchosen = zeros(n_trials)\n",
    "    ProbChosen_minus_Unchosen = zeros(n_trials)\n",
    "\n",
    "    choices = subset_data[:choices]\n",
    "    Q0select = subset_data[:Q0select_raw]\n",
    "    Q0NOTselect = subset_data[:Q0NOTselect_raw] \n",
    "    Q1select = subset_data[:Q1select_raw]\n",
    "    Q1NOTselect = subset_data[:Q1NOTselect_raw] \n",
    "    QSselect = subset_data[:QSselect_raw]\n",
    "    QSNOTselect = subset_data[:QSNOTselect_raw] \n",
    "    \n",
    "    prev_choice = NaN;\n",
    "    \n",
    "    for t = 1:n_trials\n",
    "    \n",
    "        curr_choice = choices[t]\n",
    "        \n",
    "        #if not a pav trial \n",
    "        if curr_choice>0\n",
    "            \n",
    "            #if first choice (note first trial will be pav, missed responses already taken out) \n",
    "            #then do not include sticky parameter into softmax\n",
    "            if n_trials == 2\n",
    "                ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t])) \n",
    "                ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                prev_choice = curr_choice\n",
    "                \n",
    "            #if not the first choice then do not include sticky parameter into softmax    \n",
    "            elseif n_trials > 2\n",
    "                \n",
    "                # where sticky param is added depends whether the current choice equals the current choice\n",
    "                # if it is then add into the chosen probability\n",
    "                if curr_choice==prev_choice\n",
    "                    ProbChosen[t] = exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) \n",
    "                        + betas_stick)/(exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + betas_stick) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t])) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t];\n",
    "                    prev_choice = curr_choice;\n",
    "                # if it is then add into the not chosen probability\n",
    "                elseif curr_choice!=prev_choice\n",
    "                    ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + exp((betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t]) + betas_stick)) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                    prev_choice = curr_choice;\n",
    "                end\n",
    "                \n",
    "            end\n",
    "                \n",
    "        else\n",
    "            ProbChosen[t]  = NaN;\n",
    "            ProbUnchosen[t] = NaN;\n",
    "            ProbChosen_minus_Unchosen[t] = NaN;\n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    ProbChosen_ALL = [ProbChosen_ALL; ProbChosen]\n",
    "    ProbUnchosen_ALL = [ProbUnchosen_ALL; ProbUnchosen]\n",
    "    ProbChosen_minus_Unchosen_ALL = [ProbChosen_minus_Unchosen_ALL; ProbChosen_minus_Unchosen]\n",
    "    \n",
    "end\n",
    "\n",
    "#Now bung into data frame and merge with rest\n",
    "\n",
    "Q_probs = DataFrame([ProbChosen_ALL, ProbUnchosen_ALL, ProbChosen_minus_Unchosen_ALL]) \n",
    "\n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_probs, [:ProbChosen, :ProbUnchosen, :ProbChosen_minus_Unchosen])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous full compile)\n",
    "full_Q_compile = hcat(full_Q_compile, Q_probs); #could also do just: [full_Q_compile Q_probs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save parameters to csv file\n",
    "writetable(\"full_learner_Qvalues.csv\", DataFrame(full_Q_compile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
