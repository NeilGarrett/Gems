{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start up commands/load relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling CSV [336ed68f-0bac-5ca0-87d4-7b16caf5d00b]\n",
      "└ @ Base loading.jl:1187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 2:\t┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "      From worker 2:\t│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "      From worker 2:\t└ @ Base loading.jl:941\n",
      "      From worker 3:\t┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "      From worker 3:\t│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "      From worker 3:\t└ @ Base loading.jl:941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Module Tables with build ID 63066342871565 is missing from the cache.\n",
      "│ This may mean Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:941\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(covvar < 0) ? NaN :sqrt` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288.\n",
      "│ Use `(covvar < 0) ? NaN : sqrt` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:288\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN:` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299\n",
      "┌ Warning: Deprecated syntax `(diag(covmtx)[i] .< 0) ? NaN :diag` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299.\n",
      "│ Use `(diag(covmtx)[i] .< 0) ? NaN : diag` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:299\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: `@parallel` is deprecated, use `@distributed` instead.\n",
      "│   caller = include at boot.jl:317 [inlined]\n",
      "└ @ Core ./boot.jl:317\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a)?` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ?` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)):` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `any(x -> begin\n",
      "│     # /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl, line 66\n",
      "│     isa(x, Array)\n",
      "│ end, a) ? flatten(vcat(map(flatten, a)...)) :` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:67\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:67\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T, 1})` around /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66.\n",
      "│ Use `flatten(a::Array{T, 1}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:66\n",
      "┌ Warning: Deprecated syntax `parametric method syntax flatten{T}(a::Array{T})` around /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:67.\n",
      "│ Use `flatten(a::Array{T}) where T` instead.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/common.jl:67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/genVars.jl:17.\n",
      "└ @ nothing /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/genVars.jl:17\n",
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/genVars.jl:17.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/genVars.jl:17\n",
      "┌ Warning: Deprecated syntax `try without catch or finally` at /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/genVars.jl:17.\n",
      "└ @ ~/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/genVars.jl:17\n"
     ]
    }
   ],
   "source": [
    "# load required libraries\n",
    "using Distributed\n",
    "\n",
    "# # set everything up\n",
    "parallel = true # Run on multiple CPUs. If youhttp://localhost:8888/notebooks/Dropbox/Daw_Lab/PreySelection/v103/models/model_subjective1beta2lr_delayreward/model_subjective1beta2lr_delayreward.jl.ipynb# are having trouble, set parallel = false: easier to debug\n",
    "\n",
    "# this activates the multiprocessing threads\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "    addprocs(2)\n",
    "end\n",
    "\n",
    "# load required libraries\n",
    "@everywhere using DataFrames\n",
    "@everywhere using ForwardDiff\n",
    "@everywhere using PyCall\n",
    "@everywhere using Distributions\n",
    "@everywhere using PyPlot\n",
    "@everywhere using CSV\n",
    "@everywhere using SpecialFunctions\n",
    "@everywhere using SharedArrays\n",
    "@everywhere using LinearAlgebra\n",
    "\n",
    "@everywhere PyCall.@pyimport scipy.optimize as so\n",
    "\n",
    "# this is the code for the actual fitting routines\n",
    "@everywhere include(\"em.jl\")\n",
    "@everywhere include(\"common.jl\")\n",
    "@everywhere include(\"likfuns.jl\")\n",
    "\n",
    "# this is generates starting matricies for betas, sigmas etc to feed into model\n",
    "@everywhere include(\"genVars.jl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data read and process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: readtable is deprecated, use CSV.read from the CSV package instead\n",
      "│   caller = top-level scope at In[2]:1\n",
      "└ @ Core In[2]:1\n",
      "┌ Warning: `a::AbstractArray + b::Number` is deprecated, use `a .+ b` instead.\n",
      "│   caller = top-level scope at In[2]:10\n",
      "└ @ Core In[2]:10\n",
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[2]:22\n",
      "└ @ Core In[2]:22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>participantID</th><th>block_n</th><th>trials</th><th>blockType</th><th>forcedTrial</th><th>gem_presented</th><th>market_presented</th><th>door_side</th><th>chooseLeft</th><th>outcomeState</th><th>outcome</th><th>ons_fixation</th><th>ons_door_display</th><th>ons_responsecue</th><th>ons_gem_fixation</th><th>ons_outcome_display</th><th>ons_condition_text</th><th>ons_trigger</th><th>missed_trial</th><th>rew_loss</th><th>rt</th><th>prob_market_presented</th><th>correct_choice</th><th>market_reversal</th><th>pick_black</th><th>black_presented_force</th><th>prob_independent_1</th><th>prob_independent_2</th><th>prob_dependent</th><th>sub</th><th>state_chosen</th></tr><tr><th></th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64</th><th>Int64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Int64⍰</th><th>Integer</th></tr></thead><tbody><p>6 rows × 31 columns</p><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1.0</td><td>2</td><td>0.0</td><td>12435.6</td><td>12440.7</td><td>12443.7</td><td>12445.3</td><td>12448.1</td><td>12432.6</td><td>NaN</td><td>0</td><td>1</td><td>0.658662</td><td>0.8</td><td>NaN</td><td>0</td><td>1.0</td><td>1.0</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>1</td></tr><tr><th>2</th><td>1</td><td>1</td><td>2</td><td>1</td><td>0</td><td>2</td><td>1</td><td>2</td><td>1.0</td><td>1</td><td>-1.0</td><td>12450.1</td><td>12452.6</td><td>12456.1</td><td>12457.6</td><td>12461.8</td><td>NaN</td><td>NaN</td><td>0</td><td>-1</td><td>0.599319</td><td>0.8</td><td>0.0</td><td>0</td><td>1.0</td><td>NaN</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>1</td></tr><tr><th>3</th><td>1</td><td>1</td><td>3</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1.0</td><td>2</td><td>0.0</td><td>12463.8</td><td>12466.4</td><td>12468.2</td><td>12469.8</td><td>12474.8</td><td>NaN</td><td>NaN</td><td>0</td><td>1</td><td>0.781297</td><td>0.8</td><td>NaN</td><td>0</td><td>1.0</td><td>1.0</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>1</td></tr><tr><th>4</th><td>1</td><td>1</td><td>4</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1.0</td><td>2</td><td>0.0</td><td>12476.8</td><td>12481.7</td><td>12484.1</td><td>12485.6</td><td>12488.7</td><td>NaN</td><td>NaN</td><td>0</td><td>-1</td><td>0.889409</td><td>0.8</td><td>1.0</td><td>0</td><td>2.0</td><td>NaN</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>2</td></tr><tr><th>5</th><td>1</td><td>1</td><td>5</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1.0</td><td>1</td><td>-1.0</td><td>12490.7</td><td>12494.0</td><td>12496.4</td><td>12497.9</td><td>12501.1</td><td>NaN</td><td>NaN</td><td>0</td><td>-1</td><td>0.389441</td><td>0.8</td><td>NaN</td><td>0</td><td>1.0</td><td>1.0</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>1</td></tr><tr><th>6</th><td>1</td><td>1</td><td>6</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>0.0</td><td>1</td><td>-1.0</td><td>12503.1</td><td>12509.0</td><td>12512.2</td><td>12513.8</td><td>12517.5</td><td>NaN</td><td>NaN</td><td>0</td><td>-1</td><td>0.302638</td><td>0.8</td><td>NaN</td><td>0</td><td>2.0</td><td>0.0</td><td>0.2</td><td>0.8</td><td>0.8</td><td>1</td><td>2</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccccccccccccccccccccccc}\n",
       "\t& participantID & block\\_n & trials & blockType & forcedTrial & gem\\_presented & market\\_presented & door\\_side & chooseLeft & outcomeState & outcome & ons\\_fixation & ons\\_door\\_display & ons\\_responsecue & ons\\_gem\\_fixation & ons\\_outcome\\_display & ons\\_condition\\_text & ons\\_trigger & missed\\_trial & rew\\_loss & rt & prob\\_market\\_presented & correct\\_choice & market\\_reversal & pick\\_black & black\\_presented\\_force & prob\\_independent\\_1 & prob\\_independent\\_2 & prob\\_dependent & sub & state\\_chosen\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & 1 & 2 & 1 & 1 & 1.0 & 2 & 0.0 & 12435.6 & 12440.7 & 12443.7 & 12445.3 & 12448.1 & 12432.6 & NaN & 0 & 1 & 0.658662 & 0.8 & NaN & 0 & 1.0 & 1.0 & 0.2 & 0.8 & 0.8 & 1 & 1 \\\\\n",
       "\t2 & 1 & 1 & 2 & 1 & 0 & 2 & 1 & 2 & 1.0 & 1 & -1.0 & 12450.1 & 12452.6 & 12456.1 & 12457.6 & 12461.8 & NaN & NaN & 0 & -1 & 0.599319 & 0.8 & 0.0 & 0 & 1.0 & NaN & 0.2 & 0.8 & 0.8 & 1 & 1 \\\\\n",
       "\t3 & 1 & 1 & 3 & 1 & 1 & 2 & 1 & 1 & 1.0 & 2 & 0.0 & 12463.8 & 12466.4 & 12468.2 & 12469.8 & 12474.8 & NaN & NaN & 0 & 1 & 0.781297 & 0.8 & NaN & 0 & 1.0 & 1.0 & 0.2 & 0.8 & 0.8 & 1 & 1 \\\\\n",
       "\t4 & 1 & 1 & 4 & 1 & 0 & 1 & 1 & 1 & 1.0 & 2 & 0.0 & 12476.8 & 12481.7 & 12484.1 & 12485.6 & 12488.7 & NaN & NaN & 0 & -1 & 0.889409 & 0.8 & 1.0 & 0 & 2.0 & NaN & 0.2 & 0.8 & 0.8 & 1 & 2 \\\\\n",
       "\t5 & 1 & 1 & 5 & 1 & 1 & 1 & 1 & 1 & 1.0 & 1 & -1.0 & 12490.7 & 12494.0 & 12496.4 & 12497.9 & 12501.1 & NaN & NaN & 0 & -1 & 0.389441 & 0.8 & NaN & 0 & 1.0 & 1.0 & 0.2 & 0.8 & 0.8 & 1 & 1 \\\\\n",
       "\t6 & 1 & 1 & 6 & 1 & 1 & 1 & 1 & 2 & 0.0 & 1 & -1.0 & 12503.1 & 12509.0 & 12512.2 & 12513.8 & 12517.5 & NaN & NaN & 0 & -1 & 0.302638 & 0.8 & NaN & 0 & 2.0 & 0.0 & 0.2 & 0.8 & 0.8 & 1 & 2 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×31 DataFrame. Omitted printing of 26 columns\n",
       "│ Row │ participantID │ block_n │ trials │ blockType │ forcedTrial │\n",
       "│     │ \u001b[90mInt64⍰\u001b[39m        │ \u001b[90mInt64⍰\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mInt64⍰\u001b[39m    │ \u001b[90mInt64⍰\u001b[39m      │\n",
       "├─────┼───────────────┼─────────┼────────┼───────────┼─────────────┤\n",
       "│ 1   │ 1             │ 1       │ 1      │ 1         │ 1           │\n",
       "│ 2   │ 1             │ 1       │ 2      │ 1         │ 0           │\n",
       "│ 3   │ 1             │ 1       │ 3      │ 1         │ 1           │\n",
       "│ 4   │ 1             │ 1       │ 4      │ 1         │ 0           │\n",
       "│ 5   │ 1             │ 1       │ 5      │ 1         │ 1           │\n",
       "│ 6   │ 1             │ 1       │ 6      │ 1         │ 1           │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data\n",
    "df = readtable(\"/Users/Neil/GitHubRepo/Projects/ValueInference/study4_mri/data/gem_dat.csv\")\n",
    "\n",
    "#get rid of missed responses\n",
    "df = df[df[:missed_trial].!=1,:]\n",
    "\n",
    "#add \"sub column\" \n",
    "# this is just a replica of the existing column sub_no but I think em looks for \"sub\" specifically\n",
    "df[:sub] = df[:participantID];\n",
    "\n",
    "#change coding so that 1 = market 1 in dependent condition,\n",
    "#2 and 3 refer to the two markets in the independent condition\n",
    "df[:market_presented] = df[:market_presented] + 1\n",
    "df[df[:blockType].==1,:market_presented] = 1\n",
    "\n",
    "#code picking white as 2, picking black as 1\n",
    "df[:state_chosen] = df[:pick_black]\n",
    "df[df[:state_chosen].==0, :state_chosen] = 2\n",
    "\n",
    "#convert this so can use in model\n",
    "df[:state_chosen] = convert(Vector{Integer}, df[:state_chosen])\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exlude subs 21 and 28..\n",
    "\n",
    "df = df[df[:participantID].!=21,:];\n",
    "df = df[df[:participantID].!=28,:];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use recoded condition variable in the model\n",
    "df[:condition_recode] = df[:blockType]\n",
    "df[df[:condition_recode].==2,:condition_recode] = -1\n",
    "\n",
    "#now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function rl_model(params, data)\n",
    "    \n",
    "    #model parameteres\n",
    "\tbeta_mb = params[1] #weight for MB\n",
    "    w_intercept = params[2] #weight for MB\n",
    "    w_slope = params[3]\n",
    "    lr =  0.5 .+ 0.5.*erf(params[4]/sqrt(2))\n",
    "    \n",
    "    c1 = data[:state_chosen] # choice: 1 = black door, 2 = white door\n",
    "    r = data[:outcome] # outcome: coded as +1 = gain, -1 = loss, 0 = neutral \n",
    "    s = data[:outcomeState] # stage 2 state: coded as 1 = gain/loss state reached, 2 = neutral state reached\n",
    "    t = data[:trials] # trial number\n",
    "    sub = data[:sub] # subject number\n",
    "    condition = data[:condition_recode] # condition: 1 = dependent, -1=independent\n",
    "    gem = data[:gem_presented] #gem presented\n",
    "    market = data[:market_presented] #market presented\n",
    "    reward_loss_trial = data[:rew_loss]\n",
    "    force_t = data[:forcedTrial]\n",
    "    block_n = data[:block_n]\n",
    "    \n",
    "    SR_m = zeros(typeof(beta_mb), 2) .+ 0.5 #initalise to 0.5. stores estimates of transition probabilities for black/white door going to reward/loss state \n",
    "    SR_gem = zeros(typeof(beta_mb), 4) .+ 0.5 #initalise to 0.5. stores estimates of transition probabilities for black/white door going to reward/loss state \n",
    "   \n",
    "\tQmb = zeros(typeof(beta_mb), 2) #decision variable\n",
    "    Qmb_gem = zeros(typeof(beta_mb), 2) #decision variable\n",
    "    \n",
    "    #encode in the frame of getting to the rl state\n",
    "    prob_rl_chosen_m = [];\n",
    "    prob_rl_unchosen_m = [];\n",
    "    \n",
    "    ev_rl_chosen_m = [];\n",
    "    ev_rl_unchosen_m = [];\n",
    "    \n",
    "    prob_rl_chosen_gem = [];\n",
    "    prob_rl_unchosen_gem = [];\n",
    "\n",
    "    ev_rl_chosen_gem = [];\n",
    "    ev_rl_unchosen_gem = [];\n",
    "    \n",
    "    PE_m_compile_signed = [];\n",
    "    PE_m_compile_abs = [];\n",
    "    PE_gem_compile_signed = [];\n",
    "    PE_gem_compile_abs = [];\n",
    "    \n",
    "    # initialize likelihood\n",
    "    lik = 0 \n",
    "    \n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        w = w_intercept + w_slope*(condition[i])\n",
    "\n",
    "        if gem[i]<3\n",
    "            index = 1            \n",
    "        else\n",
    "            index = 2\n",
    "        end\n",
    "                \n",
    "        Qmb = [SR_m[index].*reward_loss_trial[i], (1-SR_m[index]).*reward_loss_trial[i]]\n",
    "        Qmb_gem = [SR_gem[gem[i]].*reward_loss_trial[i], (1-SR_gem[gem[i]]).*reward_loss_trial[i]]\n",
    "       \n",
    "        if (c1[i]==1)\n",
    "            append!(prob_rl_chosen_m, SR_m[index]); append!(prob_rl_unchosen_m, 1-SR_m[index]);\n",
    "            append!(prob_rl_chosen_gem, SR_gem[gem[i]]); append!(prob_rl_unchosen_gem, 1-SR_gem[gem[i]]);\n",
    "            append!(ev_rl_chosen_m, Qmb[1]); append!(ev_rl_unchosen_m, Qmb[2]);    \n",
    "            append!(ev_rl_chosen_gem, Qmb_gem[1]); append!(ev_rl_unchosen_gem, Qmb_gem[2]);    \n",
    "            \n",
    "        elseif (c1[i]==2)\n",
    "            append!(prob_rl_chosen_m, 1-SR_m[index]); append!(prob_rl_unchosen_m, SR_m[index]);\n",
    "            append!(prob_rl_chosen_gem, 1-SR_gem[gem[i]]); append!(prob_rl_unchosen_gem, SR_gem[gem[i]]);    \n",
    "            append!(ev_rl_chosen_m, Qmb[2]); append!(ev_rl_unchosen_m, Qmb[1]);  \n",
    "            append!(ev_rl_chosen_gem, Qmb_gem[2]); append!(ev_rl_unchosen_gem, Qmb_gem[1]);    \n",
    "        end\n",
    "        \n",
    "        # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "        # add that likelihood to the running likelihood\n",
    "        #only implement for force trials\n",
    "        if (force_t[i] == 0)\n",
    "            \n",
    "            #Q-values that determine the decision\n",
    "            #Qd = beta_mb.*Qmb + beta_mb_gem.*Qmb_gem\n",
    "            Q_combined = (1-w).*Qmb + w.*Qmb_gem\n",
    "            Qd = beta_mb.*Q_combined\n",
    "            \n",
    "            lik += Qd[c1[i]] .- log(sum(exp.(Qd)))\n",
    "            \n",
    "        else\n",
    "        end\n",
    "\n",
    "        # updates go in here - these are updates of probability estimates (not contingent on outcome)\n",
    "        if (s[i]==1 & c1[i]==1)\n",
    "            PE_m = 1 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*1\n",
    "            PE_gem = 1 - SR_gem[gem[i]]\n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*1\n",
    "        elseif (s[i]==2 & c1[i]==2)\n",
    "            PE_m = 1 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*1\n",
    "            PE_gem = 1 - SR_gem[gem[i]]           \n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*1\n",
    "        else\n",
    "            PE_m = 0 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*0\n",
    "            PE_gem = 0 - SR_gem[gem[i]]            \n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*0\n",
    "        end\n",
    "        \n",
    "        append!(PE_m_compile_signed, PE_m); \n",
    "        append!(PE_m_compile_abs, abs(PE_m));    \n",
    "        append!(PE_gem_compile_signed, PE_gem);    \n",
    "        append!(PE_gem_compile_abs, abs(PE_gem));\n",
    "        \n",
    "\tend\n",
    "    \n",
    "    #compile trial by trial values here\n",
    "    trial_data = DataFrame(trial = t,\n",
    "    sub = sub,\n",
    "    block_n = block_n,\n",
    "    choice = c1,\n",
    "    outcomeState = s,\n",
    "    outcome = r,\n",
    "    gem = gem,\n",
    "    condition = condition,\n",
    "    market = market,\n",
    "    force_t = force_t,\n",
    "    prob_rl_chosen_m = prob_rl_chosen_m,\n",
    "    prob_rl_unchosen_m = prob_rl_unchosen_m,\n",
    "    ev_rl_chosen_m = ev_rl_chosen_m,\n",
    "    ev_rl_unchosen_m = ev_rl_unchosen_m,\n",
    "    prob_rl_chosen_gem = prob_rl_chosen_gem,\n",
    "    prob_rl_unchosen_gem = prob_rl_unchosen_gem,\n",
    "    ev_rl_chosen_gem =ev_rl_chosen_gem,\n",
    "    ev_rl_unchosen_gem = ev_rl_unchosen_gem,\n",
    "    PE_m_compile_signed = PE_m_compile_signed,\n",
    "    PE_m_compile_abs = PE_m_compile_abs,\n",
    "    PE_gem_compile_signed = PE_gem_compile_signed,\n",
    "    PE_gem_compile_abs = PE_gem_compile_abs)\n",
    "\n",
    "    # here if running em you can only return the likelihood\n",
    "    return -lik\n",
    "    #return (-lik, trial_data)\n",
    "\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model for one subject\n",
    "(aids debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.372332903115804"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize parameter structures\n",
    "(df, subs, X, betas, sigma) = genVars(df, 4);\n",
    "\n",
    "# run model for sub 1\n",
    "rl_model(betas, df[df[:sub].==subs[1], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run em to get best fit parameters for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 73\n",
      "betas: [1.5, 0.38, -0.27, 0.41]\n",
      "sigma: [0.9 0.08 -0.31 -0.68; 0.08 0.04 -0.02 -0.02; -0.31 -0.02 0.11 0.26; -0.68 -0.02 0.26 0.92]\n",
      "change: [3.8e-5, 7.7e-5, -8.1e-5, 0.000862, 0.000245, 2.8e-5, -2.2e-5, -0.000754, 0.000624, -0.000232, -0.001158, 0.000916, 0.00015, 0.000699]\n",
      "max: 0.000916\n",
      "160.646370 seconds (70.46 M allocations: 2.072 GiB, 0.69% gc time)\n"
     ]
    }
   ],
   "source": [
    "# initialized parameter structures (again)\n",
    "# note that some of the variables (e.g. betas, sigma) are entered and returned by em function \n",
    "(df, subs, X, betas, sigma) = genVars(df, 4);\n",
    "\n",
    "# run for full learner\n",
    "# x contains the parameters for each subject (note not the same as variable X)\n",
    "# l and h are per-subject likelihood and hessians\n",
    "@time (betas, sigma, x, l, h) = em(df, subs, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true, quiet=false);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Model Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBIC, IAIC and LOOcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 1..2..3..4..5..6..7..8..9..10..11..12..13..14..15..16..17..18..19..20..21..22..23..24..25..26..27..28..29..1350.093646152738"
     ]
    }
   ],
   "source": [
    "## model selection/comparison/scoring\n",
    "\n",
    "# laplace approximation to the aggregate log marginal likelihood of the whole dataset\n",
    "# marginalized over the individual params\n",
    "\n",
    "aggll = lml(x, l, h)\n",
    "\n",
    "# to compare this between models you need to correct for the group-level free parameters\n",
    "# either aic or bic\n",
    "\n",
    "aggll_ibic = ibic(x, l, h, betas, sigma, nrow(df))\n",
    "aggll_iaic = iaic(x, l, h, betas, sigma)\n",
    "\n",
    "# or you can compute unbiased per subject marginal likelihoods via subject-level cross validation\n",
    "# you can do paired t tests on these between models\n",
    "# these are also appropriate for SPM_BMS etc\n",
    "\n",
    "# takes ages so comment in when want to run, otherwise just use IAIC above\n",
    "liks = loocv(df, subs, x, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true)\n",
    "#aggll_loo = sum(liks)\n",
    "\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll: $aggll_iaic\\nloo nll:  $aggll_loo\")\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll:\")\n",
    "print(aggll_iaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write loocv scores to csv file\n",
    "\n",
    "(if you have run this part above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"loocv_scores.csv\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put loocv scores into dataframe\n",
    "loocv_scores = DataFrame(sub = subs,\n",
    "liks = vec(liks));\n",
    "\n",
    "#write to csv\n",
    "CSV.write(\"loocv_scores.csv\", DataFrame(loocv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and write p values, std error and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "in #53 at none\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "WARNING: LinearAlgebra.trace is deprecated, use tr instead.\n",
      "  likely near /Users/neil/.julia/packages/IJulia/GIANC/src/kernel.jl:41\n",
      "in #53 at none\n",
      "┌ Warning: `ccdf(d::UnivariateDistribution, X::AbstractArray)` is deprecated, use `ccdf.(d, X)` instead.\n",
      "│   caller = emerrors(::DataFrame, ::Array{Union{Missing, Int64},1}, ::SharedArray{Float64,2}, ::Array{Float64,3}, ::SharedArray{Float64,3}, ::Array{Float64,1}, ::Array{Float64,2}, ::Function) at em.jl:300\n",
      "└ @ Main /Users/neil/GitHubRepo/Projects/ValueInference/study4_mri/models/model5/em.jl:300\n"
     ]
    }
   ],
   "source": [
    "# standard errors on the subject-level means, based on an asymptotic Gaussian approx \n",
    "# (these may be inflated esp for small n)\n",
    "(standarderrors, pvalues, covmtx) = emerrors(df, subs, x, X, h, betas, sigma, rl_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = DataFrame(stderror = vec(standarderrors),\n",
    "pvalues = vec(pvalues),\n",
    "covmtx_1 = vec(covmtx[:,1]),\n",
    "covmtx_2 = vec(covmtx[:,2]),\n",
    "covmtx_3 = vec(covmtx[:,3]),\n",
    "covmtx_4 = vec(covmtx[:,4]))\n",
    "\n",
    "# save model stats to csv file\n",
    "CSV.write(\"model_stats.csv\", DataFrame(model_stats));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.204707, 0.0785324, 0.0477878, 0.328098]"
     ]
    }
   ],
   "source": [
    "print(standarderrors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.97961e-13, 1.54164e-6, 0.00426516, 0.217232]"
     ]
    }
   ],
   "source": [
    "print(pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0419051 0.0026705 -0.00473983 -0.0280005; 0.0026705 0.00616734 0.000115523 0.00269598; -0.00473983 0.000115523 0.00228368 0.00554894; -0.0280005 0.00269598 0.00554894 0.107648]"
     ]
    }
   ],
   "source": [
    "print(covmtx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write per subject model parameters to csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save a copy of just the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"subject_params.csv\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put parameters into variable d\n",
    "d=x';\n",
    "\n",
    "# now put parameters into dataframe\n",
    "params = DataFrame(sub = subs,\n",
    "beta_mb = vec(d[:, 1]),\n",
    "w_intercept = vec(d[:, 2]),\n",
    "w_slope = vec(d[:, 3]),   \n",
    "eta_unconverted = vec(d[:, 4]),\n",
    "eta_converted = vec(0.5 .+ 0.5*erf.(d[:, 4] / sqrt(2))))\n",
    "\n",
    "# save parameters to csv file\n",
    "CSV.write(\"subject_params.csv\", DataFrame(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = readtable(\"subject_params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Deprecated syntax `implicit assignment to global variable `x``.\n",
      "│ Use `global x` instead.\n",
      "└ @ nothing none:0\n",
      "┌ Warning: Loop variable `x` around In[51]:6 overwrites a variable in an enclosing scope. In the future the variable will be local to the loop instead.\n",
      "└ @ nothing In[51]:6\n",
      "┌ Warning: `convert(::Type{Array}, dfr::DataFrameRow)` is deprecated, use `permutedims(Vector(dfr))` instead.\n",
      "│   caller = top-level scope at In[51]:12\n",
      "└ @ Core ./In[51]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9094, 32)(9094, 22)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `head(df::AbstractDataFrame)` is deprecated, use `first(df, 6)` instead.\n",
      "│   caller = top-level scope at In[51]:32\n",
      "└ @ Core In[51]:32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"trial_by_trial_vals.csv\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize parameter structures once again\n",
    "(df, subs, X, betas, sigma) = genVars(df, 4);\n",
    "\n",
    "# initalise this - will store all trial to trial parameters\n",
    "trial_data_compile = [];\n",
    "\n",
    "# run model for each subject using best fit parameters\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = convert(Array, params[x, [:beta_mb, :eta_unconverted, :w_intercept, :w_slope]])\n",
    "    data_sub = df[df[:sub].==subs[x], :]\n",
    "    \n",
    "    # run model using these parameters - note must have commented in the model to return all of these variables (and not only -lik)\n",
    "    (minus_li, trial_data) = rl_model(betas_sub, data_sub)\n",
    "    \n",
    "    if x.==1\n",
    "        \n",
    "        trial_data_compile = trial_data\n",
    "        \n",
    "    else\n",
    "        \n",
    "        append!(trial_data_compile, trial_data)\n",
    "        \n",
    "    end\n",
    " \n",
    "end\n",
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(trial_data_compile))\n",
    "\n",
    "# print header of data compile\n",
    "head(trial_data_compile)\n",
    "\n",
    "CSV.write(\"trial_by_trial_vals.csv\", DataFrame(trial_data_compile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
