{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Start up commands/load relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load required libraries\n",
    "using Distributed\n",
    "\n",
    "# # set everything up\n",
    "parallel = true # Run on multiple CPUs. If youhttp://localhost:8888/notebooks/Dropbox/Daw_Lab/PreySelection/v103/models/model_subjective1beta2lr_delayreward/model_subjective1beta2lr_delayreward.jl.ipynb# are having trouble, set parallel = false: easier to debug\n",
    "\n",
    "# this activates the multiprocessing threads\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "    addprocs(4)\n",
    "end\n",
    "\n",
    "# load required libraries\n",
    "@everywhere using DataFrames\n",
    "@everywhere using ForwardDiff\n",
    "@everywhere using PyCall\n",
    "@everywhere using Distributions\n",
    "@everywhere using PyPlot\n",
    "@everywhere using CSV\n",
    "@everywhere using SpecialFunctions\n",
    "@everywhere using SharedArrays\n",
    "@everywhere using LinearAlgebra\n",
    "\n",
    "@everywhere PyCall.@pyimport scipy.optimize as so\n",
    "\n",
    "# this is the code for the actual fitting routines\n",
    "@everywhere include(\"em.jl\")\n",
    "@everywhere include(\"common.jl\")\n",
    "@everywhere include(\"likfuns.jl\")\n",
    "\n",
    "# this is generates starting matricies for betas, sigmas etc to feed into model\n",
    "@everywhere include(\"genVars.jl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data read and process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#read in csv file of the data\n",
    "#this already has subjects 19, 25 and 26 removed and just contains states, rewards, choices along with trial and subject number\n",
    "#missed responses have also been removed\n",
    "#reward coded as 1 when shock is avoided, -1 when shock is delivered\n",
    "df = readtable(\"/Users/neil/GitHubRepo/Projects/Aversive2Step/data/processed/julia_raw_data_ex_19_25_26.csv\")\n",
    "\n",
    "# change states from 2,3 to 1,2; this allows you to use states as index to update relevant values based on states encountered\n",
    "df[:s] = df[:s]-1\n",
    "\n",
    "# here - rescale rewards to sit between -0.5 (=shock) and 0.5 (=no shock)\n",
    "df[:r] = df[:r]./2\n",
    "\n",
    "# display header\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Read in summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#read in summary stats as well - can combine with parameters, LOOcv scores etc later on\n",
    "summary_stats = readtable(\"/Users/neil/GitHubRepo/Projects/Aversive2Step/data/processed/data_summary.csv\")\n",
    "\n",
    "#delete subjects 19, 25 and 26\n",
    "summary_stats = summary_stats[summary_stats[:subjects].!=19, :]\n",
    "summary_stats = summary_stats[summary_stats[:subjects].!=25, :]\n",
    "summary_stats = summary_stats[summary_stats[:subjects].!=26, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RL Model (Basic)\n",
    "\n",
    "Model comprises:\n",
    "\n",
    "(1) 3 beta weights - one for MB component, one for TD0 component of MF, one for TD1 component of MF. These beta weights are used to create one composite decision value for each action which is input into softmax to predict choice on each trial.\n",
    "\n",
    "(2) Here there is no seperate trace of Qvals for Pav trials. On Pav trials, agents assume to update the value of the state (just as if they had made a choice to get there).\n",
    "\n",
    "(3) One learning rate for all trial types and updates (i.e. no distinction between Pav and Instrumental or between MB and MF updates). \n",
    "\n",
    "(4) Perseverance parameter to model tendency to simply repeat past choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@everywhere function rl_model(params, data)\n",
    "    \n",
    "    #model parameteres\n",
    "\tbeta_mb = params[1] #weight for MB\n",
    "\tbeta_mf0 = params[2] #weight for MF TD0\n",
    "    beta_mf1 = params[3] #weight for MF TD1\n",
    "    lr = 0.5 + 0.5 * erf(params[4] / sqrt(2)) #learning rate\n",
    "    \n",
    "    # perseveration/stickiness parameter\n",
    "    ps = params[5]\n",
    "            \n",
    "    c1 = data[:c1] # choice 1, 1 and 2 for left vs. right\n",
    "    r = data[:r] # coded as -1 and 1; note that here -1 is shock \n",
    "    s = data[:s] # stage 2 state, coded as 1 and 2 \n",
    "    t = data[:trial] # trial\n",
    "    sub = data[:sub] # subject number\n",
    "    \n",
    "    Q0 = zeros(typeof(beta_mb), 2) #TD0\n",
    "    Q0s2 = zeros(typeof(beta_mb), 2) #values of stage 2 states\n",
    "    Q1 = zeros(typeof(beta_mb), 2) #TD1\n",
    "\tQm = zeros(typeof(beta_mb), 2) #MB values for state most commonly transitioned to for left/right action\n",
    "\n",
    "    #initialize these arrays (will store trial to trial values)\n",
    "    Q0_raw_left = []; Q0_raw_right = [];\n",
    "    Q1_raw_left = []; Q1_raw_right = [];\n",
    "    Q0s2_raw_left = []; Q0s2_raw_right = [];\n",
    "    Q0s2_raw_encounter_check = []; Q0s2_raw_NOTencounter_check = []; \n",
    "    Qd_left = []; Qd_right = [];\n",
    "    \n",
    "    # initialize likelihood\n",
    "    lik = 0 \n",
    "\n",
    "    # tracking previous choice to determine perseveration\n",
    "    prevc = 0 \n",
    "\n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        # store these on each trial        \n",
    "        \n",
    "        # note that Q values are before update occurs on that trial (so can model choice based on existing Qvals)\n",
    "        # model raw values\n",
    "        append!(Q0_raw_left, Q0[1]); append!(Q0_raw_right, Q0[2])\n",
    "        append!(Q1_raw_left, Q1[1]); append!(Q1_raw_right, Q1[2])\n",
    "        append!(Q0s2_raw_left, Q0s2[1]); append!(Q0s2_raw_right, Q0s2[2])\n",
    "        append!(Q0s2_raw_encounter_check, Q0s2[s[i]]); append!(Q0s2_raw_NOTencounter_check, Q0s2[abs(3-s[i])])\n",
    "        \n",
    "        #if a choice trial (won't be the case for the pavlovian trials)\n",
    "        if (c1[i]>0) \n",
    "            \n",
    "            # calculate model-based component of Q values - in this design is simply the value of the state each action most commonly transitions to            \n",
    "\t\t\tQm = [Q0s2[1], Q0s2[2]] #or technically Qm = [.7*Q0[2] + .3*Q0[3],.3*Q0[2] + .7*Q0[3]]           \n",
    "            \n",
    "            # ultimately, the Q-values that determine the decision are a weighted combination of MB and MF values\n",
    "            Qd = beta_mb.* Qm + beta_mf0.*(Q0) + beta_mf1.*(Q1)\n",
    "            \n",
    "            append!(Qd_left, Qd[1]); append!(Qd_right, Qd[2]);\n",
    "\n",
    "            # plus perseveration bonus to last choice \n",
    "\t\t\tif prevc>0\n",
    "\t\t\t\tQd[prevc] += ps # increments Qd[prevc] by ps \n",
    "\t\t\tend\n",
    "            \n",
    "            # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "            # add that likelihood to the running likelihood\n",
    "            lik += Qd[c1[i]] - log(sum(exp.(Qd)))\n",
    "                  \n",
    "            # updates go in here\n",
    "            Q0[c1[i]] = (1-lr) * Q0[c1[i]] + lr*Q0s2[s[i]] #TD0\n",
    "            Q1[c1[i]] = (1-lr) * Q1[c1[i]] + lr*r[i] #TD1\n",
    "\n",
    "            # store previous choice to apply perseverance bonus\n",
    "            prevc = c1[i]\n",
    "\n",
    "        else\n",
    "           \n",
    "            append!(Qd_left, NaN); \n",
    "            append!(Qd_right, NaN)\n",
    "            \n",
    "        end\n",
    "        \n",
    "        #update second stage state values according to outcomes\n",
    "\t\tQ0s2[s[i]] = (1-lr) * Q0s2[s[i]] + lr*r[i]\n",
    "                        \n",
    "\tend\n",
    "\n",
    "    # compile trial by trial values here\n",
    "    trial_data = DataFrame(trial = t,\n",
    "            sub = sub,\n",
    "            choice = c1,\n",
    "            state = s,\n",
    "            reward = r,\n",
    "            Q0_raw_left = Q0_raw_left,\n",
    "            Q0_raw_right = Q0_raw_right,\n",
    "            Q1_raw_left = Q1_raw_left,\n",
    "            Q1_raw_right = Q1_raw_right,\n",
    "            Q0s2_raw_left = Q0s2_raw_left,\n",
    "            Q0s2_raw_right = Q0s2_raw_right,\n",
    "            Qd_left = Qd_left,\n",
    "            Qd_right = Qd_right,\n",
    "            Q0s2_raw_encounter_check = Q0s2_raw_encounter_check,\n",
    "            Q0s2_raw_NOTencounter_check = Q0s2_raw_NOTencounter_check)\n",
    "        \n",
    "    # here if running em you can only return the likelihood\n",
    "    return -lik\n",
    "    \n",
    "    # but if you run in order to extract trials, subs etc then want to return this\n",
    "    #return (-lik, trial_data)\n",
    "       \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Parameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run model for one subject\n",
    "(aids debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initialize parameter structures\n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# run model for sub 1\n",
    "rl_model(betas,df[df[:sub].==subs[1],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run em to get best fit parameters for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initialized parameter structures (again)\n",
    "# note that some of the variables (e.g. betas, sigma) are entered and returned by em function \n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# run for full learner\n",
    "# x contains the parameters for each subject (note not the same as variable X)\n",
    "# l and h are per-subject likelihood and hessians\n",
    "@time (betas, sigma, x, l, h) = em(df, subs, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true, quiet=false);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Generate Model Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "IBIC, IAIC and LOOcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## model selection/comparison/scoring\n",
    "\n",
    "# laplace approximation to the aggregate log marginal likelihood of the whole dataset\n",
    "# marginalized over the individual params\n",
    "\n",
    "aggll = lml(x, l, h)\n",
    "\n",
    "# to compare this between models you need to correct for the group-level free parameters\n",
    "# either aic or bic\n",
    "\n",
    "aggll_ibic = ibic(x, l, h, betas, sigma, nrow(df))\n",
    "aggll_iaic = iaic(x, l, h, betas, sigma)\n",
    "\n",
    "# or you can compute unbiased per subject marginal likelihoods via subject-level cross validation\n",
    "# you can do paired t tests on these between models\n",
    "# these are also appropriate for SPM_BMS etc\n",
    "\n",
    "# takes ages so comment in when want to run, otherwise just use IAIC above\n",
    "liks = loocv(df, subs, x, X, betas, sigma, model_MVT; emtol=1e-3, parallel=true, full=true)\n",
    "#aggll_loo = sum(liks)\n",
    "\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll: $aggll_iaic\\nloo nll:  $aggll_loo\")\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll:\")\n",
    "print(aggll_iaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Write loocv scores to csv file\n",
    "\n",
    "(if you have run this part above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# put loocv scores into dataframe\n",
    "loocv_scores = DataFrame(sub = subs,\n",
    "liks = vec(liks));\n",
    "\n",
    "#write to csv\n",
    "CSV.write(\"loocv_scores.csv\", DataFrame(loocv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Calculate and write p values, std error and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# standard errors on the subject-level means, based on an asymptotic Gaussian approx \n",
    "# (these may be inflated esp for small n)\n",
    "(standarderrors, pvalues, covmtx) = emerrors(df,subs,x,X,h,betas,sigma,model_MVT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_stats = DataFrame(stderror = vec(standarderrors),\n",
    "pvalues = vec(pvalues),\n",
    "covmtx_1 = vec(covmtx[:,1]),\n",
    "covmtx_2 = vec(covmtx[:,2]),\n",
    "covmtx_3 = vec(covmtx[:,3]));\n",
    "\n",
    "# save model stats to csv file\n",
    "CSV.write(\"model_stats.csv\", DataFrame(model_stats));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(standarderrors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(covmtx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Write per subject model parameters to csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Save a copy of just the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# put parameters into variable d\n",
    "d=x';\n",
    "\n",
    "# now put parameters into dataframe\n",
    "params = DataFrame(sub = subs,\n",
    "betamb = vec(d[:,1]), \n",
    "beta_mf0 = vec(d[:,2]),\n",
    "beta_mf1 = vec(d[:,3]),\n",
    "eta_unconverted = vec(d[:,4]),\n",
    "eta_converted = vec(0.5 .+ 0.5*erf.(d[:,4] / sqrt(2))),\n",
    "sticky = vec(d[:,5]));\n",
    "\n",
    "# save parameters to csv file\n",
    "CSV.write(\"subject_params.csv\", DataFrame(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Save a copy with summary stats as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = params[:,2:end]\n",
    "summary_stats = [summary_stats params]\n",
    "CSV.write(\"summary_stats.csv\", DataFrame(summary_stats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Generate trial by trial values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get best fit parameters from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if you already have best fit parameters saved, can read in here (rather than running model to find)\n",
    "params_full = readtable(\"subject_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run model for each sub using best fit parameters\n",
    "\n",
    "Note: must rerun model with it set to return trial data (uncomment this)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initialize parameter structures once again\n",
    "(df, subs, X, betas, sigma) = genVars(df, 5);\n",
    "\n",
    "# initalise this - will store all trial to trial parameters\n",
    "trial_data_compile = []\n",
    "\n",
    "# run model for each subject using best fit parameters\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = Array(params[x, [:betamb, :beta_mf0, :beta_mf1, :eta_unconverted, :sticky]])\n",
    "    data_sub = df[df[:sub].==subs[x], :]\n",
    "    \n",
    "    # run model using these parameters - note must have commented in the model to return all of these variables (and not only -lik)\n",
    "    (minus_li, trial_data) = rl_model(betas_sub, data_sub)\n",
    "    \n",
    "    if x==1\n",
    "        \n",
    "        trial_data_compile = trial_data\n",
    "        \n",
    "    else\n",
    "        \n",
    "        append!(trial_data_compile, trial_data)\n",
    "        \n",
    "    end\n",
    " \n",
    "end\n",
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(trial_data_compile))\n",
    "\n",
    "# print header of data compile\n",
    "head(trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Seperate out Q values for options encountered/not encountered and Q values for options choosen/not choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for encountered option Q values, index states 1 and 2\n",
    "index_s1 = find(trial_data_compile[:state].==1)\n",
    "index_s2 = find(trial_data_compile[:state].==2)\n",
    "\n",
    "index_encounter = [index_s1; index_s2]\n",
    "\n",
    "# now use indexes to pull out Qvalues for options encountered for Q0, Q1 and Qs (raw and scaled values)\n",
    "# note that state 1 corresponds to left and 2 to right. \n",
    "# therefore if state encountered is 1, then pick left Q value for Q value of the option encountered, \n",
    "# and right Q value for the option not encountered\n",
    "Q0_raw_encounter = [trial_data_compile[index_s1,:Q0_raw_left]; trial_data_compile[index_s2,:Q0_raw_right]]\n",
    "Q0_raw_NOTencounter = [trial_data_compile[index_s1,:Q0_raw_right]; trial_data_compile[index_s2,:Q0_raw_left]]\n",
    "trial_data_compile[:Q0_raw_encounter] = vcat(Q0_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q0_raw_NOTencounter] = vcat(Q0_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q1_raw_encounter = [trial_data_compile[index_s1,:Q1_raw_left]; trial_data_compile[index_s2,:Q1_raw_right]]\n",
    "Q1_raw_NOTencounter = [trial_data_compile[index_s1,:Q1_raw_right]; trial_data_compile[index_s2,:Q1_raw_left]]\n",
    "trial_data_compile[:Q1_raw_encounter] = vcat(Q1_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q1_raw_NOTencounter] = vcat(Q1_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "Q0s2_raw_encounter = [trial_data_compile[index_s1,:Q0s2_raw_left]; trial_data_compile[index_s2,:Q0s2_raw_right]]\n",
    "Q0s2_raw_NOTencounter = [trial_data_compile[index_s1,:Q0s2_raw_right]; trial_data_compile[index_s2,:Q0s2_raw_left]]\n",
    "trial_data_compile[:Q0s2_raw_encounter] = vcat(Q0s2_raw_encounter[sortperm(index_encounter),:]...)\n",
    "trial_data_compile[:Q0s2_raw_NOTencounter] = vcat(Q0s2_raw_NOTencounter[sortperm(index_encounter),:]...)\n",
    "\n",
    "# for choosen option Q values, index choices 1 and 2 and 99 (so that length of columns is correct)\n",
    "index_c1 = find(trial_data_compile[:choice].==1)\n",
    "index_c2 = find(trial_data_compile[:choice].==2)\n",
    "index_c99 = find(trial_data_compile[:choice].==-99)\n",
    "\n",
    "index_choice = [index_c1; index_c2; index_c99]\n",
    "\n",
    "Q0_raw_choosen = [trial_data_compile[index_c1,:Q0_raw_left]; trial_data_compile[index_c2,:Q0_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q0_raw_NOTchoosen = [trial_data_compile[index_c1,:Q0_raw_right]; trial_data_compile[index_c2,:Q0_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q0_raw_choosen] = vcat(Q0_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q0_raw_NOTchoosen] = vcat(Q0_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "Q1_raw_choosen = [trial_data_compile[index_c1,:Q1_raw_left]; trial_data_compile[index_c2,:Q1_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q1_raw_NOTchoosen = [trial_data_compile[index_c1,:Q1_raw_right]; trial_data_compile[index_c2,:Q1_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q1_raw_choosen] = vcat(Q1_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q1_raw_NOTchoosen] = vcat(Q1_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "Q0s2_raw_choosen = [trial_data_compile[index_c1,:Q0s2_raw_left]; trial_data_compile[index_c2,:Q0s2_raw_right]; trial_data_compile[index_c99,:choice]]\n",
    "Q0s2_raw_NOTchoosen = [trial_data_compile[index_c1,:Q0s2_raw_right]; trial_data_compile[index_c2,:Q0s2_raw_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:Q0s2_raw_choosen] = vcat(Q0s2_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:Q0s2_raw_NOTchoosen] = vcat(Q0s2_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "QD_raw_choosen = [trial_data_compile[index_c1,:Qd_left]; trial_data_compile[index_c2,:Qd_right]; trial_data_compile[index_c99,:choice]]\n",
    "QD_raw_NOTchoosen = [trial_data_compile[index_c1,:Qd_right]; trial_data_compile[index_c2,:Qd_left]; trial_data_compile[index_c99,:choice]]\n",
    "trial_data_compile[:QD_raw_choosen] = vcat(QD_raw_choosen[sortperm(index_choice),:]...)\n",
    "trial_data_compile[:QD_raw_NOTchoosen] = vcat(QD_raw_NOTchoosen[sortperm(index_choice),:]...)\n",
    "\n",
    "# #replace -99 choices with NaNs for Q values choosen/not choosen\n",
    "trial_data_compile[find(trial_data_compile[:choice].==-99), [:Q0_raw_choosen, :Q0_raw_NOTchoosen, :Q1_raw_choosen, :Q1_raw_NOTchoosen, :Q0s2_raw_choosen, :Q0s2_raw_NOTchoosen, :QD_raw_choosen, :QD_raw_NOTchoosen]] = NaN\n",
    "\n",
    "head(trial_data_compile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Calculate probabilities of choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#calculate probability of chosen and unchosen from Q values \n",
    "\n",
    "ProbChosen_ALL = []\n",
    "ProbUnchosen_ALL =  []\n",
    "ProbChosen_minus_Unchosen_ALL = []\n",
    "\n",
    "ProbChosen_ALL_MB = []\n",
    "ProbChosen_ALL_MF = []\n",
    "ProbChosen_ALL_MB_min_MF = []\n",
    "\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "    \n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = Array(params_full[x, [:betamb, :beta_mf0, :beta_mf1, :sticky]])\n",
    "    beta_MB = betas_sub[1] #beta MB\n",
    "    betas_MF0 = betas_sub[2] #beta MF0\n",
    "    betas_MF1 = betas_sub[3] #beta MF1\n",
    "    betas_stick = betas_sub[4]    \n",
    "    \n",
    "    subset_data = trial_data_compile[trial_data_compile[:sub].==subs[x], :]\n",
    "    \n",
    "    n_trials = size(subset_data); n_trials = n_trials[1]\n",
    "\n",
    "    ProbChosen = zeros(n_trials)\n",
    "    ProbUnchosen = zeros(n_trials)\n",
    "    ProbChosen_minus_Unchosen = zeros(n_trials)\n",
    "    ProbChosen_MB = zeros(n_trials)\n",
    "    ProbChosen_MF = zeros(n_trials)\n",
    "    \n",
    "    choices = subset_data[:choice]\n",
    "    Q0select = subset_data[:Q0_raw_choosen]\n",
    "    Q0NOTselect = subset_data[:Q0_raw_NOTchoosen] \n",
    "    Q1select = subset_data[:Q1_raw_choosen]\n",
    "    Q1NOTselect = subset_data[:Q1_raw_NOTchoosen] \n",
    "    QSselect = subset_data[:Q0s2_raw_choosen]\n",
    "    QSNOTselect = subset_data[:Q0s2_raw_NOTchoosen] \n",
    "    \n",
    "    prev_choice = NaN;\n",
    "    \n",
    "    for t = 1:n_trials\n",
    "    \n",
    "        curr_choice = choices[t]\n",
    "        \n",
    "        #if not a pav trial \n",
    "        if curr_choice>0\n",
    "            \n",
    "            #if first choice (note first trial will be pav, missed responses already taken out) \n",
    "            #then do not include sticky parameter into softmax\n",
    "            if n_trials == 2\n",
    "                ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t])) \n",
    "                ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                ProbChosen_MB[t] = exp(beta_MB*QSselect[t])/(exp(beta_MB*QSselect[t]) + exp(beta_MB*QSNOTselect[t])) \n",
    "                ProbChosen_MF[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t]) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t]))\n",
    "                prev_choice = curr_choice\n",
    "                \n",
    "            #if not the first choice then do not include sticky parameter into softmax    \n",
    "            elseif n_trials > 2\n",
    "                \n",
    "                # where sticky param is added depends whether the current choice equals the current choice\n",
    "                # if it is then add into the chosen probability\n",
    "                if curr_choice==prev_choice\n",
    "                    ProbChosen[t] = exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + betas_stick)/(exp((betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + betas_stick) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t])) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t];\n",
    "                    ProbChosen_MB[t] = exp(beta_MB*QSselect[t] + betas_stick)/(exp(beta_MB*QSselect[t] + betas_stick) + exp(beta_MB*QSNOTselect[t])) \n",
    "                    ProbChosen_MF[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + betas_stick)/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + betas_stick) + exp(betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t])) \n",
    "                    prev_choice = curr_choice;\n",
    "                # if it is then add into the not chosen probability\n",
    "                elseif curr_choice!=prev_choice\n",
    "                    ProbChosen[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t] + beta_MB*QSselect[t]) + exp((betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t] + beta_MB*QSNOTselect[t]) + betas_stick)) \n",
    "                    ProbUnchosen[t] = 1 - ProbChosen[t];\n",
    "                    ProbChosen_minus_Unchosen[t] = ProbChosen[t] - ProbUnchosen[t]\n",
    "                    ProbChosen_MB[t] = exp(beta_MB*QSselect[t])/(exp(beta_MB*QSselect[t]) + exp((beta_MB*QSNOTselect[t]) + betas_stick)) \n",
    "                    ProbChosen_MF[t] = exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t])/(exp(betas_MF0*Q0select[t] + betas_MF1*Q1select[t]) + exp((betas_MF0*Q0NOTselect[t] + betas_MF1*Q1NOTselect[t]) + betas_stick)) \n",
    "                    prev_choice = curr_choice;\n",
    "                end\n",
    "                \n",
    "            end\n",
    "                \n",
    "        else\n",
    "            \n",
    "            ProbChosen[t]  = NaN;\n",
    "            ProbUnchosen[t] = NaN;\n",
    "            ProbChosen_minus_Unchosen[t] = NaN;\n",
    "            ProbChosen_MB[t] = NaN;\n",
    "            ProbChosen_MF[t] = NaN;\n",
    "            \n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    ProbChosen_ALL = [ProbChosen_ALL; ProbChosen];\n",
    "    ProbUnchosen_ALL = [ProbUnchosen_ALL; ProbUnchosen];\n",
    "    ProbChosen_minus_Unchosen_ALL = [ProbChosen_minus_Unchosen_ALL; ProbChosen_minus_Unchosen];\n",
    "    ProbChosen_ALL_MB = [ProbChosen_ALL_MB; ProbChosen_MB];\n",
    "    ProbChosen_ALL_MF = [ProbChosen_ALL_MF; ProbChosen_MF];\n",
    "    ProbChosen_ALL_MB_min_MF = [ProbChosen_ALL_MB_min_MF; ProbChosen_MB - ProbChosen_MF];\n",
    "\n",
    "end\n",
    "\n",
    "#Now bung into data frame and merge with rest\n",
    "Q_probs = DataFrame([ProbChosen_ALL, \n",
    "        ProbUnchosen_ALL, \n",
    "        ProbChosen_minus_Unchosen_ALL,\n",
    "        ProbChosen_ALL_MB,\n",
    "        ProbChosen_ALL_MF,\n",
    "        ProbChosen_ALL_MB_min_MF])\n",
    "        \n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_probs, [:ProbChosen, \n",
    "        :ProbUnchosen, \n",
    "        :ProbChosen_minus_Unchosen,\n",
    "        :ProbChosen_MB,\n",
    "        :ProbChosen_MF,\n",
    "        :ProbChosen_MB_min_MF])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous full compile)\n",
    "trial_data_compile = hcat(trial_data_compile, Q_probs); #could also do just: [full_Q_compile Q_probs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head(trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save data to csv in model folder\n",
    "NOTE: after this note you must save as an xlsx file to run in matlab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writetable(\"trial_data_compile.csv\", trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load in pupil data for each timepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
