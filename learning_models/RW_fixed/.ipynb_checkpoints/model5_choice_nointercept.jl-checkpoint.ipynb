{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start up commands/load relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries\n",
    "using Distributed\n",
    "\n",
    "# # set everything up\n",
    "parallel = true # Run on multiple CPUs. If youhttp://localhost:8888/notebooks/Dropbox/Daw_Lab/PreySelection/v103/models/model_subjective1beta2lr_delayreward/model_subjective1beta2lr_delayreward.jl.ipynb# are having trouble, set parallel = false: easier to debug\n",
    "\n",
    "# this activates the multiprocessing threads\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "    addprocs(2)\n",
    "end\n",
    "\n",
    "# load required libraries\n",
    "@everywhere using DataFrames\n",
    "@everywhere using ForwardDiff\n",
    "@everywhere using PyCall\n",
    "@everywhere using Distributions\n",
    "@everywhere using PyPlot\n",
    "@everywhere using CSV\n",
    "@everywhere using SpecialFunctions\n",
    "@everywhere using SharedArrays\n",
    "@everywhere using LinearAlgebra\n",
    "\n",
    "@everywhere PyCall.@pyimport scipy.optimize as so\n",
    "\n",
    "# this is the code for the actual fitting routines\n",
    "@everywhere include(\"em.jl\")\n",
    "@everywhere include(\"common.jl\")\n",
    "@everywhere include(\"likfuns.jl\")\n",
    "\n",
    "# this is generates starting matricies for betas, sigmas etc to feed into model\n",
    "@everywhere include(\"genVars.jl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data read and process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "df = readtable(\"/Users/Neil/GitHubRepo/Projects/ValueInference/study4_mri/data/gem_dat.csv\")\n",
    "\n",
    "#get rid of missed responses\n",
    "df = df[df[:missed_trial].!=1,:]\n",
    "\n",
    "#add \"sub column\" \n",
    "# this is just a replica of the existing column sub_no but I think em looks for \"sub\" specifically\n",
    "df[:sub] = df[:participantID];\n",
    "\n",
    "#change coding so that 1 = market 1 in dependent condition,\n",
    "#2 and 3 refer to the two markets in the independent condition\n",
    "df[:market_presented] = df[:market_presented] + 1\n",
    "df[df[:blockType].==1,:market_presented] = 1\n",
    "\n",
    "#code picking white as 2, picking black as 1\n",
    "df[:state_chosen] = df[:pick_black]\n",
    "df[df[:state_chosen].==0, :state_chosen] = 2\n",
    "\n",
    "#convert this so can use in model\n",
    "df[:state_chosen] = convert(Vector{Integer}, df[:state_chosen])\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exlude subs 21 and 28..\n",
    "\n",
    "df = df[df[:participantID].!=21,:];\n",
    "df = df[df[:participantID].!=28,:];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use recoded condition variable in the model\n",
    "df[:condition_recode] = df[:blockType]\n",
    "df[df[:condition_recode].==2,:condition_recode] = -1\n",
    "\n",
    "#now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function rl_model(params, data)\n",
    "    \n",
    "    #model parameteres\n",
    "\tbeta_mb = params[1] \n",
    "    w_slope = params[2]\n",
    "    lr =  0.5 .+ 0.5.*erf(params[3]/sqrt(2))\n",
    "    \n",
    "    c1 = data[:state_chosen] # choice: 1 = black door, 2 = white door\n",
    "    r = data[:outcome] # outcome: coded as +1 = gain, -1 = loss, 0 = neutral \n",
    "    s = data[:outcomeState] # stage 2 state: coded as 1 = gain/loss state reached, 2 = neutral state reached\n",
    "    t = data[:trials] # trial number\n",
    "    sub = data[:sub] # subject number\n",
    "    condition = data[:condition_recode] # condition: 1 = dependent, -1=independent\n",
    "    gem = data[:gem_presented] #gem presented\n",
    "    market = data[:market_presented] #market presented\n",
    "    reward_loss_trial = data[:rew_loss]\n",
    "    force_t = data[:forcedTrial]\n",
    "    block_n = data[:block_n]\n",
    "    blackFirst = data[:blackFirst]\n",
    "    \n",
    "    SR_m = zeros(typeof(beta_mb), 2) .+ 0.5 #initalise to 0.5. stores estimates of transition probabilities for black/white door going to reward/loss state \n",
    "    SR_gem = zeros(typeof(beta_mb), 4) .+ 0.5 #initalise to 0.5. stores estimates of transition probabilities for black/white door going to reward/loss state \n",
    "   \n",
    "\tQmb = zeros(typeof(beta_mb), 2) #decision variable\n",
    "    Qmb_gem = zeros(typeof(beta_mb), 2) #decision variable\n",
    "    \n",
    "    #encode in the frame of getting to the rl state\n",
    "    prob_rl_chosen_m = [];\n",
    "    prob_rl_unchosen_m = [];\n",
    "    prob_rl_doorpresented_m = [];\n",
    "\n",
    "    ev_rl_chosen_m = [];\n",
    "    ev_rl_unchosen_m = [];\n",
    "    ev_rl_doorpresented_m = [];\n",
    "    \n",
    "    prob_rl_chosen_gem = [];\n",
    "    prob_rl_unchosen_gem = [];\n",
    "    prob_rl_doorpresented_gem = [];\n",
    "\n",
    "    ev_rl_chosen_gem = [];\n",
    "    ev_rl_unchosen_gem = [];\n",
    "    ev_rl_doorpresented_gem = [];\n",
    "    \n",
    "    SPE_m_compile_signed = [];\n",
    "    SPE_m_compile_abs = [];\n",
    "    SPE_gem_compile_signed = [];\n",
    "    SPE_gem_compile_abs = [];\n",
    "    \n",
    "    EV_combined_compile = [];\n",
    "    prob_combined_rl_chosen_compile = [];\n",
    "    \n",
    "    good_bad_compile = [];\n",
    "    \n",
    "    # initialize likelihood\n",
    "    lik = 0 \n",
    "    \n",
    "\tfor i = 1:length(c1)\n",
    "        \n",
    "        w = w_slope*(condition[i])\n",
    "\n",
    "        if gem[i]<3\n",
    "            index = 1            \n",
    "        else\n",
    "            index = 2\n",
    "        end\n",
    "                \n",
    "        Qmb = [SR_m[index].*reward_loss_trial[i], (1-SR_m[index]).*reward_loss_trial[i]]\n",
    "        Qmb_gem = [SR_gem[gem[i]].*reward_loss_trial[i], (1-SR_gem[gem[i]]).*reward_loss_trial[i]]\n",
    "       \n",
    "        tmp_a = (1-w).*Qmb + w.*Qmb_gem\n",
    "        tmp_b = (1-w).*[SR_m[index], (1-SR_m[index])] + w.*[SR_gem[gem[i]], (1-SR_gem[gem[i]])]\n",
    "        \n",
    "        if (c1[i]==1)\n",
    "            append!(prob_rl_chosen_m, SR_m[index]); append!(prob_rl_unchosen_m, 1-SR_m[index]);\n",
    "            append!(prob_rl_chosen_gem, SR_gem[gem[i]]); append!(prob_rl_unchosen_gem, 1-SR_gem[gem[i]]);\n",
    "            append!(ev_rl_chosen_m, Qmb[1]); append!(ev_rl_unchosen_m, Qmb[2]);    \n",
    "            append!(ev_rl_chosen_gem, Qmb_gem[1]); append!(ev_rl_unchosen_gem, Qmb_gem[2]); \n",
    "            append!(EV_combined_compile, tmp_a[1]); \n",
    "            append!(prob_combined_rl_chosen_compile, tmp_b[1]); \n",
    "            \n",
    "        elseif (c1[i]==2)\n",
    "            append!(prob_rl_chosen_m, 1-SR_m[index]); append!(prob_rl_unchosen_m, SR_m[index]);\n",
    "            append!(prob_rl_chosen_gem, 1-SR_gem[gem[i]]); append!(prob_rl_unchosen_gem, SR_gem[gem[i]]);    \n",
    "            append!(ev_rl_chosen_m, Qmb[2]); append!(ev_rl_unchosen_m, Qmb[1]);  \n",
    "            append!(ev_rl_chosen_gem, Qmb_gem[2]); append!(ev_rl_unchosen_gem, Qmb_gem[1]);\n",
    "            append!(EV_combined_compile, tmp_a[2]); \n",
    "            append!(prob_combined_rl_chosen_compile, tmp_b[2]); \n",
    "            \n",
    "        end\n",
    "        \n",
    "        if (blackFirst[i]==1)\n",
    "            append!(prob_rl_doorpresented_m, SR_m[index]); \n",
    "            append!(prob_rl_doorpresented_gem, SR_gem[gem[i]]); \n",
    "            append!(ev_rl_doorpresented_m, SR_m[index].*reward_loss_trial[i]); \n",
    "            append!(ev_rl_doorpresented_gem, SR_gem[gem[i]].*reward_loss_trial[i]); \n",
    "        elseif (blackFirst[i]==-1)\n",
    "            append!(prob_rl_doorpresented_m, 1-SR_m[index]); \n",
    "            append!(prob_rl_doorpresented_gem, 1-SR_gem[gem[i]]);\n",
    "            append!(ev_rl_doorpresented_m, (1-SR_m[index]).*reward_loss_trial[i]); \n",
    "            append!(ev_rl_doorpresented_gem, (1-SR_gem[gem[i]]).*reward_loss_trial[i]);             \n",
    "        end\n",
    "            \n",
    "        # given Q values, posterior probability that choice was the observed choice is given by the softmax\n",
    "        # add that likelihood to the running likelihood\n",
    "        #only implement for force trials\n",
    "        if (force_t[i] == 0)\n",
    "            \n",
    "            #Q-values that determine the decision\n",
    "            Q_combined = (1-w).*Qmb + w.*Qmb_gem\n",
    "            Qd = beta_mb.*Q_combined\n",
    "            \n",
    "            lik += Qd[c1[i]] .- log(sum(exp.(Qd)))\n",
    "            \n",
    "        else\n",
    "        end\n",
    "\n",
    "        # updates go in here - these are updates of probability estimates (not contingent on outcome)\n",
    "        if (s[i]==1 & c1[i]==1)\n",
    "            SPE_m = 1 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*1\n",
    "            SPE_gem = 1 - SR_gem[gem[i]]\n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*1\n",
    "        elseif (s[i]==2 & c1[i]==2)\n",
    "            SPE_m = 1 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*1\n",
    "            SPE_gem = 1 - SR_gem[gem[i]]           \n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*1\n",
    "        else\n",
    "            SPE_m = 0 - SR_m[index]\n",
    "            SR_m[index] = (1-lr)*SR_m[index] .+ lr*0\n",
    "            SPE_gem = 0 - SR_gem[gem[i]]            \n",
    "            SR_gem[gem[i]] = (1-lr)*SR_gem[gem[i]] .+ lr*0\n",
    "        end\n",
    "        \n",
    "        append!(SPE_m_compile_signed, SPE_m); \n",
    "        append!(SPE_m_compile_abs, abs(SPE_m));    \n",
    "        append!(SPE_gem_compile_signed, SPE_gem);    \n",
    "        append!(SPE_gem_compile_abs, abs(SPE_gem));\n",
    "        \n",
    "        if (r[i]==1)\n",
    "            good_bad = 1\n",
    "        elseif (r[i]==-1)\n",
    "            good_bad = -1\n",
    "        elseif (r[i]==0) & (reward_loss_trial[i]==1)\n",
    "            good_bad = -1\n",
    "        elseif (r[i]==0) & (reward_loss_trial[i]==-1)\n",
    "            good_bad = 1\n",
    "        end\n",
    "        \n",
    "          append!(good_bad_compile, good_bad); \n",
    "\n",
    "\tend\n",
    "    \n",
    "    #compile trial by trial values here\n",
    "    trial_data = DataFrame(trial = t,\n",
    "    sub = sub,\n",
    "    block_n = block_n,\n",
    "    choice = c1,\n",
    "    outcomeState = s,\n",
    "    outcome = r,\n",
    "    gem = gem,\n",
    "    condition = condition,\n",
    "    market = market,\n",
    "    force_t = force_t,\n",
    "    prob_rl_chosen_m = prob_rl_chosen_m,\n",
    "    prob_rl_unchosen_m = prob_rl_unchosen_m,\n",
    "    ev_rl_chosen_m = ev_rl_chosen_m,\n",
    "    ev_rl_unchosen_m = ev_rl_unchosen_m,\n",
    "    prob_rl_chosen_gem = prob_rl_chosen_gem,\n",
    "    prob_rl_unchosen_gem = prob_rl_unchosen_gem,\n",
    "    ev_rl_chosen_gem =ev_rl_chosen_gem,\n",
    "    ev_rl_unchosen_gem = ev_rl_unchosen_gem,\n",
    "    SPE_m_compile_signed = SPE_m_compile_signed,\n",
    "    SPE_m_compile_abs = SPE_m_compile_abs,\n",
    "    SPE_gem_compile_signed = SPE_gem_compile_signed,\n",
    "    SPE_gem_compile_abs = SPE_gem_compile_abs,\n",
    "    EV_combined = EV_combined_compile,\n",
    "    prob_rl_chosen_combined = prob_combined_rl_chosen_compile,\n",
    "    prob_rl_doorpresented_m = prob_rl_doorpresented_m,\n",
    "        prob_rl_doorpresented_gem = prob_rl_doorpresented_gem,\n",
    "        ev_rl_doorpresented_m = ev_rl_doorpresented_m,\n",
    "        ev_rl_doorpresented_gem = ev_rl_doorpresented_gem,\n",
    "    good_bad = good_bad_compile)\n",
    "\n",
    "    # here if running em you can only return the likelihood\n",
    "    return -lik\n",
    "    #return (-lik, trial_data)\n",
    "\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model for one subject\n",
    "(aids debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameter structures\n",
    "(df, subs, X, betas, sigma) = genVars(df, 3);\n",
    "\n",
    "# run model for sub 1\n",
    "rl_model(betas, df[df[:sub].==subs[1], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run em to get best fit parameters for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized parameter structures (again)\n",
    "# note that some of the variables (e.g. betas, sigma) are entered and returned by em function \n",
    "(df, subs, X, betas, sigma) = genVars(df, 4);\n",
    "\n",
    "# run for full learner\n",
    "# x contains the parameters for each subject (note not the same as variable X)\n",
    "# l and h are per-subject likelihood and hessians\n",
    "@time (betas, sigma, x, l, h) = em(df, subs, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true, quiet=false);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Model Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBIC, IAIC and LOOcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model selection/comparison/scoring\n",
    "\n",
    "# laplace approximation to the aggregate log marginal likelihood of the whole dataset\n",
    "# marginalized over the individual params\n",
    "\n",
    "aggll = lml(x, l, h)\n",
    "\n",
    "# to compare this between models you need to correct for the group-level free parameters\n",
    "# either aic or bic\n",
    "\n",
    "aggll_ibic = ibic(x, l, h, betas, sigma, nrow(df))\n",
    "aggll_iaic = iaic(x, l, h, betas, sigma)\n",
    "\n",
    "# or you can compute unbiased per subject marginal likelihoods via subject-level cross validation\n",
    "# you can do paired t tests on these between models\n",
    "# these are also appropriate for SPM_BMS etc\n",
    "\n",
    "# takes ages so comment in when want to run, otherwise just use IAIC above\n",
    "liks = loocv(df, subs, x, X, betas, sigma, rl_model; emtol=1e-3, parallel=true, full=true)\n",
    "#aggll_loo = sum(liks)\n",
    "\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll: $aggll_iaic\\nloo nll:  $aggll_loo\")\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll:\")\n",
    "print(aggll_iaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write loocv scores to csv file\n",
    "\n",
    "(if you have run this part above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put loocv scores into dataframe\n",
    "loocv_scores = DataFrame(sub = subs,\n",
    "liks = vec(liks));\n",
    "\n",
    "#write to csv\n",
    "CSV.write(\"loocv_scores.csv\", DataFrame(loocv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and write p values, std error and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard errors on the subject-level means, based on an asymptotic Gaussian approx \n",
    "# (these may be inflated esp for small n)\n",
    "(standarderrors, pvalues, covmtx) = emerrors(df, subs, x, X, h, betas, sigma, rl_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = DataFrame(stderror = vec(standarderrors),\n",
    "pvalues = vec(pvalues),\n",
    "covmtx_1 = vec(covmtx[:,1]),\n",
    "covmtx_2 = vec(covmtx[:,2]),\n",
    "covmtx_3 = vec(covmtx[:,3]),\n",
    "covmtx_4 = vec(covmtx[:,4]))\n",
    "\n",
    "# save model stats to csv file\n",
    "CSV.write(\"model_stats.csv\", DataFrame(model_stats));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standarderrors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covmtx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write per subject model parameters to csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save a copy of just the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put parameters into variable d\n",
    "d=x';\n",
    "\n",
    "# now put parameters into dataframe\n",
    "params = DataFrame(sub = subs,\n",
    "beta_mb = vec(d[:, 1]),\n",
    "w_intercept = vec(d[:, 2]),\n",
    "w_slope = vec(d[:, 3]),   \n",
    "eta_unconverted = vec(d[:, 4]),\n",
    "eta_converted = vec(0.5 .+ 0.5*erf.(d[:, 4] / sqrt(2))))\n",
    "\n",
    "# save parameters to csv file\n",
    "CSV.write(\"subject_params.csv\", DataFrame(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = readtable(\"subject_params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameter structures once again\n",
    "(df, subs, X, betas, sigma) = genVars(df, 4);\n",
    "\n",
    "# initalise this - will store all trial to trial parameters\n",
    "trial_data_compile = [];\n",
    "\n",
    "# run model for each subject using best fit parameters\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = convert(Array, params[x, [:beta_mb, :w_intercept, :w_slope, :eta_unconverted]])\n",
    "    data_sub = df[df[:sub].==subs[x], :]\n",
    "    \n",
    "    # run model using these parameters - note must have commented in the model to return all of these variables (and not only -lik)\n",
    "    (minus_li, trial_data) = rl_model(betas_sub, data_sub)\n",
    "    \n",
    "    if x.==1\n",
    "        \n",
    "        trial_data_compile = trial_data\n",
    "        \n",
    "    else\n",
    "        \n",
    "        append!(trial_data_compile, trial_data)\n",
    "        \n",
    "    end\n",
    " \n",
    "end\n",
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(trial_data_compile))\n",
    "    \n",
    "# print header of data compile\n",
    "head(trial_data_compile)\n",
    "\n",
    "CSV.write(\"trial_by_trial_vals.csv\", DataFrame(trial_data_compile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
